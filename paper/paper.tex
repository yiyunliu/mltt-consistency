\newif\ifcomments     %% include author discussion
\newif\ifanonymous    %% include author identities
\newif\ifextended     %% include appendix
\newif\ifsubmission   %% prepare the submitted version
\newif\ifpublic       %% version available for posting / final version

\commentstrue         %% toggle comments here
\extendedfalse
\anonymoustrue

\submissionfalse     %% at most one of these must be true (neither for draft version)
\publicfalse         %% but if you want to see comments, these should both be off


% If we are going to make a version public, i.e. on arXiv, we should
% make sure that there are no comments and our names are on it.
\ifpublic
\submissionfalse
\commentsfalse
\anonymousfalse
\fi

%% If we are submission, make sure there are no comments and our names
%% are NOT on it.
\ifsubmission
\publicfalse
\commentsfalse
\anonymoustrue
\fi


%%
%% This is file `sample-acmsmall.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `acmsmall')
%%
%% IMPORTANT NOTICE:
%%
%% For the copyright see the source file.
%%
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-acmsmall.tex.
%%
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%%
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[acmsmall,screen=true,
\ifpublic review=false\else,review=true\fi
  ,anonymous=\ifanonymous true\else false\fi]{acmart}
\usepackage{ottalt}
\usepackage{minted}
\usepackage{xspace}
\usepackage{tcolorbox}
\usepackage[para]{footmisc}
\definecolor{lightgray}{gray}{0.85}
\newcommand{\dotv}[2]{\href{#1}{\texttt{#1}}{\texttt{:#2}}}
\newcommand{\lang}{$\lambda^H$\xspace}
\inputott{rules}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% to allow unicode characters in minted code
\usepackage{newunicodechar}
\newunicodechar{⇒}{$\Rightarrow$}

\usepackage{draft}

\ifcomments
\newnote{scw}{blue} % Stephanie Weirich
\newnote{yl}{purple} % Yiyun Liu
\else
\newcommand{\scw}[1]{}
\newcommand{\yl}[1]{}
\fi


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Short and Mechanized Logical Relation for Dependent Type Theory}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Yiyun Liu}
\orcid{0009-0006-8717-2498}
\affiliation{
  \institution{University of Pennsylvania}
  \city{Philadelphia}
  \country{USA}
}
\email{liuyiyun@seas.upenn.edu}

\author{Stephanie Weirich}
\orcid{0000-0002-6756-9168}
\affiliation{
  \institution{University of Pennsylvania}
  \city{Philadelphia}
  \country{USA}
}
\email{sweirich@seas.upenn.edu}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
% \renewcommand{\shortauthors}{Trovato et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Proof by logical relation is a powerful technique that has been used
to derive metatheoretic properties of type systems, such as
consistency and parametricity. While there exists a
plethora of introductory materials about logical relation in the
context of simply typed or polymorphic lambda calculus, a streamlined
presentation of proof by logical relation for a dependently language
is lacking. In this paper, I present a short
consistency proof for a dependently typed language that contains a
rich set of features, including a full cumulative universe
hierarchy, booleans, and an intensional identity type. We have
fully mechanized the consistency proof using the Coq proof assistant
in under 1000 lines of code.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Logical Relation, Dependent Types, Logical Consistency, Coq}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
In this paper, we present a \emph{short} and \emph{mechanized} proof of
logical consistency for \lang{}, a dependent type theory with a full
predicative universe hierarchy, large eliminations, an intensional identity
type, a boolean base type, and dependent elimination forms.

Our goal with this work is to demonstrate how the proof technique of
\emph{logical relations} can be applied to reason about dependent type theories.
Tutorial material on this topic~\cite{lr-tutorials} is primarily focussed on
systems with simple or polymorphic types. In that context, logical relations
can be define as simple recursive functions over the structure of types, or
(in the case of recursive types) defined over the evaluation steps of the
computation.
\scw{need one sentence to motivate why logical relations are important}

Neither of these techniques make sense for predicative dependent type theory,
so a young researcher might be excused for thinking that proofs that use
logical relations are not applicable.  \scw{Well, actually, we did use a
  step-indexed relation for Trellys\ldots}\yl{The core calculus of Trellys'
  logical fragment is simple type + identity so I don't think that counts..}
But this is not the case. Recent authors have developed tour-de-force
mechanizations for the metatheory of modern proof
assistants~\citep{nbeincoq,decagda,martin-lof-a-la-coq,anand2014towards}, and
have relied on logical relations defined as part of their
developments. However, because these proofs show diverse results about real
systems and algorithms, these developments range in size from 20,000 to
400,000 lines of code, these definitions are easy to miss and difficult to
isolate from their surrounding contexts. As a result, they are not accessible
to casual readers.

Our proof, designed to capture the essence of this proof technique in this
setting, requires less than 1000 lines of code. We have achieved this
significant reduction through a number of means: the careful selection of the
features that we include in the object type type system and the results that
we prove about it, in addition to the judicious use of automation.  Our
language is small, but includes enough to be illustrative. For example, we
eschew inductive datatypes or W-types, the but we do include propositionality
equality and booleans in order to capture the challenges presented by indexed
types and dependent pattern matching. We do not show the decidability of type
checking, nor do we develop a PER semantics, but we do demonstrate how our
consistency proof can be extended (at a moderate cost of 500 lines of code) to
show the existence of $\beta\eta$-normal form for well-typed open \emph{and}
closed terms. We include a full predicative universe hiercharchy and
type-level computation, to demonstrate the logical strength of the
approach. \scw{Say that we don't have impredicativity, but neither does anyone
  else?}\yl{Nobody else but Barras. I'll find the citation}
%%
%% SCW: save specific comparisons with other systems for later
%%
% The big difference in the size of the developments does not
% necessarily imply that our proof technique leads to a more concise
% proof due to the differing expressiveness of the languages and the
% different metatheoretic results being established. For
% example, \citet{anand2014towards} mechanizes the metatheory of
% Nuprl~\citep{constable1986implementing}, which, on top of all the
% features that \lang{} supports, includes W-types and partial types and
% requires a PER semantics to model its extensional typed
% equality. The object language from \citet{decagda} does not support
% identity types and only has one predicative universe, but additionally
% supports $\Sigma$ types. However, for a researcher who wishes to learn
% the underlying techniques for mechanized logical relation for
% dependent type theory, a small development like ours is much easier to
% navigate and understand. Furthermore, we show how our simple
% consistency proof can be easily extended to show the existence of
% $\beta\eta$-normal form for well-typed open \emph{and} closed terms,
% giving us a metatheoretic result almost as strong as the one from
% \citet{decagda} at the moderate cost of around 500 lines of extra code.


The result of our work is a development that an interested researcher can
navigate and understand. We accompany this mechanized proof with an informal
description, presented here using set theory notation and terminology so that
the material is accessible to readers with general mathematical background,
That said, our explanations do not stray too far away from our proof scripts.
We label each lemma directly to their counterpart in the proof script,
anticipating that readers may wish to reference and validate our formalism.
Our typeset representation are purposefully made to directly follow our
mechanical proofs, while avoiding, as much as possible, the introduction
of artifacts that are specific to certain theorem prover.

Not only does this connection aid readers that wish to, like us, adopt proof
assistants for their day-to-day use. We also find that this precision is
important for conveying the proof techique itself. Unlike properties that are
derivable through syntactic means, proofs by logical relation make demands on
the strength of the logic in which they are expressed. An informal proof that
attempts to be agnostic or ambiguous about the underlying
metatheory % may struggle to even
% convey the validity of their definition and
requires substantial
effort from the reader to even understand whether it is theoretically
possible to encode such proofs in a given ambient logic, such as those found
in modern proof assistants.

% The close correspondence between a typeset proof and a mechanized
% proof comes at the potential risk that the artifacts specific to
% theorem provers may become visible in the presented proof.
%However, for proofs by logical relation for
%dependent types, we find our approach advantageous for a few reasons.
Furthermore, while a proof assistant may reject perfectly valid definitions,
it helps us keep our definition precise and unambiguous. A precise definition
is crucial as the reasoning principles we are allowed to use is directly tied
to the definition, which is sometimes obscured by concise notations that
diverge too far from a formal proof.

Finally, our approach does not result in a verbose proof on paper, thanks to
the already short mechanization. While we do make conservative simplifications
to our typeset proof, such as avoiding the clunky syntax for well-founded
recursion in Coq, we keep the overall structure of our typeset proofs
consistent with our mechanization.

In Section~\ref{sec:spec}, we introduce \lang{}, the object language
of interest, and establish some elementary properties about parallel
reduction, which will be used as the equational theory of our language
and play a central role in defining our logical relation. The design
of \lang{} is reminiscent of Martin-Löf style predicatvie type
systems. The untyped conversion rule of \lang{} is inspired by Pure
Type Systems~\citet{barendregt1991introduction}, though we discuss how
our proof can be easily adjusted for systems with typed judgmental
equality.  We design \lang{} to incorporate some of the most common
features of dependent type theory, including an intensional identity
type, a boolean type, large elimination, dependent elimination, and a
full universe hierarchy. We believe a good coverage of features will
make our proof applicable to a broad range of type systems.

In Section~\ref{sec:logreldep}, we formulate the consistency property
and motivate why proof by logical relation is needed to derive it.
We define our logical relation as an inductively defined relation. We first
show that the logical relation respects evaluation (referred to as the
irrelevance property in \citet{martin-lof-a-la-coq}), then proceed to
prove that the logical relation is a partial function; that is, each
type can have at most one unique interpretation.

In Section~\ref{sec:logrelproof}, we give the definition of semantic
typing in terms of our logical relation so we can state and prove the
fundamental theorem, which states that syntactic typing implies
semantic typing, from which consistency follows as a corollary.

In Section~\ref{sec:extension}, we extend our logical relation to
prove the stronger property that every well-typed term has a
$\beta\eta$-normal form. After laying the foundation for handling
type-level computation in Section~\ref{sec:logreldep}, the extension
to include open terms in the logical relation requries mechanical
changes that directly mirrors the same extension for a simply typed
language. We use this extension to demonstrate the idea that once we
have established the base technique for proof by logical relation for
dependent types, we can factor out the complexities of an extension
the are not specifically related to dependent types; such an
extension, if desired, may be studied in the context of a simply typed
language and later ported into a dependently typed setting. We believe
it is possible to extend our logical relation to a Kripke-style and
relational model in a similar fashion.

In Section~\ref{sec:logrelmech}, we discuss the details about our
mechanization, including our use of existing libraries such as
Autosubst 2~\citep{autosubst2} for handling bindings and
CoqHammer~\citep{czajka2018hammer} for general-purpose automation.

In Section~\ref{sec:relatedwork}, we discuss how our proof relates to
existing proofs by logical relations and other proof techniques for
proving consistency and normalization.

We hope our success at creating a short and mechanized proof for a
relatively feature-complete language will encourage future researchers
to leverage the tool of logical relation more often in mechanized
proofs for dependent types.
% % For
% % example, \citet{geuvers1994short} requires impredicativity to encode
% % Calculus of Constructions, an impredicative dependent type theory, but
% % also relies on the classification property to define the logical
% % relation over well-formed types and kinds. Their simple
% % presentation of the logical relation as an inductively defined
% % function over types, reminiscent of logical relations for simply typed
% % languages,








% However, we make the
% typeset definitions as close as possible to our mechanization so the
% definitions and the proofs can be easily encoded in a proof
% assistant.
% We find the close correspondence
% between our typeset presentation and the Coq development advantageous
% for a couple of reasons. First, compared to other proof techniques,
% such as the use of preservation and progress to derive syntactic
% soundness, defining a logical relation for a dependently typed
% language is demanding on the strength of the metatheory.



% % Depending on its application, we care about certain metatheoretic
% % properties about a type system. As a programming language, we may care
% % about type soundness, which states that a well-typed never gets stuck
% % during evaluation.
% When a dependently type system is used as a program logic where terms
% encode proofs, we want our type system to be logically consistent,
% meaning that the empty type is not inhabited.

% The consistency proofs of various dependently typed systems, including Martin-Lof's
% type theory and the Calculus of Constructions, have long been
% available in the literature. In particular, recent works such as \citet{nbeincoq},
% \citet{decagda}, and \citet{martin-lof-a-la-coq} mechanize the
% correctness of the NbE algorithm, the decidability of type
% conversion, decidability of type
% checking respectively for dependently typed systems. From these
% properties, consistency can be derived as a corollary.

% The underlying technique of the forementioned
% works is proof by logical relation,
% which involves interpreting types as reducibility predicates,
% representing sets of terms satisfying certain properties with respect
% to the reduction relation. While the proof technique and the
% consistency result for dependent types are both well-established,
% there is a lack of rigorous and accessible material that shows
% how proof by logical relation can be applied to dependently typed
% systems.
% \scw{You are choosing to focus on mechanized logical relations proofs for
% dependent type theories, not consistency proofs for dependent type theories.
% Why? (And your title shuld match}


% Introductory materials about logical relations or standard textbooks such as
% \citet{skorstengaard2019introduction}, \citet{harper2016practical},
% and \citet{pierce2002types}
% talk about logical relations for simply or polymorphically typed
% languages, proving results such as termination for closed terms and parametricity.
% \scw{Are there some OPLSS notes from Amal Ahmed to also cite? Other modern textbooks?
% Does Aspinall and Hofmann's chapter of ATTAPL include a logical
% relation?}
% \yl{skorstengaard is from the OPLSS notes. Cited ATTAPL}
% \yl{Don't have a copy of }
% \scw{Seems like you should also mention POPLmark reloaded somehere too?}
% \citet{pierce2004advanced}, \citet{harperkripke}, and \citet{abel2019poplmark} show how
% a Kripke-style logical relation can be used to include scoping
% information in the logical relation and
% derive properties such as the existence of normal form or strong
% normalization for open and closed terms in simply typed languages.
% Overall, the introductory texts about logical relations
% cover systems and properties with varying degrees of complexity, from
% simply typed to polymorphicly typed, logical predicate to logical
% equivalence, closed terms to open terms.

% The glaring gap here is the
% lack of fully dependently typed systems where computations may appear
% at the type-level. It is far from obvious why proof by
% logical relation is even applicable to dependent types, since the type
% may very well-be a computation that is yet to be evaluated.
% While it is assuring that proof by logical relations for dependent
% types is available in mechanized forms, % the key to address the
% % complexities of dependent types is obscured in
% \citet{nbeincoq,decagda,martin-lof-a-la-coq} all involve relational,
% Kripke-style models that obscure the technique for addressing
% type-level computation. The added complexivity is evident
% from the size of their code base. All three developments involve 20
% thousand to 30 thousand lines of Coq or Agda code.

% The goal of this paper is to give a tutorial on proof by logical relation for
% dependent types in a simple and digestable format. \scw{This sentence should come as
% early as possible.} Dependently typed systems comes in many flavors and
% vary greatly in their expressiveness.
% In Section~\ref{sec:spec}, we introduce \lang{}, a dependently typed
% language that is small but relatively complete in features \scw{list these features explicitly:
% large eliminations, indexed types, others? \ldots} related to
% dependently types, including large elimination, a full universe
% hierarchy, an intensional identity type and a boolean base type, both
% of which are equipped with dependent elimination forms (e.g. J eliminator
% for the identity type). In particular, the inclusion of identity
% types, which is absent from \citet{decagda}, \citet{nbeincoq},
% helps demonstrate how indexed types are handled when defining the
% logical relation.

% % We choose boolean
% % types over natural numbers as our base type for simplicity, but include an
% % intensional identity type in our type system to show how indexed
% % types are treated in a logical relational proof. \scw{Talk about
% % identity type first.} Unlike
% % \citet{nbeincoq,decagda,martin-lof-a-la-coq} but similar to
% % \citet{anand2014towards}, we include an infinite hierarchy of
% % universes to not only support type-level computations, but also avoid
% % the unnecessary code duplication pointed out by \citet{nbeincoq} when
% % big and small types are treated non-uniformly.

% In Section~\ref{sec:logrelproof}, we use the standard technique that
% is commonly seen in ...

% Our consistency proof is short and fully mechanized. The proof scripts
% involve less than 1000 lines of manually written Coq code. In fact, what we find
% encouraging is that among the 1000
% lines of Coq code, 400 lines are related to the specification of the
% type system, semantics, and properties related to untyped lambda
% terms. The semantic type soundness proof through logical relation
% takes almost the same amount of code as our syntactic type soundness
% proof!
% Thanks to the conciseness of
% the proof, we are able to present it in detail in
% Sections~\ref{sec:logreldep} and \ref{sec:logrelproof}. Moreover, the
% structure of our mechanization closely corresponds to the proof we
% present in the text, enabling us to label at the footnote each lemma
% directly to their counterpart in the proof script for the readers to
% reference and validate.

% The technique we use is most similar to the one from \citet{nbeincoq},
% which leverages impredicativity to define the logical
% relation as a partial function.
% Rather than framing impredicativity as a
% mechanism for encoding induction
% recursion~\citep{induction-recursion-dybjer}, a scheme in which
% semantic models (including logical relations) for dependent types can
% be defined, we opt for a direct explanation through the informal
% language of sets, where impredicativity manifests in the form of
% second-order logical formulas and thus more intuitive to grasp
% for readers with a general mathematical background.

% A naive attempt at proving consistency through induction over the
% typing derivation would fail since the inductive hypothesis is not
% strong enough to derive the consistency result. Instead, one typically
% relies on the technique referred to as proof by logical relation to
% interpret types as reducibility predicates to strengthen the inductive
% hypothesis.




% This paper is specifically
% about establishing logical consistency for a fully dependently typed
% system with an infinite universe hierarchy and support for large
% elimination .
% The type system, presented in Section~\ref{sec:spec}, is
% most similar to Martin-Lof's predicate type theory with the minor
% difference that type conversion is based on untyped equality.


% Rather,
% our goal is to present the proof in a form that is digestable by a
% working type theorist and can be more readily mechanized in a proof
% assistant. Compared to existing efforts at mechanizing logical
% consistency or stronger properties such as existence of normal
% form~\citep{nbeincoq},
% decidable type checking~\citep{decagda}, our work is minimal since it requires very
% little scaffolding and therefore results in an extremely succinct
% proof of under 1000 lines of manually written Coq code for a dependent
% type theory that is reasonably complete in its features.

% The key technique that underlies our consistency proof is proof by
% logical relation. In
% Section~\ref{sec:spec}, we present the dependent type theory of
% interest. In Section~\ref{sec:logreldep}, we give the definition
% of the logical relation for the dependent type theory. Rather than
% presenting the logical relation as an inductive-recursive definition,
% we use the more elementary concept of a partial function to capture
% the interpretation of types. The alternative representation requires us
% to show that the set of equations indeed defines a partial function;
% that is, for each input, there should always be a unique
% output.
% From the interpretation function, we can define the semantic
% typing judgment for the set of lambda terms.
% In Section~\ref{sec:logrelproof}, we prove the fundamental theorem,
% which states that syntactic typing implies semantic typing. Once the
% fundamental theorem is established, logical consistency follows as a
% trivial corollary. In Section~\ref{sec:logrelmech}, we point out the
% specifics related to the Coq mechanization of the proof described in earlier
% section.
% Finally, in Section~\ref{sec:relatedwork}, we give a short survey of
% existing literature related to logical consistency about dependent
% type theory.

\scw{The end of this section needs to include an explicit summar of the
contributions of the paper. }

\section{Specification of a Dependent Type Theory}
\label{sec:spec}

\scw{This section needs to say:
  \begin{itemize}
\item definitional equality is untyped so that we can prove
  properties about it independent of the type system
\item definitional equality is based on parallel reduction so that we can take
  advantage of the algorithmic structure later. This definition is easier to
  invert because there are fewer derivation. That is important when reasoning
  about our logical relation.
\item can prove that parallel reduction is equivalent to other definitions of
  equality using standard means (cite Barendregt's book).  (we go halfway
  there by showing it is an equivalence relation). Can also prove equivalent
  to typed relation. (cite Siles, also CoreSpec?)
\item All of the proofs in this section are standard, well known, and use
  techniques that are well-suited for proof assistants. In fact, de Bruijn's
  paper that introduces de Bruijn indices was part of a mechanized confluence
  proof for the untyped lambda calculus.
\item extensions: forward reference to eta equivalence for functions in later
  section. type-directed equivalence is future work
  \end{itemize}
}

\begin{figure}[h]
\[
\begin{array}{lcll}
\mathit{Natural\ numbers}\\
[[i]],[[j]],[[n]] & \in &  [[SNat]] &  \\ \\

\mathit{Contexts}\\
[[G]]       & ::= & [[empty]]\ |\ [[G ++ A]] &  \\ \\
\mathit{Terms}\\
[[a]],[[b]],[[t]],[[p]],[[A]],[[B]] & ::= & [[Set i]]\ |\ [[var n]]\  |\ [[Void]]
                  & \mbox{universes, variables, empty type} \\
            & |   & [[Pi A B]]\ |\ [[\ A a]]\ |\ [[a b]]
                  & \mbox{function types, abstractions, applications} \\
            & |   & [[a ~ b : A ]]\ |\  [[refl]]\ |\ [[J t a b p]]
                  & \mbox{equality types, reflexivity proof, J eliminator} \\
            & |   & [[Bool]]\ |\  [[true]]\ |\  [[false]]\ % |\  [[if a b0 b1]]
                  & \mbox{boolean type, true, false} \\
            & |   & [[if a b0 b1]]
                  & \mbox{if} \\ \\
% \mathit{Renaming}\\
% [[xi]] & \in & [[SNat -> SNat]] & \\ \\
\mathit{Substitution}\\
[[rho]] & \in & [[SNat -> STm]] &
\end{array}
\]
  \caption{Syntax of \lang \scw{Where does the name come from?}}
  \label{fig:syntax}
\end{figure}

% \begin{figure}[h]
%     \[
%       \begin{array}{lll}
%         \mathit{Curried\ Addition} \\
%         add(n) & := & m \mapsto n + m \\ \\
%         \mathit{Extension ([[xi]])} \\
%         [[(xi .: j) 0]]  & := & 0 \\
%         [[(xi .: j) Suc i]]  & := & [[xi j]] \\ \\

%         \mathit{Extension ([[rho]])} \\
%         [[(rho .: a) 0]]  & := & [[a]] \\
%         [[(rho .: a) Suc i]]  & := & [[rho i]] \\ \\

%         \mathit{Up ([[xi]])} \\
%         [[up xi]] & := & (add(1) \circ [[xi]]) , 0 \\ \\

%         \mathit{Renaming} \\
%         [[var i {xi}]] & := & [[xi i]] \\
%         [[(Set i) {xi}]] & := & [[Set i]] \\
%         [[Void {xi}]] & := & [[Void]]\\
%         [[(Pi A B) {xi}]] & := & [[Pi A{xi} B{up xi}]] \\
%         [[(\ A a) {xi}]] & := & [[\ A {xi} (#a {up xi}#)]] \\
%         [[(a b) {xi}]] & := & [[a {xi} (# b {xi} #)]] \\
%         [[Bool {xi}]] & := & [[Bool]] \\
%         [[true {xi}]] & := & [[true]] \\
%         [[false {xi}]] & := & [[false]] \\
%         [[(if a b0 b1) {xi}]] & := & [[if a{xi} b0{xi} b1{xi}]] \\
%         [[(a ~ b : A) {xi}]] & := & [[ a{xi} ~ b{xi} : A{xi}]] \\
%         [[refl {xi}]] & := & [[refl]] \\
%         [[(J t a b p ) {xi}]] & := & [[J t {xi} a {xi} b {xi} p{xi}]] \\ \\

%         \mathit{Lookup} \\
%         [[(G ++ A) 0]] & := &  [[A]] \\
%         [[(G ++ A) Suc i]] & := & [[G i]] \\ \\

%         \mathit{Drop} \\
%         [[drop 0 G]] & := & [[G]] \\
%         [[drop Suc i (#G ++ A#)]] & := & [[drop i G]] \\ \\
%       \end{array}
%     \]
%   \caption{Auxiliary Functions over Syntax}
%   \label{fig:auxdef}
% \end{figure}


In this section, we present the dynamics and statics of the
dependent type theory whose logical consistency will be proven in
Section~\ref{sec:logrelproof}. For concision, we refer to this system
as \lang.

The syntax of \lang can be found in Figure~\ref{fig:syntax}.
\scw{Why so many metavariables for terms? Do you need $c$, $p$ and $t$?}
We use
the unscoped de Bruijn representation for both our Coq development and
the informal presentation in our paper since it is more amenable to
automation (Section~\ref{sec:automation}) and leaves no ambiguity
about variable freeness conditions.

%  \scw{Give an overview of the figure}
% \scw{Define a convention that separates your use of natural numbers. Sometimes they
% are universe levels and sometimes they are de Bruijn indices. Better to have separate
% metavariables for each. (And it is possible to generalize universe
% levels to structures other than natural numbers. Ask Jonathan.} \yl{resolved?}
As a dependent type theory, terms and types are collapsed into the same
syntactic category. The type $[[Set i]]$ represent universe
types and $[[var n]]$ represent de Bruijn variables. While
$[[i]],[[j]],$ and $[[n]]$ are all metavariables representing natural
numbers, we always use $[[n]]$ to represent term variables that
participate in substitution and $[[i]],[[j]]$ to represent universe levels.
Dependent functions take the form $[[Pi A B]]$ and
we use the notation $[[A -> B]]$ when the output type $[[B]]$ is not
dependent on the input variable.
Finally, we include in \lang{} the intensional identity type $[[a ~ b : A]]$ whose
proofs can be eliminated by the J-eliminator $[[J t a b p]]$, where
$[[p]]$ is an equality proof between $[[a]]$ and $[[b]]$, and $[[t]]$
is the term whose type is to be casted.
\scw{Example of what you can use identity types for? Or an example of
a program that uses J?}

% We find de Bruijn
% representation advantageous for specification since it leaves very
% little ambiguity about the variable freeness side
% conditions, making our proof more easily reproducible. Furthermore, as we discuss in
% Section~\ref{sec:automation}, de Bruijn representation is much more
% amenable to automated reasoning in proof assistants.

% \scw{Need to explain the notations in the text. What are these operations?
% What do readers need to understand about them? Help me understand
% the figure} \yl{resolved}
% \scw{As this is a tutorial paper, you'll need to explain more about how de Bruijn
% indices work.} \yl{resolved?}
% We omit most of the
% definitions of renaming and substitution and only show the definition
% of a few representative cases of substitution.
\begin{figure}[ht]
  \begin{equation*}
    \begin{split}
      \begin{array}{lll}
        % \mathit{IdentityRen} \\
        % [[id i]] & := & [[i]] \\ \\
        \mathit{IdentityTm} \\
        [[idtm n]] & := & [[var n]] \\ \\
        % \mathit{ConsRen ([[xi .: n]])} \\
        % ([[xi .: n]])([[0]]) & := & [[n]] \\
        % ([[xi .: n]])([[Suc i]]) & := & [[xi i]] \\ \\
        \mathit{ConsSubst ([[rho .: a]])} \\
        ([[rho .: a]])([[0]]) & := & [[a]] \\
        ([[rho .: a]])([[Suc n]]) & := & [[rho n]] \\ \\
        \mathit{Curried\ Add} \\
        [[up n m]] & := & \ottkw{v}_{[[n]] + [[m]]}
      \end{array}
    \end{split}
    \qquad \qquad
    \begin{split}
      \begin{array}{lll}
        % \mathit{UpRen} \\
        % [[( up xi ) 0]] & := & [[0]] \\
        % [[( up xi ) Suc i]] & := & [[ Suc ren xi i ]] \\ \\
        % \mathit{Renaming ([[a < xi >]])} \\
        % [[(Pi A B) < xi >]] & := & [[Pi A < xi > B < up xi >]] \\
        % [[(a b) < xi >]] & := & [[a < xi > (# b < xi > #)]] \\
        % \ldots \\ \\
        \mathit{Lifting} \\
        [[( up rho ) 0]] & := & [[var 0]] \\
        [[( up rho ) Suc n]] & := & [[ rho n < up 1 > ]] \\ \\
        \mathit{Substitution ([[ a { rho }  ]])} \\
        [[var n { rho }  ]] & := &  [[rho n]] \\
        [[(Pi A B) { rho }]] & := & [[Pi A { rho } B { up rho }]] \\
        [[(a b) { rho }]] & := & [[a { rho } (# b { rho } #)]] \\
        [[(\ a) { rho }]] & := & [[\ (a { up rho })]] \\
        \ldots
      \end{array}
    \end{split}
  \end{equation*}
  \caption{Auxiliary Functions over Syntax}
  \label{fig:auxdef}
\end{figure}


% Without providing
% the full definition of the renaming and substitution functions, it is
% impossible to tell the binding structure from the syntax
% alone. Therefore, we annotate the syntax in Figure~\ref{fig:syntax}
% with the de Bruijn depth of each term, though we note that the
% syntax we work with is unscoped and the choice does matter when
% we extend our logical relation to open terms in Section~\ref{sec:extension}.

% Figure~\ref{fig:auxdef} shows the auxiliary definitions over the term
% syntax, including renaming, substitution, and operations over
% the typing context or substitution.

The \lang language is expressive enough to support large
eliminations, the ability to compute a type using a term as input. For
example, the function $[[\ Bool if var 0 Bool Bool -> Bool]]$ returns
either $[[Bool]]$ or $[[Bool -> Bool]]$ depending on whether the input
is $[[true]]$ or $[[false]]$.

We adapt from \citet{autosubst2} the notations for simultaneous
renaming, substitution, and other auxiliary definitions used in
our paper, summarized in Figure~\ref{fig:auxdef}. We need those
definitions to specify the reduction relation and the typing relation
for \lang{}. The metavariable $[[rho]]$ represents substitutions,
mappings from de Bruijn indices to terms.
One example of a substitution is
the function $\ottkw{id}_{tm}$, which takes a de Bruijn index directly
injects it as a term variable. The $\uparrow^{[[n]]}$ operator is
more general and adds $[[n]]$ to the index before injecting it as a
term. The $[[(rho .: a)]]$ operation allows us to extend a substitution
$[[rho]]$ with an extra element $[[a]]$; the extended substitution maps the variable
$[[var 0]]$ to $[[a]]$ and variables $[[var Suc i]]$ to $[[rho i]]$.

The substitution operator, which takes the form $[[a {rho}]]$,
traverses the syntax of $[[a]]$ and replaces each variable $[[var i]]$
with the term $[[rho i]]$. When traversing under binders (e.g. in the
$[[(\ a) { rho }]]$ case), the $\Uparrow$ operator prevents $[[var
0]]$, the bound variable, from being replaced by
$[[rho]]$. From the definition of $[[up rho]]$, we see that it keeps
$[[var 0]]$ unchanged during substitution and replaces each $[[var
Suc i]]$ with $[[rho i {up 1}]]$. The extra shifting with $[[up 1]]$
is required so the variables in terms from the codomain of $[[rho]]$ skip over
the newly introduced binder to refer to the correct binding
location. The substitution operator is referred to as simultaneous
substitution as it substitutes all variables at once. It is possible
to recover single substitution by composing the extension operator and
the identity substitution: $[[a { b }]] := [[a { idtm .: b }]]$.

\begin{figure}[h]
\begin{minipage}{0.9\textwidth}
\drules[P]{$[[a => b]]$}{Parallel Reduction}{AppAbs, IfTrue, IfFalse, JRefl}
\drules[PS]{$[[a =>+ b]]$}{Transitive Closure of Parallel Reduction}{Refl, Step}
\drules[C]{$[[a <=> b]]$}{Coherence}{Intro}
\end{minipage}
\caption{Parallel reduction ($\beta$-rules only) and convertibility }
\label{fig:par}
\end{figure}

% \scw{motivate parallel reduction. Why are you telling us this now. Is this
%   an explanation of definitional equality and its properties?}
Before we specify the typing rules, we need to first specify its
untyped equational theory. We choose to represent the untyped
equational theory in an algorithmic style using the notion of parallel
reduction, defined in Figure~\ref{fig:par} (congruence rules are omitted). Parallel reduction takes
the form $[[a => b]]$ and we denote its transitive as $[[a =>+
b]]$. We say that two terms $[[a0]]$ and $[[a1]]$ are convertible,
denoted by the notation $[[a0 <=> a1]]$, if there exists some term
$[[b]]$ such that $[[a0 =>+ b]]$ and $[[a1 =>+ b]]$. The symmetric
notation of convertibility suggests that it is an equivalence
relation. We sketch out the sequence of lemmas required to derive this
property below and omit the details. Our technique for proving the
properties about parallel reduction is based on
\citet{takahashi-parallel-reduction}. A modern exposition of the
same technique can be found in \citet{plfa22.08}.
\begin{lemma}[Par Refl\footnote{\dotv{join.v}{Par\_refl}}]
  \label{lemma:parrefl}
  For all terms $[[a]]$, $[[a => a]]$.
\end{lemma}
\begin{lemma}[Par cong\footnote{\dotv{join.v}{par\_cong}}]
  \label{lemma:parcong}
  If $[[a0 => a1]]$ and $[[b0 => b1]]$, then $[[a0 { b0 } => a1 { b1 }]]$.
\end{lemma}
\begin{corollary}[Par subst\footnote{\dotv{join.v}{par\_subst}}]
  \label{lemma:parsubst}
  If $[[a0 => a1]]$, then $[[a0 {b} => a1 {b}]]$ for arbitrary $[[b]]$.
\end{corollary}
\begin{lemma}[Par diamond\footnote{\dotv{join.v}{par\_confluent}}]
  \label{lemma:pardiamond}
  If $[[a => b0]]$ and $[[a => b1]]$, then there exists some term
  $[[c]]$ such that $[[b0 => c]]$ and $[[b1 => c]]$.
\end{lemma}
\begin{lemma}[Coherence refl\footnote{\dotv{join.v}{Coherent\_reflexive}}]
  \label{lemma:coherencerefl}
  For all terms $[[a]]$, $[[a <=> a]]$.
\end{lemma}
\begin{lemma}[Coherence sym\footnote{\dotv{join.v}{Coherent\_symmetric}}]
  \label{lemma:coherencesym}
  If $[[a <=> b]]$, then $[[b <=> a]]$.
\end{lemma}
\begin{lemma}[Coherence trans\footnote{\dotv{join.v}{Coherent\_transitive}}]
  \label{lemma:coherencetrans}
  If $[[a0 <=> a1]]$ and $[[a1 <=> a2]]$, then $[[a0 <=> a2]]$.
\end{lemma}
From Lemma~\ref{lemma:coherencerefl}, \ref{lemma:coherencesym}, and
\ref{lemma:coherencetrans}, we conclude that coherence is indeed an
equivalence relation. It is then trivial to show that all untyped
$\beta$-equivalence rules are admissible, though we omit this proof
from our mechanization and will from now on focus on parallel
reduction since the diamond property (Lemma~\ref{lemma:pardiamond})
makes it easier to work with. A detailed argument of the equivalence
between $[[a <=> b]]$ and untyped $\beta$-equivalence can be found in
\citet{barendregt:lambda-calculi-with-types} and
\citet{takahashi-parallel-reduction}.

\begin{figure}[h]
\begin{minipage}{0.9\textwidth}
\drules[Ctx]{$[[ |- G]]$}{Context Well-Formedness}{Empty, Cons}
\drules[T]{$[[G |-  a : A]]$}{Typing}{Var, Set, Pi, Abs, App, Conv,
  Refl, Eq, J, If, Bool, True, False, Void}
\end{minipage}
\caption{Syntactic typing for \lang}
\label{fig:typing}
\end{figure}
% Figure~\ref{fig:par} shows the definition of the parallel reduction
% relation, which takes the form $[[a => b]]$. We use $[[a =>+ b]]$ to
% represent its transitive and reflexive closure, which in turn allows us to define
% the coherence relation $[[a <=> b]]$.\scw{where is the terminology ``coherence''
% from? I'm not familiar with it. Maybe you can replace it with ``definitional
% equivalence'' as that is how it is used in \lang?}
% We say that two terms $[[a]]$
% and $[[b]]$ are coherent if they can eventually reduce to some common
% term $[[c]]$ through parallel reduction. The symmetric notation of
% coherence suggests\scw{but you prove it below?} it is an equivalence relation.

% We sketch out some key properties about parallel reduction and
% coherence without giving their proofs. Our technique for establishing
% those results is based on

% \scw{cite barendregt?}
% \yl{resolved}

% TODO: remove the lengthy discussion below

% Now, we prove that coherence is indeed an equivalence relation.

% First, we show that coherence is reflexive through the following
% sequence of lemmas.


% Lemma~\ref{lemma:parrefl} can be proven by structural induction over
% the term $[[a]]$. Lemmas~\ref{lemma:parsrefl} and \ref{lemma:coherencerefl}
% immediately follow as corollaries of Lemma~\ref{lemma:parrefl}.

% The reflexivity of parallel reduction enables us to embed rules from
% call-by-name semantics into parallel reduction, as the following lemma
% shows.
% \begin{lemma}[Par AbsCbn\footnote{\dotv{join.v}{P\_AppAbs\_cbn}}] For all $[[A]], [[a]],$ and $[[b]]$,
%   \label{lemma:parabscbn}
%   $[[(\ A a) b => b {a}]]$
% \end{lemma}
% \begin{proof}
%   Immediate from Lemma~\ref{lemma:parrefl} and \rref{P-AppAbs}.
% \end{proof}

% Symmetry of coherence immediately falls from its definition.

% Before we can prove transitivity, we need to show that parallel
% reduction satisfies the diamond property.


% The congruence property (Lemma~\ref{lemma:parcong}) can be proven by
% structural induction over the derivation of $[[a0 => a1]]$.
% Likewise, Lemma~\ref{lemma:pardiamond} can be proven by structural induction
% over the derivation of $[[a => b0]]$. The \rref{P-AppAbs} case requires
% the use of Lemma~\ref{lemma:parcong}.

% From Lemma~\ref{lemma:parcong} and \ref{lemma:parrefl}, we recover the
% single substitution property as a simple corollary.


% A relation that satisfies the
% diamond property must also be confluent, meaning that its transitive
% and reflexive closure is confluent.
% \begin{lemma}[Par confluent\footnote{\dotv{join.v}{pars\_confluent}}]
%   \label{lemma:parconfluent}
%   If $[[a =>+ b0]]$ and $[[a =>+ b1]]$, then there exists some term
%   $[[c]]$ such that $[[b0 =>+ c]]$ and $[[b1 =>+ c]]$.
% \end{lemma}
% While $[[a =>+ b]]$ is defined as the transitive closure of $[[a => b]]$,
% it coincides with the transitive and reflexive closure of $[[a => b]]$ since $[[a => b]]$ is reflexive (Lemma~\ref{lemma:parrefl}).

% The transitivity of the coherence relation follows as a corollary of
% Lemma~\ref{lemma:parconfluent}.
% By the definition of coherence, there exists some term $[[b]]$ such that $[[a0 =>+ b0]]$,
% $[[a1 =>+ b0]]$ and some term $[[b1]]$ such that $[[a1 =>+ b1]]$ and
% $[[a2 =>+ b1]]$. By Lemma~\ref{lemma:parconfluent}, there exists some
% term $[[c]]$ such that $[[b0 =>+ c]]$ and $[[b1 =>+ c]]$. It sufficies
% to show that $[[a0 =>+ c]]$ and $[[a2 =>+ c]]$, both of which
% trivially hold since the transitive closure $[[a =>+ b]]$ is transitive.
% This concludes the proof that coherence is an equivalence relation.
% \begin{lemma}[Coherence Equivalence]
%   \label{lemma:coherenceequiv}
%   The relation $[[a <=> b]]$ satisfies reflexivity, symmetry, and
%   transitivity and therefore is an equivalence relation.
% \end{lemma}


Figure~\ref{fig:typing} gives the full typing rules for
\lang{}. The premises wrapped in \colorbox{lightgray}{gray} boxes can be shown to be
admissible syntactically, though some of them are required to
strengthen the inductive hypothesis of the fundamental theorem.
% \scw{Is the precondition for T-ABS really admissible? Isn't it required
% to ensure predicativity? Have you proved it? Have you proved regularity?}
% \yl{I proved regularity. \Rref{T-Abs} is admissible if cumulativity
%   was formulated correctly (which wasn't the case in the version
%   of the paper you read). I revised \rref{T-Univ} so the premise is
%   not admissible }
% \scw{Do you have a formation rule for identity types?}
% \yl{Added}

In \rref{T-Var}, $[[G n]]$ is the partial function defined
by the equations $[[ (G ++ A)  0 ]] := [[A]]$ and $[[ (G ++ A) Suc
n ]] := [[G n]]$.
The precondition $[[n < | G | ]]$, where $[[ | G |
]]$ represents the length of the context $[[G]]$, ensures that $[[G
n]]$ has a defined output. The type $[[G n]]$ needs to be shifted
by $[[Suc n]]$ since the types stored in the context $[[G]]$ are
scoped differently. In the typing judgment $[[G |- a : A]]$, we want
both $[[a]]$ and $[[A]]$ to have the same scope. However, the closer a
type is to the head of $[[G]]$, the smaller de Bruijn it has since
there is less variables in the context it can refer to (see \rref{Ctx-Cons}). Shifting $[[G
n]]$ by $[[Suc n]]$ weakens the type so it is scoped consistently with
the full context $[[G]]$ rather than a truncated version of $[[G]]$.

\Rref{T-Conv} uses the convertibility relation from earlier
as our equality judgment for type conversion. The use of an untyped
relation for type conversion is reminiscent of Barendregt's Pure Type
Systems~\citet{barendregt1991introduction} and makes our formulation different
from languages such as MLTT~\citep{Martin-Lof-1973}, where the judgmental equality
takes the form $\Gamma \vdash a \equiv b : A$, from which one can
usually derive  $[[G |- a : A]]$ and $[[G |- b : A]]$ after proving
subject reduction.

\citet{siles2012pure} shows the equivalence of Barendregt's
Pure Type System~\citep{barendregt1991introduction}, which employs
untyped equality, and its variant that uses typed judgmental
equality. This assures us that we do not lose much generality working
with a system with untyped conversion. We include a detailed
discussion in Section~\ref{sec:relatedwork} on how type-directed and
untyped equality affect the applicability of our technique.

% As a result, there is no loss of generality from

% It is trivial to embed a system with judgmental
% equality to a system with untyped equality by erasing typing
% information. As a result, it is easy to port our consistency result from our
% type system to a variant with typed judgmental equality
% as long as the typed system does not include $\eta$ laws
% that would require type annotations (e.g. the $\eta$-law for unit
% types).
% and we discuss in Section~\ref{sec:extension} how we can extend
% our proof to handle those rules.
\yl{Unresolved: is it ok to say our system's conversion rule is untyped like
Coq?}
% \scw{Maybe move more of this paragraph and the next to the discussion/related
%   work section, and add a forward pointer here.}
% \scw{Just say that like Coq, the definition of the system uses untyped
% equality}

% Working with a system with untyped equality has the huge benefit that
% the confluence result for untyped parallel reduction
% (Lemma~\ref{lemma:pardiamond}) is easily derivable without having to
% resort to the complex syntatic (resp. semantic) technique from
% \citet{siles2012pure} (resp. \citet{decagda}) to resolve
% the circularity of subject reduction and $\Pi$-injectivity.
% Section~\ref{sec:extension} explains how we
% generalize our technique to include $\eta$-law for functions and
% show the existence of normal form for well-typed (open and closed)
% terms, achieving a similar level of expressiveness of the type system
% and strength of metatheoretic property as \citet{decagda}.

% Finally, since our system has an infinite universe hierarchy, we can
% present the system à la Russell by using the same judgment form
%$[[G |- a : A]]$ regardless of whether $[[a]]$ is a term or a type. There
% is no need to distinguish between big types and small types
% and duplicate our typing specification.
% \scw{Is there an advantage for Tarski universes even with infinite
% hierarchy? or no?}


% , the
% statement that $\Gamma \vdash [[Pi A0 B0]] \equiv [[Pi A1 B1]]$
% implies $\Gamma \vdash [[A0]] \equiv [[A1]]$ and
% $\Gamma, [[A0]]\vdash [[B0]] \equiv [[B1]]$.



% working with a system with untyped equality not only preserves the
% same level of generality,
% Of course,
% but also enables us to derive confluence
% (Lemma~\ref{lemma:parconfluent}) early on without having to use the
% intricate techniques from \citet{lemma:}







% TODO, where terms ... and ... are known to be
% well-typed. The equivalence of such systems and a system that uses
% untyped equality are explored in detail in ...

% Without fancy eta laws, it is easy to embed a typed language into an
% untyped language.


% We note that a more conventional presentation of
% \rref{T-Conv} would instead use full beta reduction as the base for
% the definition of coherence. However, since full beta reduction
% doesn't satisfy the diamond property, one typically needs parallel
% reduction as an auxilliary definition to derive the confluence of full
% beta reduction. Our formulation of \lang through parallel reduction
% is slightly more economical.

\section{Logical Relation}
% \scw{This section pre-supposes that we want to define a logical relation,
% but doesn't precisely state what we want to use it to prove, and why a logical
% relation is suitable. (And why the property you want to prove is difficult to
% show!) Should add more motivation here.}
\scw{We need to explicitly point out that the key ideas of this paper are
  discussed, here, in this section.
  We need to explicitly remark on why logical relations are difficult to
  define for dependent type theory and explain why this setting is more
  difficult than with simple types (STLC) or with polymorphic types (System F).
  \begin{itemize}
  \item Dependent function types (result type mentions argument value, so can't define
    relation by recursion over type structure)
  \item Definitional equality (not all types look like types)
  \item Identity types(?)
  \end{itemize}
  Should we be more explicit in our comparison with Girard's trick for polymorphic type?
  There, the definition stays recursive because it doesn't substitute for the variables
  in the function types. But that approach is not available in this setting, because not
  all quantified things are types. And we might need that information to interpret, say,
  identity types in the right way.
}
\scw{ We also need to explicitly point out that our logical relation is untyped.
  This has two benefits: it allows semantic typing to be meaningful independent from
  syntactic typing (cite Derek, forward reference to next section) and it avoids
  significant bookkeeping, especially in the case of Kripke logical relations (we need to define
  what these are).
  Is there a cost to an untyped relation?
}
Before we define our logical relation, we first formally specify the
consistency property that we want to prove.
\begin{theorem}[Logical Consistency]
  \label{theorem:consistency}
  The judgment $[[empty |- a : Void ]]$ is not derivable.
\end{theorem}
The property can be formulated in a simply typed language, where
$[[Void]]$ is similarly defined as a type that has no term. A related
property, referred to as the termination property (for closed terms),
is commonly used in introductory materials such as
\citet{skorstengaard2019introduction}, \citet{pierce2002types}, and
\citet{harpertait} to motivate the need for a logical relation.

A naive attempt to proving Theorem~\ref{theorem:consistency} by
induction on the derivation $[[empty |- a : Void]]$ would succeed at
almost all cases except for \rref{T-App}. In the application
case, we are given $[[empty |- b : Pi A B]]$ and $[[empty |- a : A]]$, and
the equality that $[[B {a} = Bool]]$. Our goal is to show that
$[[empty |- b a : Void]]$ is not possible. However, note that there is
nothing we know of $[[b]]$ or $[[a]]$ from the induction hypothesis
because neither $[[Pi A B]]$ nor $[[A]]$ is equal to $[[Bool]]$.
We have no way of deriving a contradiction from $[[empty |- b a :
Void]]$. The takeaway from this failed attempt is that, in order to
derive the consistency, we need to know something about types other
than $[[Void]]$. From a pragmatic point of view, proof by logical
relation can be seen as a sophisticated way of strengthening the
induction hypothesis. From the strengthened property, the fundamental
theorem, we will be able to derive consistency as a corollary.

The complexity of applying proof by logical relation to dependent types stem
from the fact that the logical relation is much harder to define. In
simply typed languages, the logical relation is defined as a recursive
function over the type $[[A]]$. In dependent types, the type
$[[A]]$ can take the form $[[(\ var 0) Bool]]$. To assign meaning to
this type, we need to first reduce it to $[[Bool]]$. However, we
cannot write a function that performs the reduction because we do not
know the termination of well-typed terms a priori. As a result, we
define the logical relation as an inductively defined relation,
reminiscent of how we specify the reduction graph of a partial
function; the functionality of the relation can later be recovered in Lemma~\ref{lemma:logreldeter}.

\label{sec:logreldep}
\begin{figure}[h]
\drules[I]{$[[Interp I i A S]]$}{Logical Relation}{Void, Bool, Eq, Pi, Set, Red}
\caption{Logical relation for \lang}
\label{fig:logrel}
\end{figure}
The logical relation for \lang{}, which takes the form $[[Interp I i A
S]]$, is defined as an inductively generated relation (Figure~\ref{fig:logrel}).
% The logical relation takes the form $[[Interp I i A S]]$.
Metavariables $[[A]]$ and $[[i]]$ stand for terms and natural
numbers respectively, as introduced earlier in
Figure~\ref{fig:syntax}.
\scw{Many introductory texts define the relation as a recursive function
over type structure, or step-indices. You use an inductive relation instead, why?}
% \scw{Can we view this inductive relation as the graph of the partial function
% that is defined recursively over types?} \yl{reolsved}
% \scw{What is this form extensible too? impredicative quantification? recursive
% types? } \yl{resolved? impredicativity is hard}
\scw{Is it worth observing here that this definition is not over sets of typed
terms. That it characterizes all terms that look like booleans (i.e. evaluate to
true or false) or all terms that look like proofs (i.e. evaluate to refl). The
fact that there is no connection between p and a and b in the I-Eq case is strange
looking. Need to explain.  }
The metavariables $[[I]]$ and $[[S]]$ are
sets with the following signatures.
\begin{equation*}
  \begin{split}
    [[I]] &\in [[ { j | j < i  } ->  PowerSet STm ]] \\
    [[S]] &\in [[PowerSet STm]]
  \end{split}
\end{equation*}
The notation $[[PowerSet STm]]$ denotes the powerset of the set of
\lang{} terms.
The function $[[I]]$ is a family of sets of terms indexed by
natural numbers strictly less than the parameter $[[i]]$, which
represents the current universe level.  In \rref{I-Set}, function
$[[I]]$ is used to define the meaning of
universes that are strictly smaller than the current level $[[i]]$. The
restriction $[[j < i]]$ in \rref{I-Set} is crucial for our system to
be predicative and we will explain the reason shortly.

To tie the knot and obtain an interpretation of all universe levels,
we define in Figure~\ref{fig:logrelrec} the final version of our interpretation judgment recursively
using the well-foundedness of $<$ relation on natural
numbers (recall that
the parameter $[[I]]$ of $[[Interp I i A S]]$ takes only natural
numbers strictly less than $[[i]]$ as its input).
The judgment $[[InterpR i A S]]$ now reads that the type $[[A]]$ is a
level-$[[i]]$ type \emph{semantically} inhabited by terms from the set
$[[S]]$.

\begin{figure}[h]
\begin{equation*}
    [[InterpR i A S]] := [[ Interp I i A S  ]], \text{where } [[I i]] := [[{A | exists S , InterpR i A S}]]
\end{equation*}
\caption{Logical relation for all universe levels}
\label{fig:logrelrec}
\end{figure}
The definition of in Figure~\ref{fig:logrelrec} explains how the $[[j
< i]]$ constraint in \rref{I-Set} makes our system predicative; the
interpretation of the $[[i]]_{th}$ universe is only dependent on
universes at strictly lower than $[[i]]$, which have been defined earlier.
Removing the ordering constraint would result in a
system where one can encode Girard's
paradox~\citep{girard-thesis}. Our proof would no longer work with the
restriction removed since the definition of $[[InterpR i A S]]$ would
not be well-founded when $[[Interp I i A S]]$ calls $[[I]]$ on
universe levels greater than or equal to $[[i]]$, which are yet to be defined.

By unfolding the definition in Figure~\ref{fig:logrelrec}, we
show that the same introduction rules for $[[Interp I i A S]]$ are
admissible for $[[InterpR i A S]]$, by
instantiating $[[I]]$ with $[[I i]] := [[{A | exists S , InterpR i A
  S}]]$, the same function $[[I]]$ used in the definition of $[[InterpR i A
S]]$. We give as example the following rules.
\begin{center}
\drule[]{IR-Void} \qquad \drule[]{IR-Set}
\end{center}

In most informal presentations, instead of defining the logical
relation in two steps as we have shown above, the rules for $[[InterpR
i A S]]$ are given directly, with the implicit understanding that the
relation is an inductive definition nested inside a recursive
function over the universe level $[[i]]$. We choose
the more explicit definition not only because it is directly definable
in existing proof assistants where inductive definitions must appear
at the top level, but also because it makes clear the induction
principle we are allowed to use when reasoning about $[[InterpR i A
S]]$.

% The paragraph below might be useful but I don't know how to phrase
% it well

% The most general format of the induction principle over
% $[[InterpR i A S]]$ is first by strong induction over the universe level $[[i]]$
% followed by structural induction over $[[Interp I i A S]]$. As
% examples, ... (\rref{I-Set} and \rref{I-Red}).

For the majority of the properties we are about to prove in this section, we
do not need any information about the parameterized function $[[I]]$.
Each property about $[[InterpR i A S]]$ follows as a corollary of
a property about $[[Interp I i A S]]$ with no or few assumptions imposed on
$[[I]]$. As a result, we usually state our lemmas in terms of
$[[Interp I i A S]]$ without duplicating them in terms of $[[InterpR i
A S]]$.

To derive consistency, it suffices to restrict $[[S]]$ to the set of
terms that reduce to closed terms. \Rref{I-Void, I-Bool} are
unsurprising; when considering only closed terms, the empty type
should not be inhabited and therefore corresponds to the empty set,
whereas the boolean type is semantically inhabited by terms that
evaluate to the boolean values $[[true]]$ or $[[false]]$. \Rref{I-Eq}
says that an equality type $[[a ~ b : A]]$ corresonds to the
set of terms that evaluate to $[[refl]]$ when $[[a <=> b]]$ holds and
otherwise corresponds to the empty set. Side conditions like $[[a <=>
b]]$ are typically required for indexed types, of which equality types
are an instance. \Rref{I-Par} enables us to reduce our types in order
to assign meanings. Recall the type expression $[[(\ var 0)
Bool]]$. \Rref{I-Par} says to know that
$[[Interp I i  (\ var 0) Bool S ]]$ for some $[[S]]$, it suffices to
show that $[[Interp I i Bool S]]$ since $[[(\var 0) Bool =>
Bool]]$. The derivation that $[[Interp I i (\ var 0) Bool { a | a =>+
  true \/ a =>+ false }]]$ therefore follows by composing \rref{I-Par}
and \rref{I-Bool}.


\Rref{I-Pi} is the most interesting. To explain what it means, we
need to perform a few steps of transformations to its precondition.
The precondition consists of a
mysterious relation $[[R]]$ over the set $[[S]]$, an interpretation
of the type $[[A]]$, and returns a subset of terms. $[[R]]$ is further
subject to the following two constraints:
\begin{itemize}
\item $[[forall a, (# exists S0  , ( a , S0 ) in R #)]]$
\item $[[forall a, forall S0, (# ( a , S0 ) in R implies Interp I i B { a } S0 #)]]$
\end{itemize}
The first condition allows us to induce a function $[[F in S ->
PowerSet STm]]$ such that $[[(a , F a) in R]]$. Then we can easily
show that $[[forall a, (# a in S implies Interp I i B { a } F a #)]]$.

For the other direction, given a function $[[F]]$ satisfying the
property $[[forall a, (# a in S implies Interp I i B { a } F a #) ]]$, it
is possible to  define a relation $[[R]]=[[
{ ( a , F a )  | a in S }]]$. It is easy to verify that $[[R]]$ satisfy
the the constraint required in the precondition of \rref{I-Pi}.

Furthermore, the skolemization process allows us to conclude the
following equivalence:
\[ \exists F, [[forall a, (# a in S implies Interp I i B { a } F a #)]] \iff [[forall a, (# a in S implies (# exists S0 , Interp I i B {a} S0 #) #)]]  \]
% Ignoring the content below the horizontal bar of
% the derivation, we claim the statements from the precondition are equivalent to
% the conjunction of the following statements:
% \begin{itemize}
% \item $[[Interp I i A S]]$
% \item $\forall [[a]], \text{ if }[[a in S]]\text{, then } \exists
%   [[S0]]\text{, } [[Interp I i B { a } S0 ]] $
% \end{itemize}
% In general, let $R$ be a binary relation over the sets $[[A]]$ and
% $[[B]]$, it easy to verify the following equivalence, which is used to
% justify the skolemization process~\citep{skolemization}.
% \scw{Is this true constructively? If not, is that ok?}
% \[\forall a \in A, \exists b \in B \text{ such that } (a,b) \in R
%   \iff \exists F \in A \rightarrow B \text, \forall a \in A, (a, F(a))
%   \in R\]
% The left-hand side is equivalent to the right-hand side, but has no
% mentioning of any functions.
The precondition of \rref{I-Pi} therefore can be formulated as the
following statements:
\begin{itemize}
\item $[[Interp I i A S]]$
\item $[[forall a, (# a in S implies (# exists S0 , Interp I i B {a} S0 #) #)]]$
\end{itemize}
From this alternative formulation, we can more easily tell what is
happening in \rref{I-Pi}: the
function type $[[Pi A B]]$ has an interpretation if its input
type $[[A]]$ can be
interpreted as some set $[[S]]$, and for all terms $[[a in S]]$, the
type $[[B {a}]]$, obtained by substituing $[[a]]$ into the output type
$[[B]]$, has some semantic interpretation.

If we look at $[[Interp I i Pi A B { b | forall a, forall S0, (# ( a , S0 ) in R implies b a in S0 #) }]]$, the conclusion of \rref{I-Pi}, we see why the
presentation with an explicit $[[R in S * PowerSet STm]]$ is
useful. We want to state the fact that $[[B {a}]]$ has a semantic
interpretation of some set $[[S0]]$, but we also want to refer to the
set $[[S0]]$ when we talk about the set that $[[Pi A B]]$ corresponds
to. With the relation $[[R]]$ in scope, we can refer to the
witness sets $[[S0]]$ such that $[[Interp I i B {a} S0]]$ for $[[a in S]]$.
With the alternative representation that is free of the relation $[[R]]$, we
might want to reformulate our logical relation in the following more
concise but equivalent form, whose admissibility follows directly from
\rref{I-Pi}.
\begin{center}
  \drule[]{I-PiAlt}
\end{center}
\begin{lemma}
  \label{lemma:piintroalt}
  \Rref{I-PiAlt} is admissible.
\end{lemma}
\begin{proof}
Immediate from \rref{I-Pi} with $[[R]]$ instantiated to the relation $[[{ (a
, S0 ) | a in S , Interp I i B { a } S0 }]]$.
\end{proof}

Unfortunately, we cannot define the function case of our logical
relation directly using \rref{I-PiAlt} since it not only violates the
syntactic strict positivity constraint required in proof assistants,
but is genuinely non-monotone when written as an endofunction over the
domain of relations.
Intuitively, the failure of monotonicity stems from the fact
that the witness picked in the precondition is not necessarily the
same witness being referred to in the post condition. While it might
be possible to restrict the domain with additional constraints such as
functionality and inversion properties, we opt for our current
formulation of \rref{I-Pi} so we immediately obtain a
well-defined inductive relation and a usable induction principle. The
slight disadvantage of \rref{I-Pi} is that we need to construct the
function $[[R]]$ each time we apply it, though this is mitigated by
the immediate admissibility of \rref{I-PiAlt}.

In the rest of the section, we prove four important facts about
our logical relation: irrelevance (Lemma~\ref{lemma:logrelcoherence}),
functionality (Lemma~\ref{lemma:logreldeter}), cumulativity
(Lemma~\ref{lemma:logrelcumulativity}), and the backward closure
property (Lemma~\ref{lemma:logrelbackclos}).

First, we prove a family of simple properties, which we refer to as
inversion principles for our logical relation. Given $[[Interp I i A
S]]$ where $[[A]]$ is in some head form such as $[[Bool]]$ or $[[Pi A0
B0]]$, the inversion lemma allows us to say something about the set
$[[S]]$. Its proof is simple, but we sketch out the case for
functions to help readers confirm their understanding of \rref{I-Pi}.
\begin{lemma}[Inversion of the logical relation]
  \label{lemma:interpinv}\leavevmode
  \begin{enumerate}
  \item\footnote{\dotv{semtyping.v}{InterpExt\_Void\_inv}} If $[[Interp I i Void S]]$, then $[[S = emptyset]]$.
  \item\footnote{\dotv{semtyping.v}{InterpExt\_Bool\_inv}} If $[[Interp I i Bool S]]$, then $[[S = { a | a =>+ true \/ a =>+ false   }]]$.
  \item\footnote{\dotv{semtyping.v}{InterpExt\_Eq\_inv}} If $[[Interp I i a ~ b : A S]]$, then $[[S = { p | p =>+ refl , a <=> b  }]]$.
  \item\footnote{\dotv{semtyping.v}{InterpExt\_Fun\_inv}} If $[[Interp I i Pi A B S1]]$, then there exists $[[S]],[[R]]$ such that:
    \begin{itemize}
    \item $[[Interp I i A S ]]$
    \item $[[R in S * PowerSet STm]]$
    \item $[[forall a, (# a in S implies (# exists S0 , (a , S0) in R #) #)]]$
    \item $[[forall a, forall S0, (# ( a , S0 ) in R implies Interp I i B { a } S0 #)]]$
    \item $[[S1 = { b | forall a, forall S0, (# ( a , S0 ) in R implies b a in S0 #) }]]$
    \end{itemize}
  \item\footnote{\dotv{semtyping.v}{InterpExt\_Univ\_inv}} If $[[Interp I i Set j S]]$, then $[[j < i]]$ and $[[S = I j]]$.
  \end{enumerate}
\end{lemma}
\begin{proof}
  As mentioned earlier, we only show the inversion property for the
  function type.
  We start by inducting over the derivation of $[[Interp I i Pi A B S]]$. There
  are only two possible cases we need to consider.
  \begin{description}
  \item[\Rref{I-Pi}:] Immediate.
  \item[\Rref{I-Red}:] We are given that $[[Interp I i Pi A B S1]]$.
    We know that there exists some $[[A0]]$ and
    $[[B0]]$ such that $[[Pi A B => Pi A0 B0]]$ and $[[Interp I i Pi
    A0 B0 S1]]$. From the
    induction hypothesis, there exists $[[S]]$ and $[[R]]$ such that :
    \begin{itemize}
    \item $[[Interp I i A0 S ]]$
    \item $[[R in S * PowerSet STm]]$
    \item $[[forall a, (# a in S implies (# exists S0 , (a , S0) in R #) #)]]$
    \item $[[forall a, forall S0, (# ( a , S0 ) in R implies Interp I i B0 { a } S0 #)]]$
    \item $[[S1 = { b | forall a, forall S0, (# ( a , S0 ) in R implies b a in S0 #) }]]$
    \end{itemize}
    By inverting the derivation of $[[Pi A B => Pi A0 B0]]$, we derive $[[A => A0]]$ and
    $[[B => B0]]$. By Lemma~\ref{lemma:parsubst}, we have $[[B {a} => B0 {a} ]]$ for all
    $[[a]]$. As a result, by \rref{I-Red}, the same $[[S]]$ and
    $[[R]]$ additionally satisfies the following properties:
    \begin{itemize}
    \item $[[Interp I i A S ]]$
    \item $[[forall a, forall S0, (# ( a , S0 ) in R implies Interp I i B { a } S0 #)]]$
    \end{itemize}
    These properties are exactly what we need to finish the proof.
  \end{description}
\end{proof}

\Rref{I-Red} bakes into the logical relation the backward preservation
property. That is, given $[[Interp I i A S]]$, if $[[B =>+ A]]$, then
$[[Interp I i B S]]$ also holds. The following property shows that
preservation holds in the usual forward direction too.
\begin{lemma}[Preservation of the logical relation\footnote{\dotv{semtyping.v}{InterpExt\_preservation}}]
  \label{lemma:interppreservation}
  If $[[Interp I i A S]]$ and $[[A => B]]$, then $[[Interp I i B S]]$.
\end{lemma}
\begin{proof}
  We carry out the proof by induction over the derivation of $[[Interp
  I i A S]]$.

  The only interesting case is \Rref{I-Red}. Given that
  $[[A => B0]]$ and $[[Interp I i B0 S]]$, we need to show
  for all  $[[B1]]$ such that $[[A => B1]]$, we have $[[Interp I i B1
  S]]$. By the diamond property of parallel reduction
  (Lemma~\ref{lemma:pardiamond}), there exists some term $[[B]]$ such
  that $[[B0 => B]]$ and $[[B1 => B]]$. By the induction hypothesis,
  we deduce $[[Interp I i B S]]$ from $[[B0 => B]]$ and $[[Interp I i
  B0 S]]$. By \rref{I-Par} and $[[B1 => B]]$, we conclude that
  $[[Interp I i B S]]$.

  The remaining cases all fall from induction hypotheses and basic
  properties about convertibility and parallel reduction we have
  established in Section~\ref{sec:spec}.
\end{proof}
From Lemma~\ref{lemma:interppreservation} and \rref{I-Red}, we can easily
derive the following corollary that two convertible types can always interpret
into the same set. We adopt the terminology from \citet{martin-lof-a-la-coq}
and refer to this property as irrelevance.
\begin{corollary}[Irrelevance of logical relation\footnote{\dotv{semtyping.v}{InterpUnivN\_Coherent}}]
  \label{lemma:logrelcoherence}
  If $[[Interp I i A S]]$ and $[[A <=> B]]$, then $[[Interp I i B S]]$.
\end{corollary}
% \scw{Need a transition here}

Since the definition of our logical relation is an inductive relation,
it is not immediately obvious why each type $[[A]]$ can only uniquely
corresponds to one set $[[S]]$. The following lemma shows that our
logical relation is indeed functional.
\begin{lemma}[Logical relation is functional\footnote{\dotv{semtyping.v}{InterpExt\_deterministic}}]
  \label{lemma:logreldeter}
  If $[[Interp I i A S0]]$ and $[[Interp I i A S1]]$, then $[[S0 = S1]]$.
\end{lemma}
\begin{proof}
  The proof proceeds by induction over the derivation of the first
  premise $[[Interp I i A S0]]$.
  All cases that are not \rref{I-Red} follow immediately from the
  Lemma~\ref{lemma:interpinv}.

  For \rref{I-Red}, we are given that there exists some $[[B]]$ such
  that $[[A => B]]$ and $[[Interp I i B S0]]$. Our goal is to show
  that given $[[Interp I i A S1]]$ for some $[[S1]]$, we have $[[S0 =
  S1]]$. By the preservation property
  (Lemma~\ref{lemma:interppreservation}),
  we know that $[[Interp I i B S1]]$ since $[[A => B]]$. The statement
  $[[S0 = S1]]$ then immediately follows from the induction hypothesis.
\end{proof}

Lemma~\ref{lemma:logreldeter} enables us to show the following
improved inversion lemma for function types whose statement is free of
the relation $[[R]]$, analogous to the admissible rule \rref{I-PiAlt}.
\begin{lemma}[Pi Inv Alt\footnote{\dotv{semtyping.v}{InterpExt\_Fun\_inv\_nopf}}]
  \label{lemma:piinvalt}
  Suppose $[[Interp I i Pi A B S]]$, then there exists some $[[S0]]$
  such that the following constraints hold:
  \begin{itemize}
  \item $[[Interp I i A S0]]$
  \item $[[forall a, (# a in S0 implies (# exists S1 , Interp I i B {a}
    S1 #) #)]]$
  \item $[[S = { b | forall a, (# a in S0 , forall
    S1, (# Interp I i B {a} S1,  b a in S1 #) #) }]]$
  \end{itemize}
\end{lemma}
\begin{proof}
  Immediate from Lemmas~\ref{lemma:interpinv} and \ref{lemma:logreldeter}.
\end{proof}

The next lemma shows that our logical relation satisfies
cumulativity. That is, if a type has an interpretation at a lower
universe level, then we can obtain the same interpretation at a higher
universe level.
\begin{lemma}[Logical relation cumulativity\footnote{\dotv{semtyping.v}{InterpExt\_cumulative}}]
  \label{lemma:logrelcumulativity}
  If $[[Interp I i0 A S]]$ and $[[i0 < i1]]$, then $[[Interp I i1 A S]]$.
\end{lemma}
\begin{proof}
  Trivial by structural induction over the derivation of $[[Interp I
  i0 A S]]$.
\end{proof}
Note that in the statement of Lemma~\ref{lemma:logrelcumulativity}, we
implicitly assume that $[[I]]$ is defined on the set of natural
numbers less than $[[i1]]$.

\begin{corollary}[Logical relation is functional with different levels\footnote{\dotv{semtyping.v}{InterpExt\_deterministic'}}]
  \label{lemma:logreldeterhet}
  If $[[Interp I i0 A S0]]$ and $[[Interp I i1 A S1]]$, then $[[S0 = S1]]$.
\end{corollary}
\begin{proof}
  Immediate from Lemma~\ref{lemma:logreldeter} and
  \ref{lemma:logrelcumulativity}.
\end{proof}

We say that a set of terms $[[S]]$ is closed under expansion if given
$[[a in S]]$, then $[[b in S]]$ for all $[[b => a]]$.
The final property we want to show is that the output set $[[S]]$ from
the logical relation is closed under expansion. Unlike the previous
lemmas, we directly state the lemma
in terms of $[[InterpR i A S]]$ rather than $[[Interp I i A S]]$
because we need to know something about $[[I]]$ for this property to
hold in the \rref{I-Set} case.

\yl{Can lift this lemma somewhere earlier in the section since it doesn't really
  depend on anything}
\begin{lemma}[Interpreted sets are closed under expansion\footnote{\dotv{semtyping.v}{InterpExt\_back\_clos}}]
  \label{lemma:logrelbackclos}
  If $[[InterpR i A S]]$, then the set $[[S]]$ is closed under expansion.
\end{lemma}
\begin{proof}
  By the definition of $[[InterpR i A S]]$ from
  Figure~\ref{fig:logrelrec}, we unfold $[[InterpR i A S]]$ by one
  step into $[[ Interp I i A S  ]]$ where $[[I i]] := [[{A | exists S
    , InterpR i A S}]]$.
  We then proceed by induction over the derivation of $[[Interp I i A S]]$.

  All cases are trivial except for the \rref{I-Set} case, where we
  want to show that the set $[[I j]]$ is closed under expansion for
  all $[[j < i]]$. However, by the definition of $[[I]]$, we know that
  $[[A in I j]]$ if only if there exists some $[[S]]$ such that
  $[[Interp I i A S]]$. By \rref{I-Par}, we must also have $[[B in I
  j]]$ for all $[[B => A]]$.
\end{proof}

\section{Semantic Typing and Consistency}
\label{sec:logrelproof}
\yl{todo: rename all variables from i,j to n}
\scw{Would it make sense to define the notation $a \in [\![A]\!]^i$ when
there exists some $S$ such that $[[InterpR i A S]]$ and $[[a in S]]$ ?}
% \begin{figure}[h]
% \[
% \begin{array}{lcl}

%       [[rho |= G]] &:= & \forall i\ j\ S, \text{ if }[[i < |G|]]\text{ and
%                      } [[InterpR j (G i < up Suc i > ) { rho } S ]] \text{, then } [[rho i in S]] \\
%       [[G |= a : A]] &:= & \forall [[rho]], \text{ if }[[rho |= G]]
%    \text{ then there exists some } [[j]] \text{
%                        and } [[S]] \text{ such that } [[InterpR j A {rho} S]]
%        \text{ and } [[a {rho} in S]] \\
%       [[|= G]] &:= & \forall [[i < |G|]], \exists [[j]], [[drop Suc i G |= G i : Set j]]
% \end{array}
% \]
%   \caption{Semantic Typing for \lang}
%   \label{fig:semtyping}
% \end{figure}x

% The logical relation we define in Figure~\ref{fig:logrel} does not
% include cases for variables. Likewise, for the base types such as
% boolean and equality, the output set $[[S]]$ contains only terms that
% evaluate to closed terms.

In this section, we show that all closed, well-typed terms are contained
within their type-indexed sets. In other words, $[[empty |- a : A]]$ implies
$[[InterpR i A S]]$ and $[[a in S]]$.  This result gives us consistency
because we know that $[[InterpR i Void S]]$ is defined, and that $[[S]]$ must
be the empty set. Therefore, if there were some closed, well-typed term of type
$[[Void]]$, it would need to be a member of the empty set, a contradiction.

To prove this result, we define a notion of semantic typing based on the
logical relation we have defined in Section~\ref{sec:logreldep} and prove the
fundamental lemma, which states that syntactic typing implies semantic typing.
Semantic typing extends our logical relation from being a (type-indexed)
family of predicates on closed terms, to a type-indexed family of predicates
on open terms. 

The necessity of semantic typing as an extra layer of
definition on top of the logic relation can be understood in simply typed
languages~\citep{skorstengaard2019introduction, harpertait,
  pierce2002types}. In our setting, attempting to show that
$[[empty |- a : A]]$ implies $[[InterpR i A S]]$ and $[[a in S]]$ will fail in
\rref{T-Abs}, where the induction hypothesis is not helpful since the body of
the lambda term is typed under a non-empty context. Through the definition of
semantic typing, we can state a strengthened property that is actually
provable.

\begin{definition}[Semantic well-formed substitution\footnote{\dotv{soundness.v}{$\rho$\_ok}}]
Define $[[rho |= G]]$ when 
\[ \forall i\ j\ S, \text{ if }[[i < |G|]]\text{ and
                     } [[InterpR j (G i < up Suc i > ) { rho } S ]] \text{, then } [[rho i in S]] \]
\end{definition}

% To generalize our logical relation to open
% terms, we define the semantic typing judgment by closing the open
% terms with a substitution whose codomain consists of terms that
% respect the interpretation of the types from the context.
% The full
% definitions of well-formed substitution ($[[rho |= G]]$), semantic
% typing ($[[ G |= a : A]]$), and semantic context well-formedness
% ($[[|= G]]$) are presented in Figure~\ref{fig:semtyping}.

The $[[rho |= G]]$ notation denotes the semantic well-formedness of a
substitution $[[rho]]$ with respect to a context $[[G]]$. Intuitively, for any
variable $[[i]]$ in the context (thus the restriction $[[i < | G |]]$),
$[[rho i]]$ is a term that inhabits all possible interpretations of the type
$[[G i]]$ from the context.


Since we are in a dependently typed system, there
may be variables in $[[G i]]$, too. The type $[[(G i < up Suc i > ) {
  rho }]]$ applies $[[rho]]$ to replace those variables. The shifting
operation $[[up Suc i]]$ can be viewed as an artifact of the de Bruijn
representation to lift the type $[[G i]]$ to the right scope before
substitution can be carried out.

Finally, despite the for all quantification over the interpreted set
$[[S]]$ and the universe level $[[j]]$ in the definition of $[[rho |=
G]]$, we only need show that there exists some $[[j]]$ and $[[S]]$
such that $[[InterpR j (G i < up Suc i > ) { rho } S]]$ and $[[rho i
in S]]$. This idea is encapsulated in the second of the two structural
law about $[[rho |= G]]$.
\begin{lemma}[Well-formed $[[rho]]$ empty\footnote{\dotv{soundness.v}{$\rho$\_ok\_nil}}]
  \label{lemma:rhowfempty}
  $[[rho |= G]]$ whenever $[[G]]$ is the empty context.
\end{lemma}
\begin{lemma}[Well-formed $[[rho]]$ cons\footnote{\dotv{soundness.v}{$\rho$\_ok\_cons}}]
  If $[[InterpR i A S]]$, $[[a in S]]$, and $[[rho |= G]]$, then
  $[[rho .: a |= G ++ A]]$.
\end{lemma}

We next define semantic well-typedness.

\begin{definition}[Semantic typing\footnote{\dotv{soundness.v}{SemWt}}]
Define $[[G |= a : A]]$  when
\[ \forall [[rho]], \text{ if }[[rho |=
                       G]]\text{ then there exists some } [[j]] \text{
                       and } [[S]] \text{ such that } [[InterpR j A
                       {rho} S]] \text{ and } [[a {rho} in S]]  \]
\end{definition}

This definition says the term $[[a]]$ can be semantically typed $[[A]]$ under
the context $[[G]]$ if for all substitutions $[[rho]]$ such that
$[[rho |= G]]$, the type $[[A { rho }]]$ can be interpreted as the set
$[[S]]$, and $[[a { rho } in S]]$. Our definition of semantic well-typedness
is standard, though dependent types add a small twist that we apply the
$[[rho]]$ to $[[A]]$ and require that $[[A { rho }]]$ has some interpretation.

Finally, we define semantic well-formedness for contexts, analogous to the 
relation $[[|-G]]$.

\begin{definition}[Semantic context well-formedness\footnote{\dotv{soundness.v}{SemWff}}]
Define $[[|= G]]$ when
\[
   \forall [[i < |G|]],\text{ there exists some } [[j]] \text{ such that } [[drop Suc i G |= G i : Set j]] \]
\end{definition}

In this definition, we use the notation $[[drop i G]]$ to denote
the typing context obtained by dropping the last $[[i]]$ elements of
$[[G]]$. When $[[G]]$ has fewer than $[[i]]$ elements, $[[drop i G]]$ returns
the empty list. Intuitively, $[[|= G]]$ says that all
types in the context must correspond to some set according to the logical
relation. The truncation to the context $[[G]]$ is due to the telescopic
scoping of the types in the context. An alternative approach would be to define $[[|= G]]$
inductively, similar to $[[|- G]]$, but we find it easier to use this definition and
recover the structural rules as lemmas.
\begin{lemma}[Semantic context well-formedness cons]
  \label{lemma:semwffcons}
  If $[[|= G]]$ and $[[G |= A : Set i]]$, then $[[|= G ++ A]]$.
\end{lemma}
\begin{lemma}[Semantic context well-formedness empty]
  \label{lemma:semwffempty}
  $[[|= G]]$ holds when $[[G]]$ is empty.
\end{lemma}


The following lemma makes the statement $[[G |= A : Set i]]$ easier to
work with.
\begin{lemma}[Set Inversion\footnote{\dotv{soundness.v}{SemWt\_Univ}}]
  \label{lemma:setinv}
  The following two statements are equivalent:
  \begin{itemize}
  \item $[[G |= A : Set i]]$
  \item $\forall$ $[[rho]]$, if $[[rho |= G]]$, then there exists
    $[[S]]$ such that $[[InterpR i (A {rho}) S]]$
  \end{itemize}
\end{lemma}
\begin{proof}
  The forward direction is immediate by
  Lemma~\ref{lemma:interpinv}. We now consider the backward direction
  and show that $[[G |= A : Set i]]$ given the second bullet.

  Suppose $[[rho |= G]]$, then we know that there exists some $[[S]]$
  such that $[[InterpR i (A {rho}) S]]$. By the definition of semantic
  typing, it suffices to show that there exists some $[[j]]$ and
  $[[S0]]$ such that  $[[InterpR j Set i S0]]$ and $[[A {rho} in
  S0]]$.
  Pick $[[Suc i]]$ for $[[j]]$ and $[[ { A | exists S , InterpR i A S }
  ]]$ for $[[S0]]$ and it is trivial to verify the conditions hold.
\end{proof}



% The semantic context well-formedness judgment ($[[|= G]]$), unlike its syntactic
% counterpart $[[|- G]]$, is defined through a $\forall$ quantified statement rather
% than inductively over the context. \scw{why is that the case?} It is easy to recover the same
% structural rules:
% \scw{point out that this lemma is the semantic analogue to Ctx-Cons. What about
% Ctx-empty?}
% \begin{proof}
%   By the definition of semantic context well-formedness, the goal is
%   to show that given $[[i < | G ++ A |]] = [[Suc |G|]]$, $[[drop Suc i   (G ++ A) |= (G ++ A) i : Set j]]$. The statement can be easily
%   proven by case analysis on whether $[[i]]$ is zero.
% \end{proof}

Next, we show some non-trivial cases of the fundamental theorem as
top-level lemmas. For example, we can define the semantic analogue to the 
syntactic typing rule for variables (\rref{T-Var}).
\begin{lemma}[ST-Var]
  \label{lemma:stvar}
  If $[[|= G]]$ and $[[i < |G|]]$, then $[[G |= var i : G i < up Suc i  >]]$.
\end{lemma}
\begin{proof}
  Suppose $[[rho |= G]]$. By the definition of semantic typing, we
need to show that there exists some $[[j]]$ and $[[S]]$ such that
  \begin{itemize}
  \item $[[InterpR j G i < up Suc i > { rho } S]]$
  \item $[[rho i in S]]$
  \end{itemize}
  From the definition of $[[|= G]]$, we know that there exists some
  $[[j]]$ such that $[[drop Suc i G |= G i : Set j]]$. This is not
  immediately useful since $[[rho |= G]]$, not the truncated
  context. We claim, without giving the proof, that from $[[drop Suc i
  G |= G i  : Set j]]$, we can derive $[[G |= G i {up Suc i} : Set
  j]]$. A rigorous justification would require us to formally state
  and show renaming/weakening lemma for semantic typing. We instead
  provide an informal justification since the proof of renaming
  is uninteresting and only requires unfolding definitions, but its
  statement introduces unnecessary line noise related to shifting.

  Intuitively, a substitution $[[rho]]$
  that closes over a context should always induce a truncated
  substituion for each truncated context. As a result, if
  some term $[[b]]$ is semantically well-typed under some truncated
  context $[[G]]$, then it must also be semantically well-typed under
  the context $[[G]]$ up to shifting.
%
  Knowing that $[[G |= G i {up Suc i} : Set j]]$ holds, we can then
  apply Lemma~\ref{lemma:setinv} to show that
  $[[InterpR j G i < up Suc i > { rho } S]]$. It now
  suffices to show $[[rho i in S]]$, but that is immediate from the
  definition of $[[rho |= G]]$.
\end{proof}

% Next, we show some non-trivial cases of the fundamental theorem as
% top-level lemmas.
% We first formulate the definition of valid renamings and prove that
% semantic typing satisfies renaming so we can weaken the context when
% reasoning about the variable case of the fundamental lemma
% (Lemma~\ref{lemma:stvar}). Intuitively, given a valuation $[[rho |= G ++ D]]$, it is easy to show that we can extract some valuation
% $[[rho0]]$ such that $[[rho0 |= G]]$, where $[[rho0]]$ is obtained by
% ``truncating'' $[[rho]]$. As a result, if we know that $[[G |= a :A]]$, then we can conclude that $[[G ++ D |= a0 : A0 ]]$, where
% $[[a0]]$ and $[[A0]]$ are obtained by shifting $[[a]]$ and $[[A]]$
% after weakening the context; this implication holds because $[[rho |=G ++ D]]$ induces a context $[[rho0]]$ such that $[[rho0 |= G]]$ so we
% can make use of the premise $[[G |= a : A]]$ to derive what we need
% for the conclusion. We recommend the readers to skip the proofs of
% Lemmas~\ref{lemma:validtruncate} through \ref{lemma:semrenaming}
% during the first read as long as they have an intuitive understanding
% of what the renaming property is meant to capture.

% \scw{Make this a definition? Would it be useful to create notation
%   for the relation, such as $[[xi]]:[[G]]\Rightarrow[[D]]$? }
% We say that $[[xi]]$ is
% valid from the context $[[G]]$ to the context $[[D]]$ if the
% following condition holds.
% \[ \forall i \text{, if } i < | [[G]] |\text{, then }[[ ren xi i < |D| ]] \text{ and }
%   [[D ren xi  i < up Suc ren xi i > = G i < up Suc i > < xi >]] \]

% \begin{lemma}[Truncate is valid]
%   \label{lemma:validtruncate}
%   If $[[i < |G|]]$, then $[[up i]]$ is a valid renaming from $[[drop i   G]]$ to $[[G]]$.
% \end{lemma}
% \begin{proof}
%   By the definition of a valid renaming, we must show that given $[[j   < |drop i G|]] = [[|G|]] - [[i]]$, then the following conditions hold:
%   \begin{itemize}
%   \item $[[ren up i j]] = i + j  < [[| G | ]]$
%   \item $[[G ren up i j < up Suc ren up i j > = drop i G j < up Suc j > < up i >]]$
%   \end{itemize}
%   The first bullet point is immediate from the fact that $[[j]] <
%   [[|G|]] - [[i]]$. The second bullet follows from unfolding the
%   definitions, and the fact that $[[drop i G j]] = [[G]](i + j)$ when
%   $[[i]] + [[j]] < [[|G|]]$.
% \end{proof}

% \begin{lemma}[Renaming for $[[rho |= G]]$]
%   \label{lemma:renamingval}
%   If $[[rho |= D]]$ and $[[xi]]$ is a valid renaming from $[[G]]$ to
%   $[[D]]$, then we have $[[rho0 |= G]]$ where $[[rho0 i = rho ren xi i]]$.
% \scw{could you use $[[rho]]\circ[[xi]]$ for $[[rho0]]$?}
% \end{lemma}
% \begin{proof}
%   Unfolding the definition of $[[rho0 |= G]]$, the goal is to show
%   that for all $i,j,$ and $S$, if $[[i < |G|]]$ and $[[InterpR j (G i   < up Suc i > ) { rho0 } S ]] \text{, then } [[rho0 i]] = [[rho ren xi i in S]]$.

%   By the definition of $[[rho0]]$ and the validity of $[[xi]]$, we
% have $[[G i < up Suc i > { rho0 }]] = [[G i < up Suc i > < xi > { rho } ]] = [[D ren xi i < up Suc ren xi i > { rho }]]$. From $[[rho |= D]]$ and $[[ren xi i < | D |]]$, we have $[[InterpR j D ren xi i < up Suc ren xi i > { rho } S]]$ and $[[rho ren xi i in S]]$.
% \end{proof}

% \begin{lemma}[Renaming for $[[G |= a : A]]$]
%   \label{lemma:semrenaming}
%   If $[[G |= a : A]]$ and $[[xi]]$ is a valid renaming from $[[G]]$ to
%   $[[D]]$, then $[[D |= a < xi > : A < xi > ]]$.
% \end{lemma}
% \begin{proof}
%   Immediate from the definition of semantic typing and Lemma~\ref{lemma:renamingval}.
% \end{proof}

% \scw{Need a transition here that you are starting to explain the semantic typing
% rules.}


\begin{lemma}[ST-Set]
  \label{lemma:stset}
  If $[[i < j]]$, then $[[G |= Set i : Set j]]$.
\end{lemma}
\begin{proof}
  Immediate by Lemma~\ref{lemma:setinv} and \rref{I-Set}.
\end{proof}

\begin{lemma}[ST-Pi]
  \label{lemma:stpi}
  If $[[G |= A : Set i]]$ and $[[G ++ A |= B : Set i]]$, then $[[G |= Pi
  A B : Set i]]$.
\end{lemma}
\begin{proof}
  Applying Lemma~\ref{lemma:setinv} to the
  conclusion, it now suffices to show that given $[[rho |= G]]$, there
  exists some $[[S]]$ such that $[[InterpR i Pi A{rho} B{up rho} S]]$.
  From Lemma~\ref{lemma:setinv} and $[[G |= A : Set i]]$, we know that
  there exists some set $[[S0]]$ such that $[[InterpR i A {rho} S0]]$.
From $[[G ++ A |= B : Set i]]$, we know that there must
exists $[[S]]$ such that $[[InterpR i B {rho .: a} S]]$ for every $[[a
in S0]]$. The conclusion immediately follows from Lemma~\ref{lemma:piintroalt}.
\end{proof}

\begin{lemma}[ST-Abs]
  \label{lemma:stabs}
  If $[[G |= Pi A B : Set i]]$ and $[[G ++ A |= b : B]]$, then $[[G |=
  \ A b : Pi A B]]$.
\end{lemma}
\begin{proof}
  By unfolding the definition of $[[G |= \ A b : Pi A B]]$, we need to
  show that given some $[[rho |= G]]$, there exists some $[[i]]$ and
  $[[S]]$ such that $[[InterpR i Pi A {rho} B {up rho} S]]$ and $[[\
  A{rho} b{up rho} in S]]$.

  By Lemma~\ref{lemma:setinv} and the premise $[[G |= Pi A B : Set
  i]]$, there exists some set $[[S]]$ such that
  $[[InterpR i Pi A {rho} B {up rho} S]]$. It now suffices to show that
  $[[\A{rho} b{up rho} in S
  ]]$. By Lemma~\ref{lemma:piinvalt}, there exists some $[[S0]]$ such
  that all following conditions hold:
  \begin{itemize}
  \item $[[InterpR i A{rho} S0]]$
  \item $[[forall a, (# a in S0 implies (# exists S1 , InterpR i B
    {rho .: a}
    S1 #) #)]]$
  \item $[[S = { b | forall a, (# a in S0 , forall
      S1, (# InterpR i B {rho .: a} S1,  b a in S1 #) #) }]]$
  \end{itemize}
  To show that $[[\A{rho} b{up rho} in S]]$, we need to prove
  that given $[[a in S0]]$,
  $[[Interp I i B {rho .: a} S1]]$, we have  $[[( \A{rho} b{up rho} )
  a in S1]]$.
  By Lemma~\ref{lemma:logrelbackclos}, the set $[[S1]]$ is closed
  under expansion. Since $[[( \A{rho} b{up rho} )
  a => b {up rho} {a}]] = [[b {rho .: a}]]$, it suffices to show that
  $[[b {rho .: a} in S1]]$, which is immediate from $[[G ++ A |= b :
  B]]$ and the fact that the logical relation is deterministic and
  cumulative (Lemma~\ref{lemma:logreldeterhet}).
\end{proof}

\begin{lemma}[ST-App]
  \label{lemma:stapp}
  If $[[G |= b : Pi A B]]$ and $[[G |= a : A]]$, then $[[G |= b a : B {a}]]$.
\end{lemma}
\begin{proof}
Suppose $[[rho |= G]]$. The goal is to show that there exists some
$[[i]]$ and $[[S1]]$
such that  $[[b {rho} a {rho} in S1 ]]$ and $[[InterpR i B {a} {rho}
S1]]$, or equivalently, $[[InterpR i B {rho .: a {rho}} S1]]$ since
$[[B {a}{rho}]] = [[B {rho .: a {rho}}]]$. By the premise $[[G |= b :
Pi A B]]$, Lemma~\ref{lemma:setinv}, and Lemma~\ref{lemma:piinvalt},
there exists some $[[i]]$ and $[[S0]]$ such that:
  \begin{itemize}
  \item $[[InterpR i A{rho} S0]]$
  \item $[[forall a0, (# a0 in S0 implies (# exists S1 , InterpR i B
    {rho .: a0}
    S1 #) #)]]$
  \item $[[forall a0, (# a0 in S0 , forall
      S1, (# InterpR i B {rho .: a0} S1,  b {rho} a0 in S1 #) #)]]$
  \end{itemize}
  Instantiating the variable $[[a0]]$ from the last two bullets with
  the term $[[a {rho}]]$, the conclusion immediately follows.
\end{proof}

\begin{theorem}[The Fundamental Theorem\footnote{\dotv{soundness.v}{soundness}}]
  \label{theorem:soundness}\leavevmode
  \begin{itemize}
  \item If $[[G |- a : A]]$, then $[[G |= a : A]]$.
  \item If $[[|- G]]$, then $[[|= G]]$.
  \end{itemize}
\end{theorem}
\begin{proof}
  Proof by mutual induction over the derivation of $[[G |- a :
  A]]$ and $[[|- G]]$.   The cases related to context well-formedness immediately follows
  from Lemma~\ref{lemma:semwffcons}. The semantic typing rules
(Lemmas~\ref{lemma:stvar},~\ref{lemma:stset},~\ref{lemma:stpi},~\ref{lemma:stabs},~\ref{lemma:stapp})
  can be used to discharge their syntactic counterparts
  (e.g. Lemma~\ref{lemma:stabs} for case \rref{T-Abs}). The remaining
  cases not covered by the lemmas are similar to the ones already
  shown.
\end{proof}

Recall the logical consistency property
(Theorem~\ref{theorem:consistency}), which states that the judgment
$[[empty |- a : Void ]]$ is not derivable. We now give a proof of the
property using the fundamental lemma.

\begin{proof}
  Suppose $[[empty |- a : Void]]$ is derivable, then by the
  fundamental lemma, we have $[[empty |= a : Void]]$, which states
  that for all $[[rho |= empty]]$, and for all $[[j]]$, $[[S]]$ such
  that $[[InterpR j Void S]]$, we have $[[a {rho} in S]]$. By
  Lemma~\ref{lemma:rhowfempty}, any $[[rho]]$ we pick trivially
  satisfies $[[rho |= G]]$. For convenience, we pick $[[rho]]$ as
  $[[idtm]]$, though any $[[rho]]$ would work since
  $[[empty |- a : Void]]$ ensures there is no free variable in
  $[[a]]$. We have $[[a {idtm}]] = [[a in S]]$. By the $[[Void]]$
  case of the inversion property (Lemma~\ref{lemma:interpinv}), we
  know that $[[S]]$ must be the empty set and therefore contradicts
  the assumption that $[[a in S]]$.
\end{proof}


\section{Existence of $\beta$-normal forms}
\label{sec:extension}
In this section, we show how the logical relation from
Section~\ref{sec:logreldep} can be extended to show the existence of
$\beta$ normal forms for (open and closed) well-typed terms.
\scw{Why is this a sketch? We've done the whole proof and we will
explain it all, right?}\yl{s/sketch out/show. I used sketch because we
didn't spell out the full proofs}

\scw{The goal of this section is also to demonstrate that our logical relations
  proof technique can be extended to reason about the (parallel) reduction of
  open terms, not just the reduction of terms after closing
  substitutions. This is important, in particular, for dependently-typed languages
  because type checking involves reasoning about open terms. But even simple type
  systems may wish to employ this sort of reasoning, in the case of, say, reasoning
  about compiler correctness in open environments. (Does Amal do anthing like this?)
}

The goal of this section is to prove that all well-typed terms have
$\beta$-normal forms. In other words, we can repeatedly use our parallel
reduction relation to reduce any term to a unique normal form, where no
further reductions can be applied. This result can be used to show that our
type conversion relation is decidable, as computation of the normal form will
always terminate.

\begin{figure}[h]
  \[
    \begin{array}{llcl}
       \beta\text{-}\mathit{neutral\ terms} &
      [[e]] & ::= & [[i]]\ |\ [[e f]]\ |\ [[J e f f f]]\ |\ [[if e f
                    f]] \\ \\
      \beta\text{-}\mathit{normal\ terms} &
      [[f]] & ::= & [[e]]\ |\ [[Set i]]\ |\ [[Void]]\ |\ [[Pi f f]]\
                    |\ [[f ~ f : f]]\\
            & & |   & [[\ f]]\ |\ [[refl]]\ |\ [[Bool]]\ |\ [[true]]\ |\ [[false]]
    \end{array}
  \]
  \caption{$\beta$-neutral and normal forms}
  \label{fig:nenf}
\end{figure}

The syntactic forms $[[e]]$ and $[[f]]$ (Figure~\ref{fig:nenf}) capture the
neutral terms and normal forms with respect to $\beta$-reduction. We sometimes
use the judgment forms $[[ne a]]$ and $[[nf a]]$ to indicate that there exists
$[[e]]$ or $[[f]]$ such that $[[a = e]]$ or $[[a = f]]$.

The predicates $[[wne a]]$ and $[[wn
a]]$ describe terms that can evaluate into $\beta$-neutral or
$\beta$-normal form through parallel reduction and are defined as
follows.
\[ [[wne a]] \iff \exists [[e]], [[a =>+ e]] \]
\[ [[wn a]] \iff \exists [[f]], [[a =>+ f]] \]
We can read $[[wne a]]$ and $[[wn a]]$ as the term $[[a]]$ weakly normalizes to a neutral or a normal form respectively.

\begin{figure}[h]
  \drules[I]{$[[Interp I i A S]]$}{Logical Relation}{Ne, VoidNew, BoolNew, EqNew}
  \caption{Extended logical relation}
  \label{fig:logrelopen}
\end{figure}

The updated logical relation is shown
in Figure~\ref{fig:logrelopen}.
% The idea of a term blocked from $\beta$ reduction is
% captured by $[[e]]$, the set of neutral terms. We augment the
% interpretation of booleans and the empty types with terms that
% evaluate to neutral terms. Furthermore, types that are neutral terms
% can also be assigned a meaning since they may be inhabited by other
% neutral terms.
In the definition of the logical relation, we omit the rules for
the function and universe cases since they remain identical to the
original version in Figure~\ref{fig:logrel}.
The changes to \rref{I-Bool} and \rref{I-Void} follow the exact same pattern.
An open term of type $[[Bool]]$ does
not necessarily reduce to $[[true]]$ or $[[false]]$, but may reduce to
a variable, or more generally, a neutral term. Likewise, the
$[[Void]]$ type, while remains uninhabited under an empty context, may
be inherited by the set of neutral terms when there is a variable in
the context that allows us to inhabit $[[Void]]$.

The rule for equality type $[[a ~ b : A]]$ is augmented with the preconditions that
$[[a]]$, $[[b]]$, and $[[A]]$ are all in their normal forms since
otherwise our model would include equality types that are themselves
not normalizing. Furthermore, the side condition $[[a <=> b]]$ is only
available when the equality proof reduces to $[[refl]]$. If the proof
term reduces to a neutral term, then there is nothing we can learn
about the relationship between $[[a]]$ and $[[b]]$.

Finally, in a
non-empty context, a type itself may evaluate to a neutral term and in
turn can only inhabited by neutral terms, thus the addition of \rref{I-Ne}.

Interestingly, all the properties we have shown in
Section~\ref{sec:logreldep} and \ref{sec:logrelproof} before the
fundamental lemma can be proven in the exact same order, where the new
cases due to \rref{I-Ne} and the augmentation of neutral terms
to \rref{I-Void, I-Eq, I-Bool} can be immediately discharged by
Lemma~\ref{lemma:parnenf}.

Before we can prove the fundamental theorem and derive the
normalization property as its corollary, we need to additionally
formulate and prove the adequacy property.

\yl{Moved renaming back to Sec 5 because they are needed for the
  non-eta development too}
Let us first start with some auxiliary lemmas and definitions.
\begin{lemma}[Par anti-renaming]
  \label{lemma:parantirenaming} If $[[a < xi > => b0]]$, then there
exists some $[[b]]$ such that $[[b < xi > = b0]]$ and $[[a => b]]$.
\end{lemma}

We can show that parallel reduction preserves $\beta$-normal and
neutral forms.
\begin{lemma}[Par preserves $\beta$-neutral and normal forms]
  \label{lemma:parnenf}
  If $[[a => b]]$, then
  \begin{itemize}
  \item $[[ne a]]$ implies $[[ne b]]$
  \item $[[nf a]]$ implies $[[nf b]]$
  \end{itemize}
\end{lemma}

\begin{lemma}[Wn extensionality]
  \label{lemma:extwn}
  If $[[wn (a var i)]]$, then $[[wn a]]$.
\end{lemma}
\begin{proof}
  By induction over the length of the reduction sequence in $[[wn (a
  var i)]]$. The conclusion follows from Lemma~\ref{lemma:parantirenaming} and
  \ref{lemma:parnenf}.
\end{proof}

\begin{lemma}[wne wn]
  \label{lemma:wnewn}
  If $[[wne a]]$ and $[[wn b]]$, then $[[wne a b]]$.
\end{lemma}
\begin{proof}
  Immediate by lexicographical induction over the length of the reduction sequences in
  $[[wne a]]$ and $[[wn b]]$.
\end{proof}

To state the adequacy lemma, we first define the notion
of reducibility candidates (shortened as $CR$), predicates over sets
of lambda terms that capture the properties we need from our logical
relation. \scw{Need to provide intuition for these two properties that need
to be proved similtaneously. Also, cite where this form of proof originally
appeared? This part is standard.}
\begin{definition}[CR]
  Let $[[S]]$ be a set of lambda terms. We say that
  \begin{itemize}
  \item $[[S]] \in CR_1 \iff $  $[[forall a, (#  wne a implies a in S #)]]$
  \item $[[S]] \in CR_2 \iff$ $[[forall a, (# a in S implies wn a #)]]$
  \item $[[S]] \in CR \iff $ $[[S]] \in CR_1$ and $[[S]] \in CR_2$
  \end{itemize}
\end{definition}

\yl{Merged all the separate adequacy related properties into a single
  property proved through nested induction. (The mechanization has
  been adjusted accordingly)}
We now state and prove the adequacy lemma. We give some more details
since we prove it through nested induction.
\begin{lemma}[Adequacy\footnote{\dotv{soundnessopen.v}{soundness}}]
  \label{lemma:adequacy}
  If $[[InterpR i A S]]$, then we have $[[S]] \in CR$.
\end{lemma}
\begin{proof}
  We start by strong induction over $[[i]]$. We are given the
  induction hypothesis that for all $[[j < i]]$, $[[InterpR j A S]]$
  implies $[[S]] \in CR$. Our goal is to show $[[InterpR i A S]]$
  implies $[[S]] \in CR$.

  By its definition in Figure~\ref{fig:logrelrec}, we have the
  equality $[[InterpR i A S]] = [[Interp I i A S]]$  where $[[I i]] :=
  [[{A | exists S , InterpR i A S}]]$.
  We then proceed by structural over the derivation of $[[Interp I i A
  S]]$. The only interesting cases are \rref{I-Pi} and \rref{I-Set}.
  The function case requires Lemmas~\ref{lemma:extwn} and
  \ref{lemma:wnewn} we have shown earlier.

  The \rref{I-Set} case is the most involved. We need to show that
  for all $[[j < i]]$, the set $[[{ A | exists S, InterpR j A S  }]]
  \in CR$. We immediately know that $[[{A | exists S, InterpR j A S
  }]] \in CR_1$ by \rref{I-Ne}. It remains to show that $[[{A | exists S, InterpR j A S
  }]] \in CR_2$, or equivalently, for all $[[A]]$, $[[InterpR j A S]]$
  implies $[[wn A]]$. Suppose $[[InterpR j A S]]$ for an arbitrary
  $[[A]]$. We have $[[InterpR j A S]]=[[Interp I j A S]]$ where $[[I]]$
  has the same definition from earlier but its domain restricted to
  numbers less than $[[j]]$. We perform another induction on
  $[[j]]$. All cases are trivial except for the case for
  \rref{I-Pi}. Our induction hypothesis immediately gives us $[[wn
  A]]$. To derive $[[wn Pi A B]]$, it remains to show $[[wn B]]$. We
  use the outermost induction hypothesis to show that $[[var 0]]$
  semantically inhabits $[[A]]$, from which we derive $[[wn B {var 0}]]$
  and conclude $[[wn B]]$ through antirenaming (Lemma~\ref{lemma:parantirenaming}).
\end{proof}

% \begin{lemma}[Adequacy: $CR_1$ for type]
%   \label{lemma:cr1ty}
%   If $[[wne A]]$, then we have $[[Interp I i A {a | wne a }]]$.
% \end{lemma}
% \begin{proof}
%   Immediately from \rref{I-Ne} and \rref{I-Par}.
% \end{proof}

% \begin{lemma}[Adequacy: $CR$ for interpreted sets]
%   \label{lemma:crel}
%   If $[[I]](j) \in CR$ for all $[[j < i]]$ and $[[Interp I i A S]]$, then $[[S]] \in CR$.
% \end{lemma}
% \begin{proof}
%   By induction over the derivation of $[[Interp I i A S]]$. The base
%   cases are all immediate.

%   In the function case ($[[Pi A B]]$), we use the induction
%   hypothesis to show that variables, which are special cases of
%   neutral terms, semantically inhabit the input type $[[A]]$. We apply the
%   function to an arbitrary variable and we can then use
%   Lemma~\ref{lemma:extwn} to conclude the $CR_2$ property.

%   To show
%   the $CR_1$ property, we need to prove that given a neutral term $[[b]]$
%   such that $[[wne b]]$,
%   and a term $[[a]]$ that semantically inhabits $[[A]]$, $[[b a]]$ gives
%   us a term that semantically inhabits $[[B {a}]]$. From the induction
%   hypothesis, $[[A]]$ also satisfies $CR_2$ and therefore $[[wn a]]$
%   holds. By Lemma~\ref{lemma:wnewn}, we have $[[wne b a]]$. By $CR_2$
%   from the induction hypothesis, since every term that evaluates to
%   some neutral form semantically inhabits $[[B {a}]]$. Done.
% \end{proof}


% \begin{lemma}[Adequacy: $CR_2$ for type]
%   \label{lemma:cr2ty}
%   If $[[I]](j) \in CR$ for all $[[j < i]]$ and $[[Interp I i A S]]$, then $[[wn A]]$ holds.
% \end{lemma}
% \begin{proof}
%   By induction over the derivation of $[[Interp I i A S]]$. The
%   function case uses Lemma~\ref{lemma:crel} and Lemma~\ref{lemma:extwn}.
% \end{proof}

% \begin{lemma}[Adequacy: $CR_2$ for types (Rec)]
%   \label{lemma:cr2tyrec}
%   If $[[InterpR i A S]]$, then $[[wn A]]$.
% \end{lemma}
% \begin{proof}
%   By strong induction over $[[i]]$ and Lemma~\ref{lemma:cr2ty}.
% \end{proof}

% \begin{lemma}[Adequacy: $CR$ for terms (Rec)]
%   \label{lemma:crelrec}
%   If $[[InterpR i A S]]$, then $[[S]] \in CR$.
% \end{lemma}
% \begin{proof}
%   After unfolding the definition of $[[InterpR i A S]]$, trivial by
%   Lemmas~\ref{lemma:cr1ty}, \ref{lemma:crel} and \ref{lemma:cr2tyrec}.
% \end{proof}

The formulation of the valuation and semantic well-typedness from
Figure~\ref{fig:semtyping} and the fundamental lemma remains
unchanged.
The proof of the fundamental lemma is still carried out by induction
over the typing derivation, where the additional neutral term related
cases are handled by Lemma~\ref{lemma:adequacy}, the adequacy property.

The normalization property then follows as a corollary of the
fundamental theorem.
\begin{corollary}[Existence of $\beta$-normal form]
  \label{corollary:exbetanf}
  If $[[G |- a : A]]$, then $[[wn a]]$ and $[[wn A]]$.
\end{corollary}
\begin{proof}
  By the fundamental lemma, we know that $[[G |= a : A]]$. That is,
  for all $[[rho |= G]]$, there exists some $[[i]]$ and $[[S]]$ such
  that $[[InterpR i A {rho} S]]$ and $[[a {rho} in S]]$.
  We pick the valuation $[[rho]] = [[idtm]]$ (defined in Figure~\ref{fig:auxdef}), which injects
  natural numbers as term variables. The side condition $[[idtm |=
  G]]$ is satisfied since Lemma~\ref{lemma:adequacy} says neutral terms,
  including variables, semantically inhabit any $[[S0]]$ where
  $[[S0]]$ is the interpretation of some type. With our choice of
  $[[rho]]$, we have $[[A {rho}]] = [[A {idtm}]] = [[A]]$ and $[[a {rho}]] = [[a{idtm}]] = [[a]]$. Then we
  know that $[[InterpR i A S]]$ and $[[a in S]]$ for some $[[i]]$ and
  $[[S]]$. By Lemma~\ref{lemma:adequacy}, we
  conclude that $[[wn a]]$ and $[[wn A]]$ respectively.
\end{proof}

Due to the non-deterministic nature of parallel reduction, we need to take a
few more steps to convert the existence of $\beta$-normal form into a decision
procedure for type conversion. More specifically, we can show that a
deterministic evaluation strategy such as leftmost-outermost reduction can
always find the $\beta$-normal form if there exists one. Then the termination
of that strategy immediately follows from Corollary~\ref{corollary:exbetanf}
However, we omit such proofs since they can can be formulated on untyped
lambda terms and thus are orthogonal to the specifics of dependently typed
systems. Instead, we redirect readers to \citet{factorization-essentially,
  takahashi-parallel-reduction} for the details.

\scw{Name and foreshadow these lemmas when they are introduced so that
it is easier to refer to them in the discussion.}
Finally, we want to point out that
the adequacy property (Lemma~\ref{lemma:adequacy}) are in fact required in the normalization proof
for simply typed languages~\citep{abel2019poplmark}. Similar to the
simply typed scenario, adequacy needs to be proven before the
fundamental theorem so we can handle elimination rules such as
\rref{T-If} and \rref{T-App} where the scrutinee is a neutral term. % In
% \citet{abel2019poplmark}, a variant of Lemma~\ref{lemma:extwn} is used
% in the exact same way to show the normalization of lambda forms
Dependent types make the adequacy proof slightly more complicated
as we also need to know that every type has a normal form, not just
the terms.
This complicates our proof specifically in the \rref{I-Set} case for
our adequacy property (Lemma~\ref{lemma:adequacy}).

Overall, despite the dependently typed setting,
the extension of our logical relation to prove normalization of open
\emph{and} closed terms closely mirrors the progression from
normalization of closed terms~\citep{harpertait} to normalization of
open terms~\citep{harperkripke} in the simply typed lambda calculus.
It is in fact reassuring that once we have laid the foundational
technique for handling dependent types in our logical relation, the
extension to open terms mostly boil down to properties that can be
independently derived from the logical relation through syntactic
means.

\section{Existence of $\beta\eta$-normal forms}
We can easily incorporate the function $\eta$ law to the equational
theory of \lang{} by adding the following parallel reduction rule.
\begin{center}
  \drule[width=2.5in]{P-AbsEta}
\end{center}
% \Rref{P-AbsEta} effectively adds the $\eta$ law for functions to our
% equational theory since convertibility ($[[a <=> b]]$), the untyped relation
% used for type conversion, is built on top of parallel reduction.
We can recover the same confluence result about parallel reduction
using the standard techniques from
\citet{barendregt:lambda-calculi-with-types,
takahashi-parallel-reduction}, though anti-renaming
(Lemma~\ref{lemma:parantirenaming}) needs to be proven before the
diamond property (Lemma~\ref{lemma:pardiamond}). Another complication
is that confluence and anti-renaming now requires induction on a size
metric of lambda terms so the $\eta$ case has a useful induction hypothesis.

Note that the specification of our logical relation does not require
any changes. We can continue using $\ottkw{ne}$ and $\ottkw{nf}$ to
represent $\beta$-neutral and normal forms. By reproving the
fundamental lemma, we learn that every well-typed term as a
$\beta$-normal form. Lemma~\ref{lemma:parnenf} still holds with our
extended parallel reduction. In the presence of the $\eta$ reduction
rule, Lemma~\ref{lemma:parnenf} tells us that $\eta$ reduction
preserves $\beta$-normal forms (i.e. does not produce new
$\beta$-redexes). Furthermore, since the $\eta$ reduction rule for
functions strictly decreases the size of the term, the existence of
$\beta\eta$ normal form trivially follows.
\begin{corollary}[Existence of $\beta\eta$-normal form]
\label{corollary:exbetaeta}
If $[[G |- a : A]]$, then $[[a]]$ has $\beta\eta$-normal form.
\end{corollary}
Due to some technical
details, our proof about the existence of $\beta\eta$ form does not
immediately induce a decision procedure for type conversion in
\lang{}. We discuss this issue and its workaround in
Section~\ref{sec:conversionalgo}.


\section{Mechanization}
\label{sec:logrelmech}
\begin{figure}[h]
  \begin{tabular}{ l |  c  | c | c }
    & Consistency & Normalization & Syntactic metatheory \\
    \hline
    % Library (Autosubst 2)  & 491 & - \\
    Syntactic typing (specification) &  68 & - & - \\
    Renaming & 46 & -  & - \\
    Untyped reduction & 349 & - & - \\
    Neutral and normal forms & N/A & 269 & N/A \\
    Logical relation & 331 & 426 & N/A \\
    Semantic typing and soundness & 169 & 199 & N/A \\
    Syntactic soundness & N/A & N/A  & 660 \\
    \hline
    Total & 963 & 1357 & 1123 \\
  \end{tabular}
  \caption{Statistics of the Coq Development}
  \label{fig:linecount}
\end{figure}

Figure~\ref{fig:linecount} shows the number of non-blank, non-comment lines of
code\footnote{calculated by the \texttt{cloc} tool} for each file of our
development, including the base consistency proof from
Section~\ref{sec:logreldep} and \ref{sec:logrelproof} and the extension to
normalization for open and closed terms from Section~\ref{sec:extension}.

Because the normalization and the consistency development share the same
syntactic and typing specification, they differ in only the categories
that are relevant to the logical relation. We use - as a marker that
the line count is the same.

Autosubst 2 takes our syntax specification in higher-order abstract
syntax and generates Coq syntax specification, renaming and
substitution functions, and lemmas and tactics that allow reasoning
about those functions. The auto-generated syntax file by Autosubst 2
and library header files are omitted from the figure.

Orthogonal to the development of our consistency and normalization
proof, we have also proven the syntactic soundness of our system through subject
reduction and progress. The syntactic soundness proof shares the
definition of renaming with our semantic soundness proof, which is
factored out as a separate file under the Renaming (common) category.
\scw{Should add this line count as another column, for comparison. I've done so,
but may need to update the numbers. }

\subsection{Artifacts Specific to Coq}
In this section, we discuss the Coq encoding of the definitions and proofs presented
in Section~\ref{sec:logrelproof} and the artifacts of this encoding that are
specific to Coq.

% The inductive
% definition of the logical relation in Figure~\ref{fig:logrel} requires
% the impredicativity of Coq's \texttt{Prop} sort since\scw{or ``so that''?} in \rref{I-Pi},
% the function $[[F]]$ can be later instantiated into the logical
% relation itself (e.g. in the proof of Lemma~\ref{lemma:piintroalt}).

In our proof presented in Section~\ref{sec:logreldep}, the relation
$[[R]]$ in \rref{I-Pi} requires Coq's impredicative \texttt{Prop} sort
since $[[R]]$ can later be instantiated into something defined in
terms of the logical relation itself (e.g. in
Lemma~\ref{lemma:piintroalt}). \scw{I'm having trouble connecting the rule in
the figure with rule \texttt{InterpExtFun} in the coq development. Would it make
sense to include the definition of ProdSpace? What is the Coq type of R?}

In the Coq mechanized proof, the definition of $[[Interp I i A S]]$ has type
\texttt{Prop}, when \texttt{I} has type \texttt{nat -> tm -> Prop} and \texttt{S}
has type \texttt {tm -> Prop}.  However, if desired, we could consistently
replace the use of \texttt{Prop} with Coq's predicative sort
\texttt{Type}. This variation of the definition could be used to define the
interpretation for any \emph{finite} number of universes. The use of
\texttt{Type} becomes troublesome only when we attempt to define
$[[InterpR i A S]]$, the top-level logical relation defined in
Figure~\ref{fig:logrelrec} that recursively calls itself at smaller universe
levels. Therefore, the one feature of \lang{} that truly requires impredicativity
is its countable universe hierarchy. \scw{I'm not sure the last part of this sentence
adds much: ``Although, lemmas such as the
admissibility of \rref{I-PiAlt} (Lemma~\ref{lemma:piintroalt}) not only simply
our mechanization, but also give better intuition on what our logical relation
means.'' Yes, we need impredicativity to define these lemmas, but without impredicativity
our logical relation means something else.}

The definition of $[[Interp I i A S]]$ has an almost one-to-one
correspondence to the Coq definition. The main difference is the
specification of $[[I]]$. In
Section~\ref{sec:logreldep}, we define $[[I]]$ as a function over
numbers less than $[[i]]$, the universe level. In Coq, we only require
$[[I]]$ to be function with the set of natural numbers as its domain.
In the Coq encoding of $[[InterpR i A S]]$ (Figure~\ref{fig:logrelrec}), we define $[[I]]$ as follows.
\begin{equation*}
  \begin{split}
    [[I]]   &\in [[SNat -> PowerSet STm]] \\
    [[I j]] &=
     \begin{cases}
      \ [[{A | exists S , InterpR j A S}]] & \text{when } j < i \\
      \ [[emptyset]] & \text{otherwise}
    \end{cases}
  \end{split}
\end{equation*}
Since $[[I]]$ is only applied to numbers strictly less than $[[i]]$ in
\rref{I-Set}, we can retroactively show that the set we return in the $j
\geq i$ case is junk data that does not affect the result of the logical
relation. This property allows us to recover the simple equation for $[[InterpR i A S]]$ shown in Figure~\ref{fig:logrelrec}.

Finally, in set theory, to show that two sets $[[S0]]$ and $[[S1]]$
are equal, it suffices to show the extensional property that $\forall
x, x \in [[S0]] \iff x \in [[S1]]$. We leverage this fact
occassionally in our presented proofs.
In Coq, sets of terms ($[[PowerSet STm]]$) is encoded as the type \texttt{tm ->
Prop}, a predicate over \lang{} terms.
In axiom-free Coq, predicates do not come with the extensionality
property. Given two predicates $P$ and $Q$, we can prove that $\forall
x, P(x) \iff Q(x)$, but we can not concldue that $P = Q$. While
predicate extensionality is not necessary in our development, we
assume it as an axiom since it is known to be consistent with Coq's
metatheory and helps bridge the gap between our mechanization and the
proofs we present.


% In Coq, there is a distinction between computable functions and
% relations that can later be proven to be functional. The former can be
% viewed as a strict subset of the latter in axiom-free Coq. To be more
% precise, given a relation \texttt{R : A -> B -> Prop} subject to the
% totality and functionality constraints ($\forall$ \texttt{a} $\in$
% \texttt{A}, there exists a unique \texttt{b} $\in$ \texttt{B} such
% that \texttt{R a b} is inhabited), we do not immediately obtain a function
% \texttt{F : A -> B} such that $\forall$ \texttt{a} $\in$ \texttt{A},
% \texttt{R a (F a)} is inhabited. However, the functional side
% conditions of a relation is clunky to express and tend to block
% automation. A simple workaround is to assume the axiom of unique choice, which
% is known to be consistent with Coq and allows us to induce a function \texttt{F
% : A -> B} once we have shown the relation \texttt{R : A -> B -> Prop}
% is functional. This approach would make our Coq development match
% the text version of our proof from Section~\ref{sec:logrelproof} more
% closely.

% However, we choose instead an axiom-free workaround and define
% \rref{I-Pi} as follows in our Coq mechanization.
% \begin{center}
%   \drule[]{I-PiCoq}
% \end{center}
% It should be easy to verify that the preconditions of
% \rref{I-Pi}, \rref{I-PiAlt}, and \rref{I-PiCoq} are all
% equivalent. After establishing Lemma~\ref{lemma:logreldeter}, it is
% possible to further show that the conclusions of the rules are
% equivalent, too.\scw{If it is easy, you should have already done it.
% Unless it is really long and boring.}

% This formulation allows us to derive Lemma~\ref{lemma:piintroalt}
% before we even show that our logical relation is
% functional/deterministic, but does not affect the proof structure
% otherwise.
% We choose to keep this discrepancy between the Coq development and the
% description of the logical relation presented in Section~\ref{sec:logreldep} since the
% skolemization process is more intuitively expressed in terms of
% function symbols rather than relation symbols. Otherwise, we do not
% see a clear advantage of \rref{I-PiCoq} over \rref{I-Pi} in set
% theory, where there is no distinction between computable functions and
% functions in general. \scw{not sure I follow this last bit}

\subsection{Automation}
\label{sec:automation}
Our Coq mechanization heavily uses automation, though instead of
defining custom tactics, we rely mostly on off-the-shelf tools such as
Autosubst 2~\citep{autosubst2} and CoqHammer~\citep{czajka2018hammer}.

We use the Autosubst 2 framework to specify our syntax in HOAS and
produce Coq syntax files in de Bruijn representation. Additionallly,
Autosubst 2 provides a powerful tactic \texttt{asimpl} that
can be used to prove the equivalence of two terms constructed using
the primitive operators provided by the framework. This greatly
simplifies the reasoning about substitution in our development as
almost all substitution related properties about the syntax are
immediately discharged by \texttt{asimpl}.

For other automation tasks that are not specific to binding, we use
the powerful \texttt{sauto} tactic provided by CoqHammer to write
short and declarative proofs. For example, here is a one-line proof of
the triangle property about parallel reduction, from which the diamond
property (Lemma~\ref{lemma:pardiamond}) follows as a corollary.
The triangle property states
that if $[[a => b]]$, then $[[b]]\Rightarrow [[a]]^*$, where $[[a]]^*$
is the Takahashi translation~\citep{takahashi-parallel-reduction}
which roughly corresponds to simultaneous reduction of the redexes in
$[[a]]$, excluding the new redexes that appear as a result of
reduction.
\begin{minted}{coq}
Lemma par_triangle a : forall b, (a ⇒ b) -> (b ⇒ tstar a).
Proof.
  apply tstar_ind; hauto lq:on inv:Par use:Par_refl,par_cong ctrs:Par.
Qed.
\end{minted}
In prose, the triangle property can be proven by induction over the graph of
\mintinline{coq}{tstar a}, the Takahashi translation. Options \texttt{inv:Par}
and \texttt{ctrs:Par} say that the proof involves inverting and constructing
of the derivations of parallel reduction. The option
\texttt{use:Par\_refl,par\_cong} allows the automation tactic to use the
reflexivity and congruence properties of parallel reduction as lemmas.

The flag \texttt{lq:on} tunes CoqHammer's search algorithm.  While this flag
appears arcane, when developing our proof scripts we never specify this option
manually. Instead, we first invoke the \texttt{best} tactic provided by
CoqHammer, specifying only the \texttt{inv}, \texttt{ctrs}, and lemmas that we
want to use. The \texttt{best} tactic then iterates through possible
configurations and provides us with a replacement with the tuned performance
flags that save time for future re-execution of the proof script.

The automation provided by CoqHammer not only gives us a proof that is shorter
and more resiliant to changes, but also gives useful documentation for readers
who wish to understand how the underlying proof. Although automation performs
extensive search, it does not use lemmas or invert derivations that are not
specified in the \texttt{use} or \texttt{inv} flag.

\subsection{Extraction of a conversion algorithm}
\label{sec:conversionalgo}
A constructive proof of the existence of $\beta\eta$-normal form
for well-typed terms (Corollary~\ref{corollary:exbetaeta}) induces a
normalization algorithm. From this normalization procedure, we can
derive a normalize-and-compare algorithm. Given two well-typed terms
$[[a]]$ and $[[b]]$, to know whether $[[a <=> b]]$, we apply the
normalization algorithm on $[[a]]$ and $[[b]]$ to obtain $\beta\eta$
normal forms $[[f0]]$ and $[[f1]]$. The algorithm then returns true
exactly when $[[f0]]$ and $[[f1]]$ are syntactically equal. This
algorithm is referred to as normalize-and-compare by
\citet{pierce2004advanced}.

The soundness of the algorithm is immediate. The completeness of the
algorithm is justified the confluence property of the untyped
reduction relation. Suppose $[[a <=> b]]$, $[[a =>+ f0]]$, $[[b =>+
f1]]$ but $[[f0]]$ is syntactically distinct from each
other. By the transitivity of convertibility, we have $[[f0 <=> f1]]$.
Because $[[f0]]$ and $[[f1]]$ are both in
$\beta\eta$-normal forms and can only reduce to themselves, we must
have $[[f0 = f1]]$. Contradiction.

In our development, since our countable universe hierarchy
relies on impredicativity from the metatheory, we encode our
properties in Coq's \texttt{Prop} sort, which is not very suitable for
code execution. On the other hand, due to our heavy reliance on
automated proof search, even if we were able to extract an algorithm from \texttt{Prop},
the algorithm would be unpredictable because its definition depends on
the specific choices made by the proof search algorithm.

However, with a little more effort, it is possible to recover a
precise algorithm. The first step is to define a deterministic
small-step reduction relation that is normalizing; that is, the
relation can always find a normal form if there exists one. A good
candidate is the leftmost-outermost reduction strategy. Its
normalizing property is standard and can be proven using the
factorization technique discussed in
\citet{takahashi-parallel-reduction, factorization-essentially}. By
composing the existence of normal form and the fact that the
deterministic relation is normalizing, we can derive show the
accessibility of the deterministic reduction relation
(\mintinline{coq}{Acc} in Coq), and use the accessibility proof as
an induction metric to define an executable algorithm.

\section{Related Work}
\label{sec:relatedwork}

\scw{Maybe it would be useful to include a chart here, so that readers can
  easily keep track of the features of the various languages.  i.e. which ones
  include large eliminations? type-directed equivalence? impredicative prop?
  inductive datatypes? what are their line counts?}

Proof by logical relations does not come with a precise definition. In
the most general sense, a logical relation can be viewed as a
practical technique that uses a type-indexed relation to assign
meanings to types and strengthen the induction hypothesis for the
property of interest. The original idea of this technique can be
traced back to
\citet{tait1967:reducibility}. \citet{tait1967:reducibility} maps
types to sets of terms satisfying certain properties related to reduction.
The same idea is explained in \citet{girard1989proofs} and extended to
prove the strong normalization property of System F.

Tait's method has been successfully applied to dependently typed
languages.  \citet{Martin-Lof-1973}, \citet{luo1990extended},
\citet{geuvers1994short}, and
\citet{barendregt:lambda-calculi-with-types} are some of the earlier
works that prove strong
normalization for different dependently type systems using Tait's notion of
reducibility.

\scw{Should give Martin L\"of credit for first consistency proof.}
\scw{What techniques do these three proofs use? How is it different from
your proof? What about Luo, which
introduced a universe hierarchy? What about categories with families, or
other ways of showing consistency?}

% Some of these proofs are still reapplied in more recent works. For
% example, the technique for proving strong normalization by
% \citet{geuvers1994short} is adapted by \citet{moon2021graded} to show
% the normalization property for a dependently typed system extended with
% modalities.

The pen and paper representation of the logical relation proofs
can be challenging to adapt to a theorem prover since a lot of details
are hidden behind the concise notations.
As an example, \citet{geuvers1994short} presents the interpretation for types as
an inductively defined total function over the set of syntactically
well-formed types. Despite the notation for the logical relation as a
simply typed function that takes a type and returns some set, the
interpretation function in reality is a dependent function whose
return type depends on the derivation of the well-typedness of its
input. The well-typedness derivation and the proof of the
classification theorem are needed relevantly in the body
of the interpretation function to decide whether an argument of an
application should be erased during interpretation. Due to the
impredicativity of the object language, \citet{geuvers1994short}'s
proof cannot be encoded in Agda, which has a predicative
metatheory. Due to the use of proof-relevant derivations, even in
Coq, a proof assistant that supports impredicativity, one would need
to constantly juggle between the impredicative but irrelevant sort
\texttt{Prop} sort and the predicative but relevant sort
\texttt{Type}.

More recent works such as \citet{Abel12}
and\citet{abel2008betaeta} make their definitions more explicit and
precise and thus easier to encode in proof assistants. Our definition
of logical relation is reminiscent to their definition of a
semantic universe hierarchy, though our logical relation is defined to
be closed under expansion with respect to parallel reduction rather
than weak head reduction. Furthermore, \citet{Abel12} and
\citet{abel2008betaeta} use the semantic universe hierachy as a
measure to define Kripke-style logical relations, from which they
derive the correctness of their conversion algorithms. In our work, we
use the semantic universe hierarchy directly because it is sufficient
for deriving consistency and later normalization.

\citet{decagda} mechanizes in Agda the decidability of type
conversion rule for a dependently typed language with one predicative
universe level and typed judgmental equality with function
$\eta$-law. They
use a Kripke-style logical relation parameterized over a
type-directed equivalence relation satisfying certain
properties to facillitate the reuse of their definition. The
logical relation is defined using the induction-recursion scheme,
which is available in Agda but not in Coq.
\citet{martin-lof-a-la-coq} manages to encode the logical relation
from \citet{decagda} in the predicative fragment of Coq and further
extends the decidability of type conversion result
from~\citet{decagda} to the decidability type checking of a
bidrectional type system.

\citet{anand2014towards} mechanizes the metatheory of
Nuprl~\citep{constable1986implementing} in Coq. The metatheory is an
extensional type theory with features such as dependent functions,
inductive types, and a full universe hierarchy. \citet{nbeincoq}
mechanizes the normalization-by-evaluation algorithm in Coq for a
dependently typed language with one predicative universe, similar to
\citet{decagda} and \citet{martin-lof-a-la-coq}. Both
\citet{anand2014towards} and \citet{nbeincoq} leverage the
impredicative \texttt{Prop} sort of Coq to define the interpretation
of dependent function types and thus are closely related to our
mechanization. However, instead of explaining the inductive
logical relation as a convoluted workaround to the lack of
induction-recursion in Coq, we give a self-contained explanation of
our logical relation.

Finally, \citet{barras2010sets, Wang2013SemanticsOI} assign
set-theoretic semantics to dependent type theory in Coq. Unlike the
previous mechanization efforts, which primarily focus on predicative
type theory and more direct reducibility models,
\citet{barras2010sets, Wang2013SemanticsOI} tackle extensions of
$CC^\omega$, a system that incorporates a predicative universe on top
of the impredicative sort in Calculus of Constructions. We choose to
focus on a simple term model so we do not have to take the extra step
of mechanizing mathematical objects such as sets and domains.

\section{Discussion}
\label{sec:discuss}
\yl{I'm not sure how strong of a statement we can make about our proof
  technique. We've already demonstrated how to address type-level dependency
  when defining a logical relation through a simple example. Claiming that our
  proof structure is better seems quite ambitious, but I think there's a
  middle point where we claim that adding moderate features like typed
  reduction doesn't instantly make our code size expand all the way from 1000
  to 20,000 without saying the other developments are just verbose for no good
  reason}
\scw{I think we can find reasons for much of the differences. Am I missing any?
While it would be difficult to assign numbers to each of the deltas, I think it
is believable that when put together they add up to a lot.
\begin{itemize}
\item We don't include inductive or coinductive datatypes. We don't include
cumulativity. We don't include Prop. We don't include universe polymorphism.
\item We state our equality algorithmically instead of declaratively. On one
  hand, this gives us automatic inversion principles when working with
  definition. Furthermore, we don't need to prove the equivalence between an
  algorithmic version and a declarative specification.
\item Our equality requires a simple decision algorithm and isn't type directed.
\item We don't prove decidability of type checking. (And, it is not provable
  for our system, because we lack type annotations on functions. We should
  point this out.)
\item Our logical relation is unary and untyped. The latter means that we don't
  require the bookkeeping of a Kripke logical relation when reasoning about
  open terms. I don't know why unary relations are shorter.
\item CoqHammer leads to short proofs.
\end{itemize}
}
\yl{ Just one more technical point to add, though it's in the text already:
  the logical relation is closed backward by full reduction rather
  than weak-head/deterministic reduction. This requires an early
  confluence result to show that the logrel is
  deterministic/functional but simplifies everything else
  (e.g. conversion is justified immediately by our preservation
  theorem, but that is not the case if you use weak head reduction).\\ \\
  Also, regarding the first point, cumulativity only exists in
  Barras's work. Inductive, (maybe coinductive?), can be found in
  nuprl, metacoq, and maybe Barras's work.\\ \\
  The 20,000 - 30,000 LoC mechanization are all about small languages
  with pretty much the same features as our language except for your
  second and third bullet point. martin-lof a la coq, Abel's work, and
  nbe in coq aren't that richer in feature otherwise. None includes
  cumulativity (they only have one predicative universe)\\ \\
  The 400,000 NuPRL in Coq probably falls into a different cateogry
  because they are trying to mechanize a full practical language}


The short consistency proof we present achieves the goal of
demonstrating the technique of proof by logical relation for dependently typed
languages. However, what remains unanswered is what makes our development
significantly shorter compared to others. Are we proving simpler results, for
smaller languages, are we making more use of automation, or is our proof
technique genuinely more efficient?
% focus on the following question: why is our proof,
% even with its extension to the existence $\beta\eta$-normal form, so much
% shorter than the other mechanized results from \citet{decagda,
% nbeincoq, martin-lof-a-la-coq}?


First, the metatheoretic properties that we prove are indeed simpler.  Unlike
developments that mechanize the correctness of a type-directed conversion
algorithm, we only show the existence of normal forms for open and closed
terms and state our properties in terms of an untyped reduction relation. This
avoids a lot of the scaffolding related to the specification of the algorithm
and the proof obligations that the algorithm is sound and complete with
respect to the declarative specification of the type system.
As a result, our logical relation, unlike the ones from \citet{decagda,
  nbeincoq, martin-lof-a-la-coq, anand2014towards}, maps from types to
predicates rather than relations. \scw{How does this follow? Why do we need unary relations where they need binary relations?} The need for a relational model is
directly related to the metatheoretic property one wants to
prove. \citet{anand2014towards} requires a relational model to capture
the extensionality of their type system, whereas \citet{decagda,
  martin-lof-a-la-coq, nbeincoq} uses a relational model to derive the
injectivity of $\Pi$ types and justify the validity of
$\eta$-conversion among other properties.
Since \lang{} uses an untyped conversion rule, type conversion can be
done through the \emph{normalize-and-compare}
strategy described in \citet{pierce2004advanced}. The decidability of
normalize-and-compare is implied by the existence of
$\beta\eta$-normal form, which follows from our logical
predicate.

\scw{I'm getting confused by this paragraph. Does this reorganization sense:
  Our language is simpler than Nuprl, because it doesn't have extensional
  equality. It is simpler than Agda, because it doesn't have type-directed
  equality. Both of these cases require the definition of a binary logical
  relation, that defines a notion of semantic equality between terms. This
  relation justifies the injectivity of $\Pi$ types and justify the validity
  of $\eta$-conversion among other properties.}  \scw{Furthermore our proof is
  also simpler because we don't need prove the correctness of the NBE
  algorithm, which is used to show the decidability of Agda's type-directed
  equivalence. Therefore, we don't need to define this algorithm and show that
  it is sound and complete with respect to the type-directed
  equality. Instead, to show the decidability of our untyped equivalence, we
  need only show that terms have $\beta\eta$ normal forms. }


In terms of our proof technique, we close over our semantically valid types
and terms in \rref{I-Par, I-Bool} using the non-deterministic parallel
reduction relation, while \citet{decagda,nbeincoq} employ a deterministic weak
head reduction relation. Our use of a non-deterministic reduction strategy
means that we need confluence to prove the functionality of our logical
relation. However, the benefit is that it immediately gives us a semantic
justification of the conversion rule (Lemma~\ref{lemma:logrelcoherence}).
% In particular, we obtain the confluence
% result of reduction at a very early stage before we even define our
% logical relation.

With untyped conversion,
we sidestep the relational, Kripke-style logical relation found in
other mechanized proofs. \scw{Need to define Kripke-style. Also the other
proofs need Kripke style because they are defining typed relations, not untyped
relations. }
However, our early dependence on confluence
before the fundamental theorem is established can be alarming.
In a system with type-directed reduction,
confluence is not immediately available because it
depends on $\Pi$-injectivity, which is usually only proven after the
fundamental theorem.\scw{confluence depends on Pi injectivity? I thought
it was only needed for subject reduction}\yl{it's
transitive. Confluence depends on subject reduction, which in turn
depends on pi injectivity. Maybe it's worth spelling out the details}
Fortunately, there are syntactic workarounds for the $\Pi$-injectivity
problem that allow us to recover confluence property independently
from the logical relation. \citet{siles2012pure} generalize the
notion of Type Parallel One Step Reduction from \citet{adams2006pure}
to syntactically prove $\Pi$-injectivity for arbitrary Pure Type
Systems. \citet{weirich:systemd} add $\Pi$-injectivity to their
equational theory, thus allowing subject reduction to be proven
independently from confluence. By adopting these techniques that allow
us to derive confluence early even for systems with type-directed
reduction, we believe our proof technique can significantly shorten
the existing logical relation proofs for systems with typed judgmental
equality and more complex $\eta$ laws. We leave that as part of our
future work.
% Therefore, we believe that even in a
% system where type-directed reduction is required (e.g. a system with
% the unit $\eta$-law) in the logical relation, the proof can still be carried
% out in a structure similar to the one we have presented.
\scw{Not sure that I understand this paragraph}
\yl{Reworded slightly to emphasize it's future work that we haven't
  done and it is speculative}

Finally, despite our earlier claim that our metatheoretic properties
are not as strong as some of the related work, we can strengthen our
results through syntactic means. For example, the
normalize-and-compare strategy does not induce an efficient algorithm
for type conversion, like the ones from \citet{decagda} and
\citet{martin-lof-a-la-coq}. However, with the standard syntactic
techniques from \citet{takahashi-parallel-reduction,
factorization-essentially}, we can prove that leftmost-outermost
reduction is a normalizing reduction strategy, from which we can
separately show the correctness a more efficient algorithm that
reduces the two terms to weak head normal form before recursively
comparing their subcomponents. We believe factoring such properties
out of a logical relation is valuable, as it helps us identify the
part of our proof that requires extra strength from the metatheory.
\scw{Why don't we just use leftmost-outermost reduction in the first place?
Do we even need nondeterministic parallel reduction?}
\yl{The conversion uses full reduction. Nondeterministic reduction
  makes it harder to show that convertible types have the same
  meaning. Maybe it would require us to prove factorization in our
  development but it definitely simplifies the determinism proof
  (confluence is no longer required before the fundamental
  lemma). }

% Finally, it is worth pointing out that all systems we have discussed
% so far builds a relational model for their logical relation.

% Recall
% that our logical relation takes the form $[[InterpR i A S]]$ where
% $[[S]]$ is a set of terms. In a relational model, each type is
% interpreted as a partial equivalence relation over terms rather than a
% set. A relational model is necessary for an extensional type theory
% such as Nuprl, though \citet{nbeincoq,decagda,martin-lof-a-la-coq} all
% use a relational model either to justify the function $\eta$-law or to
% derive $\Pi$-injectivity. In Section~\ref{sec:extension}, our $\eta$
% law for function is baked into the untyped reduction
% relation and therefore a relational model is not needed.
% \scw{would it be difficult to extend your proof to be a PER?}

% The dependently typed systems we have discussed so far also vary
% greatly in expressiveness. For example, the Calculus of
% Constructions~\citep{CoC} and MLTT without universe levels are unable
% to encode large elimination. \citet{decagda} and \citet{nbeincoq} lack
% identity types. % \citet{nbeincoq} lacks $\eta$-law for functions.
% Among
% the mechanized systems we have discussed so far, only
% \citet{anand2014towards} has a full universe hierarchy.
% Our object language \lang{}, while small, has a decent coverage of
% features commonly seen in dependently typed languages, including
% dependent pattern matching, dependent function types, a full universe
% hierarchy, an intensional identity type. We hope features such as
% type-directed reduction (necessary for unit $\eta$-law) and
% impredicative sorts can be implemented in a similarly streamlined
% fashion and we will leave those extensions as part of our future work.

% To end this section, we
% \scw{should this be a new subsection?}
% The final question we want to address is: why is our proof,
% even with the extension from Section~\ref{sec:extension}, so much
% shorter than the proofs from \citet{decagda, nbeincoq,
%   martin-lof-a-la-coq}?


% This contrasts our development with
% \citet{martin-lof-a-la-coq}, where the irrelevance property turns out to be the most
% difficult property to prove due to the complexity of the equality
% judgment used to define the logical relation. In our system, the
% irrelevance property (Corollary~\ref{lemma:logrelcoherence}) is a
% direct consequence of Lemma~\ref{lemma:interppreservation},\scw{refer to
% lemma name} which is
% straightforward after we prove the results about parallel
% reduction in Section~\ref{sec:spec}. In other words, we keep the
% the logical relation itself minimal at the cost of extra lemmas that can be proven
% through syntactic means independently from the logical relation.
% For example, as commented near the end of Section~\ref{sec:extension},
% our normalization property (Corollary~\ref{corollary:exbetanf})
% % can induce a decision procedure for type conversion by reducing two
% % terms to $\beta\eta$-normal form and check for their syntactic
% % equivalence. This decision procedure would be inefficient compared to
% % NbE or the algorithm from \citet{martin-lof-a-la-coq} that reduces terms
% % to weak head normal and checks for the equivalence of subterms
% % recursively
% does not immediately induce an efficient decision procedure, but it is
% possible to recover an efficient algorithm by reasoning about untyped
% lambda terms.

% the concision of
% our proof can be largely attributed to the fact that we bake into the
% logical relation only the minimum amount of information that is the
% most conducive to the proof of the metatheoretic result.

% Another key to our proof is the very early establishment of the confluence
% property of the paralell reduction relation
% (Lemma~\ref{lemma:pardiamond}). This property is used in
% Lemma~\ref{lemma:interppreservation} to show that the interpretation
% of a type is preserved under evaluation. That is, if $[[InterpR i A S]]$ and $[[A => B]]$, then we also have $[[InterpR i B S]]$.
% In a system with typed directed reduction, the confluence result is
% harder to establish since confluence requires subject reduction, which
% circularly depends on $\Pi$-injectivity, a consequence of
% confluence~\citep{siles2012pure}. There are different workarounds to
% this problem. \citet{siles2012pure} proposes a syntactic approach by
% defining a type system where the confluence result is
% directly provable and later show that the system of interest is
% equivalent to the system with the confluence property.
% \citet{decagda} uses a relational model and the relational counterpart
% of Lemma~\ref{lemma:extwn} to derive $\Pi$-injectivity. The relational
% model is parameterized by a typed indexed equivalence relation and
% is reused to prove derive different properties in their
% development. Another perhaps simpler approach is to simply
% extend the judgmental equality with rules about
% $\Pi$-injectivity~\citep{weirich:systemd}. This allows subject
% reduction to be proven independently from confluence and
% $\Pi$-injectivity can later be shown to be admissible. We find the
% approach from \citep{weirich:systemd} the most lightweight as it
% allows us to derive confluence early on even in systems with typed
% conversion. \scw{Maybe mention my $\eta$-equivalence paper here somewhere?}

% In cases where the judgmental equality does not leverage type information heavily
% (e.g. $\eta$-law for the unit type), it might be possible to show that
% $\Gamma \vdash a \equiv b : A$ is equivalent to the conjunction of
% $[[G |- a : A]]$, $[[G |- b : A ]]$, and $[[a <=> b]]$. If such a
% property holds (we believe this is likely true for both
% \citet{decagda} and \citet{martin-lof-a-la-coq}), we can reuse our existing logical relation in
% terms of untyped parallel reduction to show the decidability of type
% conversion. Otherwise, to fully model the system, we need to bake
% typing information into our logical relation and we need to redefine
% our logical relation in Kripke-style so we can relax the scoping
% constraint in order to prove adequacy, though a relational model would
% still be unnecessary as long as the $\eta$ laws are baked into the
% typed directed relation. \scw{not sure I understand this last bit}

% Since confluence plays such as key role in our proof, we are uncertain
% how to generalize our technique to systems where confluence does not
% hold, and we will investigate those scenarios in our future work.
% \scw{What systems are you thinking of? Or do you mean more generally
% that this technique only works for languages where the definition of
% equality is based on joinability of parallel reduction?}

% We are able to avoid the complexivity of a Kripke-style logical relation
% by defining our logical relation in terms of untyped parallel
% reduction, which does not impose any scoping constraint on the
% terms.


% Why is it that the justification of $\eta$ law
% requires a Kripke-style relational model in all three developments
% but not ours? Are we ``cheating'' by defining \lang{}'s equational
% theory using an untyped conversion rule? Instead of answering the
% questions one by one, we clarify the design of our type system and our
% proof technique so the answers to those questions are self-evident.

% The key to the shortness of

\section{Conclusion}
\label{sec:conclusion}
In this work, we show a short and mechanized proof of consistency
through proof by logical relation for a fully dependently typed
language with a full universe hierarchy, an intensional identity type,
and large elimination. We show the extensibility of our approach by
proving the existence of $\beta\eta$-normal forms with only small
and mechanical changes to our proof development. Our Coq mechanization
leverages existing Coq libraries for reasoning about metatheory and
general-purpose automation, allowing us to significantly reduce the
verbosity typically associated with mechanized proofs and recover a
declarative proof style that is usually only available in pen and
paper. Our development shows that proof by logical relation for
dependent types should be more accessible since it does not always
require months of effort to implement. We hope our proof can inspire
researchers to more actively mechanize results such as consistency,
normalization for dependent type theory.





% Type soundness can be proven through a syntactic
% approach~\citep{syntacticsoundness} as a corollary of two properties:
% progress and preservation. % The syntactic type soundness proof
% % varies in complexity depending on the underlying type
% % system. For example, a type system that tracks information flow would
% % require additional structural rules related to security levels. In
% % this paper, we focus on one specific type of complexity: the
% In Figure~\ref{fig:stlcsoundness}, we summarize the structure of the
% syntactic type soundness proof for the simply typed lambda
% calculus. Each lemma can be proven by structural induction over the
% typing derivation, while using the previous established results as
% lemmas for specific cases that do not immediately follow from the
% induction hypothesis. If we make our language more complex by adding
% full dependent type support, the overall structure remains almost
% identical.


% NbE in Coq

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{refs}

%%
%% If your work has an appendix, this is the place to put it.

\end{document}
\endinput
%%
%% End of file `sample-acmsmall.tex'.
