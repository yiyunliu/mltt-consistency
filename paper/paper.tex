%%
%% This is file `sample-acmsmall.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `acmsmall')
%%
%% IMPORTANT NOTICE:
%%
%% For the copyright see the source file.
%%
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-acmsmall.tex.
%%
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%%
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[acmsmall]{acmart}
\usepackage{ottalt}
\usepackage{minted}
\usepackage{xspace}
\usepackage{tcolorbox}
\usepackage[para]{footmisc}
\definecolor{lightgray}{gray}{0.75}
\newcommand{\dotv}[2]{\href{#1}{\texttt{#1}}{\texttt{:#2}}}
\newcommand{\lang}{$\lambda^H$\xspace}
\inputott{rules}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{A Short and Mechanized Consistency Proof for Dependent Type Theory}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Yiyun Liu}
\orcid{0009-0006-8717-2498}
\affiliation{
  \institution{University of Pennsylvania}
  \city{Philadelphia}
  \country{USA}
}
\email{liuyiyun@seas.upenn.edu}

\author{Stephanie Weirich}
\orcid{0000-0002-6756-9168}
\affiliation{
  \institution{University of Pennsylvania}
  \city{Philadelphia}
  \country{USA}
}
\email{sweirich@seas.upenn.edu}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
% \renewcommand{\shortauthors}{Trovato et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Proof by logical relation is a powerful technique that has been used
to derive metatheoretic properties of type systems, such as
consistency and parametricity. While there exists a
plethora of introductory materials about logical relation in the
context of simply typed or polymorphic lambda calculus, a streamlined
presentation of proof by logical relation for a dependently language
is lacking. In this paper, I present a short
consistency proof for a dependently typed language that contains a
rich set of features, including a full cumulative universe
hierarchy, booleans, and an intensional identity type. We have
fully mechanized the consistency proof using the Coq proof assistant
in under 1000 lines of code.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Logical Relation, Dependent Types, Logical Consistency, Coq}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
% Depending on its application, we care about certain metatheoretic
% properties about a type system. As a programming language, we may care
% about type soundness, which states that a well-typed never gets stuck
% during evaluation.
When a dependently type system is used as a program logic where terms
encode proofs, we want our type system to be logically consistent,
meaning that the empty type is not inhabited.

The consistency proofs of various dependently typed systems, including Martin-Lof's
type theory and the Calculus of Constructions, have long been
available in the literature. In particular, recent works such as \citet{nbeincoq},
\citet{decagda}, and \citet{martin-lof-a-la-coq} mechanize stronger
results related to the decidability of type conversion or type
checking of dependently typed systems, from which consistency can be
derived as a corollary.

The underlying technique of the forementioned
works is proof by logical relation,
which involves interpreting types as reducibility predicates,
representing sets of terms satisfying certain properties with respect
to the reduction relation. While the proof technique and the
consistency result for dependent types are both well-established,
there is a severe lack of rigorous and accessible material that shows
how proof by logical relation can be applied to dependently typed
systems.

Introductory materials about logical relations such as
\citet{skorstengaard2019introduction}, \citet{harper2016practical}
start from logical relations for simply typed languages, and
eventually extend the technique to build a relational model for System
F in order to derive
parametricity. \citet{harperkripke} gives a gentle introduction on how
logical relations for closed terms can be extended to talk about open
terms so we can derive properties such as normalization for well-typed
open terms. Overall, the introductory texts about logical relations
cover systems and properties with varying degrees of complexity, from
simply typed to polymorphicly typed, logical predicate to logical
equivalence, closed terms to open terms.

The glaring gap here is the
lack of fully dependently typed systems where computations may appear
at the type-level. It is far from obvious why proof by
logical relation is even applicable to dependent types, since the type
may very well-be a computation that is yet to be evaluated.
While it is assuring that proof by logical relations for dependent
types is available in mechanized forms, % the key to address the
% complexities of dependent types is obscured in
\citet{nbeincoq,decagda,martin-lof-a-la-coq} all involve relational,
Kripke-style models that obscure the technique for addressing
type-level computation. The added complexivity is evident
from the size of their code base. All three developments involve 20
thousand to 30 thousand lines of Coq or Agda code.

The goal of this paper is to give a tutorial on proof by logical relation for
dependent types in a simple and digestable format.
The system we present is small but covers
important features that are only available or require special treatments in
dependently typed systems. We choose boolean
types over natural numbers as our base type for simplicity, but include an
intensional identity type in our type system to show how indexed
types are treated in a logical relational proof. Unlike
\citet{nbeincoq,decagda,martin-lof-a-la-coq} but similar to
\citet{anand2014towards}, we include an infinite hierarchy of
universes to not only support type-level computations, but also avoid
the unnecessary code duplication pointed out by \citet{nbeincoq} when
big and small types are treated non-uniformly.

Our consistency proof is short and fully mechanized. The proof scripts
involve less than 1000 lines of manually written Coq code. In fact, what we find
encouraging is that among the 1000
lines of Coq code, 400 lines are related to the specification of the
type system, semantics, and properties related to untyped lambda
terms. The semantic type soundness proof through logical relation
takes almost the same amount of code as our syntactic type soundness
proof!
Thanks to the conciseness of
the proof, we are able to present it in detail in
Sections~\ref{sec:logreldep} and \ref{sec:logrelproof}. Moreover, the
structure of our mechanization closely corresponds to the proof we
present in the text, enabling us to label at the footnote each lemma
directly to their counterpart in the proof script for the readers to
reference and validate.

The technique we use is most similar to the one from \citet{nbeincoq},
which leverages impredicativity to define the logical
relation as a partial function.
Rather than framing impredicativity as a
mechanism for encoding induction
recursion~\citep{induction-recursion-dybjer}, a scheme in which
semantic models (including logical relations) for dependent types can
be defined, we opt for a direct explanation through the informal
language of sets, where impredicativity manifests in the form of
second-order logical formulas and thus more intuitive to grasp
for readers with a general mathematical background.

In Section~\ref{sec:extension}, we extend our logical
relation to prove the stronger property that every well-typed term
has a normal form. Most interestingly, we find that extending the
language with
$\eta$ rule for functions and the metatheoretic result to normalization for open terms are
mostly orthogonal to the fact that the language is dependently
typed. In our mechanized proof, the overall
structure of the logical relation remains unchanged, and the additional
proof obligations are mostly related to properties about the untyped
lambda calculus, all of which can be derived through syntactic
means.
In other words, once we have established the base technique for
proof by logical relation for dependent types, we can factor out the
complexities of an extension the are not specifically related to dependent
types; such an extension, if desired, may be studied in the context of
a simply typed language and later ported into a dependently typed setting.

In Section~\ref{sec:logrelmech}, we discuss the details about our
mechanization, including our use of existing libraries such as
Autosubst 2~\citep{autosubst2} for handling bindings and CoqHammer~\citep{czajka2018hammer} for general-purpose
automation.
In Section~\ref{sec:relatedwork}, we discuss how our proof
relates to existing proofs by logical relations for dependent types in
the literature.

We hope our success at creating a short and mechanized proof for a
relatively feature-complete language will encourage future researchers
to leverage the tool of logical relation more often in mechanized
proofs for dependent types.

% A naive attempt at proving consistency through induction over the
% typing derivation would fail since the inductive hypothesis is not
% strong enough to derive the consistency result. Instead, one typically
% relies on the technique referred to as proof by logical relation to
% interpret types as reducibility predicates to strengthen the inductive
% hypothesis.




% This paper is specifically
% about establishing logical consistency for a fully dependently typed
% system with an infinite universe hierarchy and support for large
% elimination .
% The type system, presented in Section~\ref{sec:spec}, is
% most similar to Martin-Lof's predicate type theory with the minor
% difference that type conversion is based on untyped equality.


% Rather,
% our goal is to present the proof in a form that is digestable by a
% working type theorist and can be more readily mechanized in a proof
% assistant. Compared to existing efforts at mechanizing logical
% consistency or stronger properties such as existence of normal
% form~\citep{nbeincoq},
% decidable type checking~\citep{decagda}, our work is minimal since it requires very
% little scaffolding and therefore results in an extremely succinct
% proof of under 1000 lines of manually written Coq code for a dependent
% type theory that is reasonably complete in its features.

% The key technique that underlies our consistency proof is proof by
% logical relation. In
% Section~\ref{sec:spec}, we present the dependent type theory of
% interest. In Section~\ref{sec:logreldep}, we give the definition
% of the logical relation for the dependent type theory. Rather than
% presenting the logical relation as an inductive-recursive definition,
% we use the more elementary concept of a partial function to capture
% the interpretation of types. The alternative representation requires us
% to show that the set of equations indeed defines a partial function;
% that is, for each input, there should always be a unique
% output.
% From the interpretation function, we can define the semantic
% typing judgment for the set of lambda terms.
% In Section~\ref{sec:logrelproof}, we prove the fundamental theorem,
% which states that syntactic typing implies semantic typing. Once the
% fundamental theorem is established, logical consistency follows as a
% trivial corollary. In Section~\ref{sec:logrelmech}, we point out the
% specifics related to the Coq mechanization of the proof described in earlier
% section.
% Finally, in Section~\ref{sec:relatedwork}, we give a short survey of
% existing literature related to logical consistency about dependent
% type theory.

\section{Specification of a Dependent Type Theory}
\label{sec:spec}

\begin{figure}[h]
\[
\begin{array}{lcll}
\mathit{Natural\ numbers}\\
[[i]],[[j]],[[n]] & \in &  [[SNat]] &  \\ \\

\mathit{Contexts}\\
[[G]]       & ::= & [[empty]]\ |\ [[G ++ A]] &  \\ \\
\mathit{Terms}\\
[[a]],[[b]],[[c]],[[t]],[[p]],[[A]],[[B]] & ::= & [[Set i]]\ |\ [[var i]]\  |\ [[Void]]
                  & \mbox{universes, variables, empty type} \\
            & |   & [[Pi A B]]\ |\ [[\ A a]]\ |\ [[a b]]
                  & \mbox{function types, abstractions, applications} \\
            & |   & [[a ~ b : A ]]\ |\  [[refl]]\ |\ [[J t a b p]]
                  & \mbox{equality types, reflexivity proof, J eliminator} \\
            & |   & [[Bool]]\ |\  [[true]]\ |\  [[false]]\ % |\  [[if a b0 b1]]
                  & \mbox{boolean type, true, false} \\
            & |   & [[if a b0 b1]]
                  & \mbox{if} \\ \\
\mathit{Renaming}\\
[[xi]] & \in & [[SNat -> SNat]] & \\ \\
\mathit{Substitution}\\
[[rho]] & \in & [[SNat -> STm]] &
\end{array}
\]
  \caption{Syntax of \lang}
  \label{fig:syntax}
\end{figure}

% \begin{figure}[h]
%     \[
%       \begin{array}{lll}
%         \mathit{Curried\ Addition} \\
%         add(n) & := & m \mapsto n + m \\ \\
%         \mathit{Extension ([[xi]])} \\
%         [[(xi .: j) 0]]  & := & 0 \\
%         [[(xi .: j) Suc i]]  & := & [[xi j]] \\ \\

%         \mathit{Extension ([[rho]])} \\
%         [[(rho .: a) 0]]  & := & [[a]] \\
%         [[(rho .: a) Suc i]]  & := & [[rho i]] \\ \\

%         \mathit{Up ([[xi]])} \\
%         [[up xi]] & := & (add(1) \circ [[xi]]) , 0 \\ \\

%         \mathit{Renaming} \\
%         [[var i {xi}]] & := & [[xi i]] \\
%         [[(Set i) {xi}]] & := & [[Set i]] \\
%         [[Void {xi}]] & := & [[Void]]\\
%         [[(Pi A B) {xi}]] & := & [[Pi A{xi} B{up xi}]] \\
%         [[(\ A a) {xi}]] & := & [[\ A {xi} (#a {up xi}#)]] \\
%         [[(a b) {xi}]] & := & [[a {xi} (# b {xi} #)]] \\
%         [[Bool {xi}]] & := & [[Bool]] \\
%         [[true {xi}]] & := & [[true]] \\
%         [[false {xi}]] & := & [[false]] \\
%         [[(if a b0 b1) {xi}]] & := & [[if a{xi} b0{xi} b1{xi}]] \\
%         [[(a ~ b : A) {xi}]] & := & [[ a{xi} ~ b{xi} : A{xi}]] \\
%         [[refl {xi}]] & := & [[refl]] \\
%         [[(J t a b p ) {xi}]] & := & [[J t {xi} a {xi} b {xi} p{xi}]] \\ \\

%         \mathit{Lookup} \\
%         [[(G ++ A) 0]] & := &  [[A]] \\
%         [[(G ++ A) Suc i]] & := & [[G i]] \\ \\

%         \mathit{Drop} \\
%         [[drop 0 G]] & := & [[G]] \\
%         [[drop Suc i (#G ++ A#)]] & := & [[drop i G]] \\ \\
%       \end{array}
%     \]
%   \caption{Auxiliary Functions over Syntax}
%   \label{fig:auxdef}
% \end{figure}


In this section, we present the dynamics and statics of the
dependent type theory whose logical consistency will be proven in
Section~\ref{sec:logrelproof}. For concision, we refer to this system
as \lang.

The syntax of \lang can be found in Figure~\ref{fig:syntax}. We use
the unscoped de Bruijn representation for both our Coq development and
the informal presentation in our paper. We find de Bruijn
representation advantageous for specification since it leaves very
little ambiguity about the variable freeness side
conditions, making our proof more easily reproducible. Furthermore, as we discuss in
Section~\ref{sec:automation}, de Bruijn representation is much more
amenable to automated reasoning in proof assistants.
We adopt from \citet{autosubst} the notations for simultaneous
renaming, substitution, and other auxiliary definitions related to our
syntax, summarized in Figure~\ref{fig:auxdef}. We omit most of the
definitions of renaming and substitution and only show the definition
of a few representative cases of substitution.
\begin{figure}[ht]
  \begin{equation*}
    \begin{split}
      \begin{array}{lll}
        \mathit{IdentityRen} \\
        [[id i]] & := & [[i]] \\ \\
        \mathit{IdentityTm} \\
        [[idtm i]] & := & [[var i]] \\ \\
        \mathit{ConsRen ([[xi .: n]])} \\
        ([[xi .: n]])([[0]]) & := & [[n]] \\
        ([[xi .: n]])([[Suc i]]) & := & [[xi i]] \\ \\
        \mathit{ConsSubst ([[rho .: a]])} \\
        ([[rho .: a]])([[0]]) & := & [[a]] \\
        ([[rho .: a]])([[Suc i]]) & := & [[rho i]] \\ \\
        \mathit{Curried\ Add} \\
        [[up n i]] & := & [[n]] + [[i]]
      \end{array}
    \end{split}
    \qquad \qquad
    \begin{split}
      \begin{array}{lll}
        \mathit{UpRen} \\
        [[( up xi ) 0]] & := & [[0]] \\
        [[( up xi ) Suc i]] & := & [[ Suc ren xi i ]] \\ \\
        \mathit{Renaming ([[a < xi >]])} \\
        [[(Pi A B) < xi >]] & := & [[Pi A < xi > B < up xi >]] \\
        [[(a b) < xi >]] & := & [[a < xi > (# b < xi > #)]] \\
        \ldots \\ \\
        \mathit{UpTm} \\
        [[( up rho ) 0]] & := & [[var 0]] \\
        [[( up rho ) Suc i]] & := & [[ rho i < up 1 > ]] \\ \\
        \mathit{Substitution ([[ a { rho }  ]])} \\
        [[var i { rho }  ]] & := &  [[rho i]] \\
        [[(Pi A B) { rho }]] & := & [[Pi A { rho } B { up rho }]] \\
        [[(a b) { rho }]] & := & [[a { rho } (# b { rho } #)]] \\
        \ldots
      \end{array}
    \end{split}
  \end{equation*}
  \caption{Auxiliary Functions over Syntax}
  \label{fig:auxdef}
\end{figure}


% Without providing
% the full definition of the renaming and substitution functions, it is
% impossible to tell the binding structure from the syntax
% alone. Therefore, we annotate the syntax in Figure~\ref{fig:syntax}
% with the de Bruijn depth of each term, though we note that the
% syntax we work with is unscoped and the choice does matter when
% we extend our logical relation to open terms in Section~\ref{sec:extension}.

% Figure~\ref{fig:auxdef} shows the auxiliary definitions over the term
% syntax, including renaming, substitution, and operations over
% the typing context or substitution.
As a
dependent type theory, terms and types are collapsed into the same
syntactic category. Dependent functions take the form $[[Pi A B]]$ and
we use the notation $[[A -> B]]$ when the output type $[[B]]$ is not
dependent on the input variable. $[[Set i]]$ represents the universe
type where $[[i]]$ ranges over the set of natural numbers.
 Finally,
\lang also includes an intensional identity type $[[a ~ b : A]]$ whose
proofs can be eliminated by the J-eliminator $[[J t a b p]]$, where
$[[p]]$ is an equality proof between $[[a]]$ and $[[b]]$, and $[[t]]$
is the term whose type is to be casted.

\lang is expressive enough to support large
elimination, the ability to compute a type using a term as input. For
example, the function $[[\ Bool if var 0 Bool Bool -> Bool]]$ returns
either $[[Bool]]$ or $[[Bool -> Bool]]$ depending on whether the input
is $[[true]]$ or $[[false]]$.

\begin{figure}[h]
\begin{minipage}{0.9\textwidth}
\drules[P]{$[[a => b]]$}{Parallel Reduction}{Var, Set, Void, Pi, Abs, App, AppAbs, True, False, If, IfTrue, IfFalse,
  Bool, Eq, Refl, J, JRefl}
\drules[PS]{$[[a =>+ b]]$}{Transitive Closure of Parallel Reduction}{Refl, Step}
\drules[C]{$[[a <=> b]]$}{Coherence}{Intro}
\end{minipage}
\caption{Parallel reduction and coherence}
\label{fig:par}
\end{figure}

Figure~\ref{fig:par} shows the definition of the parallel reduction
relation, which takes the form $[[a => b]]$. We use $[[a =>+ b]]$ to
represent its transitive and reflexive closure, which in turn allows us to define
the coherence relation $[[a <=> b]]$.
We say that two terms $[[a]]$
and $[[b]]$ are coherent if they can eventually reduce to some common
term $[[c]]$ through parallel reduction. The symmetric notation of
coherence suggests that it is an equivalence relation.

We sketch out some key properties about parallel reduction and
coherence without giving their proofs. Our technique for establishing
those results is based on \citet{takahashi-parallel-reduction} and a
modern exposition of the same technique can be found in
\citet{plfa22.08}.
\begin{lemma}[Par Refl\footnote{\dotv{join.v}{Par\_refl}}]
  \label{lemma:parrefl}
  For all terms $[[a]]$, $[[a => a]]$.
\end{lemma}
\begin{lemma}[Par cong\footnote{\dotv{join.v}{par\_cong}}]
  \label{lemma:parcong}
  If $[[a0 => a1]]$ and $[[b0 => b1]]$, then $[[a0 { b0 } => a1 { b1 }]]$.
\end{lemma}
\begin{corollary}[Par subst\footnote{\dotv{join.v}{par\_subst}}]
  \label{lemma:parsubst}
  If $[[a0 => a1]]$, then $[[a0 {b} => a1 {b}]]$ for arbitrary $[[b]]$.
\end{corollary}
\begin{lemma}[Par diamond\footnote{\dotv{join.v}{par\_confluent}}]
  \label{lemma:pardiamond}
  If $[[a => b0]]$ and $[[a => b1]]$, then there exists some term
  $[[c]]$ such that $[[b0 => c]]$ and $[[b1 => c]]$.
\end{lemma}
\begin{lemma}[Coherence refl\footnote{\dotv{join.v}{Coherent\_reflexive}}]
  \label{lemma:coherencerefl}
  For all terms $[[a]]$, $[[a <=> a]]$.
\end{lemma}
\begin{lemma}[Coherence sym\footnote{\dotv{join.v}{Coherent\_symmetric}}]
  \label{lemma:coherencesym}
  If $[[a <=> b]]$, then $[[b <=> a]]$.
\end{lemma}
\begin{lemma}[Coherence trans\footnote{\dotv{join.v}{Coherent\_transitive}}]
  \label{lemma:coherencetrans}
  If $[[a0 <=> a1]]$ and $[[a1 <=> a2]]$, then $[[a0 <=> a2]]$.
\end{lemma}

From Lemma~\ref{lemma:coherencerefl}, \ref{lemma:coherencesym}, and
\ref{lemma:coherencetrans}, we conclude that coherence is indeed an
equivalence relation. It is then trivial to derive that coherence is
exactly the same as the untyped $\beta$-equivalence.

% TODO: remove the lengthy discussion below

% Now, we prove that coherence is indeed an equivalence relation.

% First, we show that coherence is reflexive through the following
% sequence of lemmas.


% Lemma~\ref{lemma:parrefl} can be proven by structural induction over
% the term $[[a]]$. Lemmas~\ref{lemma:parsrefl} and \ref{lemma:coherencerefl}
% immediately follow as corollaries of Lemma~\ref{lemma:parrefl}.

% The reflexivity of parallel reduction enables us to embed rules from
% call-by-name semantics into parallel reduction, as the following lemma
% shows.
% \begin{lemma}[Par AbsCbn\footnote{\dotv{join.v}{P\_AppAbs\_cbn}}] For all $[[A]], [[a]],$ and $[[b]]$,
%   \label{lemma:parabscbn}
%   $[[(\ A a) b => b {a}]]$
% \end{lemma}
% \begin{proof}
%   Immediate from Lemma~\ref{lemma:parrefl} and \rref{P-AppAbs}.
% \end{proof}

% Symmetry of coherence immediately falls from its definition.

% Before we can prove transitivity, we need to show that parallel
% reduction satisfies the diamond property.


% The congruence property (Lemma~\ref{lemma:parcong}) can be proven by
% structural induction over the derivation of $[[a0 => a1]]$.
% Likewise, Lemma~\ref{lemma:pardiamond} can be proven by structural induction
% over the derivation of $[[a => b0]]$. The \rref{P-AppAbs} case requires
% the use of Lemma~\ref{lemma:parcong}.

% From Lemma~\ref{lemma:parcong} and \ref{lemma:parrefl}, we recover the
% single substitution property as a simple corollary.


% A relation that satisfies the
% diamond property must also be confluent, meaning that its transitive
% and reflexive closure is confluent.
% \begin{lemma}[Par confluent\footnote{\dotv{join.v}{pars\_confluent}}]
%   \label{lemma:parconfluent}
%   If $[[a =>+ b0]]$ and $[[a =>+ b1]]$, then there exists some term
%   $[[c]]$ such that $[[b0 =>+ c]]$ and $[[b1 =>+ c]]$.
% \end{lemma}
% While $[[a =>+ b]]$ is defined as the transitive closure of $[[a => b]]$,
% it coincides with the transitive and reflexive closure of $[[a => b]]$ since $[[a => b]]$ is reflexive (Lemma~\ref{lemma:parrefl}).

% The transitivity of the coherence relation follows as a corollary of
% Lemma~\ref{lemma:parconfluent}.
% By the definition of coherence, there exists some term $[[b]]$ such that $[[a0 =>+ b0]]$,
% $[[a1 =>+ b0]]$ and some term $[[b1]]$ such that $[[a1 =>+ b1]]$ and
% $[[a2 =>+ b1]]$. By Lemma~\ref{lemma:parconfluent}, there exists some
% term $[[c]]$ such that $[[b0 =>+ c]]$ and $[[b1 =>+ c]]$. It sufficies
% to show that $[[a0 =>+ c]]$ and $[[a2 =>+ c]]$, both of which
% trivially hold since the transitive closure $[[a =>+ b]]$ is transitive.
% This concludes the proof that coherence is an equivalence relation.
% \begin{lemma}[Coherence Equivalence]
%   \label{lemma:coherenceequiv}
%   The relation $[[a <=> b]]$ satisfies reflexivity, symmetry, and
%   transitivity and therefore is an equivalence relation.
% \end{lemma}

\begin{figure}[ht]
\begin{minipage}{0.9\textwidth}
\drules[Ctx]{$[[ |- G]]$}{Context Well-Formedness}{Empty, Cons}
\drules[T]{$[[G |-  a : A]]$}{Typing}{Var, Set, Pi, Abs, App, Conv,
  Refl, J, If, Bool, True, False, Void}
\end{minipage}
\caption{Syntactic typing for \lang}
\label{fig:typing}
\end{figure}

Figure~\ref{fig:typing} gives the full typing rules for
\lang{}. The premises wrapped in \colorbox{lightgray}{gray} boxes can be shown to be
admissible syntactically, though some of them are required to
strengthen the inductive hypothesis of the fundamental theorem.
In \rref{T-Var}, $[[G i]]$ is the partial function defined
with the equations $[[ (G ++ A)  0 ]] := [[A]]$ and $[[ (G ++ A) Suc
i ]] := [[G i]] $. The precondition $[[i < | G | ]]$, where $[[ | G |
]]$ represents the length of the context $[[G]]$, ensures that $[[G
i]]$ has a defined output.
\Rref{T-Conv} uses the definition of coherence from earlier
as our equality judgment for type conversion. The use of an untyped
relation for type conversion makes our formulation slightly different
from languages such as MLTT~\citep{Martin-Lof-1973}, where the judgmental equality
takes the form $\Gamma \vdash a \equiv b : A$, which implies $[[G |- a :
A]]$ and $[[G |- b : A]]$, the well-typedness of $[[a]]$ and $[[b]]$.
\citet{siles2012pure} shows the equivalence of Barendregt's
Pure Type System~\citep{barendregt1991introduction}, which employs
untyped equality, and its variant that uses typed judgmental
equality. It is trivial to embed a system with judgmental
equality to a system with untyped equality by erasing typing
information. As a result, it is easy to port our consistency result from our
type system to a variant with typed judgmental equality
as long as the typed system does not include $\eta$ laws
that would require type annotations (e.g. the $\eta$-law for unit
types). % and we discuss in Section~\ref{sec:extension} how we can extend
% our proof to handle those rules.

Working with a system with untyped equality has the huge benefit that
the confluence result for untyped parallel reduction
(Lemma~\ref{lemma:pardiamond}) is easily derivable without having to
resort to the complex syntatic (resp. semantic) technique from
\citet{siles2012pure} (resp. \citet{decagda}) to resolve
the circularity of subject reduction and $\Pi$-injectivity.
Section~\ref{sec:extension} explains how we
generalize our technique to include $\eta$-law for functions and
show the existence of normal form for well-typed (open and closed)
terms, achieving a similar level of expressiveness of the type system
and strength of metatheoretic property as \citet{decagda}.

Finally, since our system has an infinite universe hierarchy, we can
present the system Ã  la Russell by using the same judgment form $[[G
|- a : A]]$ regardless of whether $[[a]]$ is a term or a type. There
is no need to distinguish between big types and small types
and duplicate our typing specification.

% , the
% statement that $\Gamma \vdash [[Pi A0 B0]] \equiv [[Pi A1 B1]]$
% implies $\Gamma \vdash [[A0]] \equiv [[A1]]$ and
% $\Gamma, [[A0]]\vdash [[B0]] \equiv [[B1]]$.



% working with a system with untyped equality not only preserves the
% same level of generality,
% Of course,
% but also enables us to derive confluence
% (Lemma~\ref{lemma:parconfluent}) early on without having to use the
% intricate techniques from \citet{lemma:}







% TODO, where terms ... and ... are known to be
% well-typed. The equivalence of such systems and a system that uses
% untyped equality are explored in detail in ...

% Without fancy eta laws, it is easy to embed a typed language into an
% untyped language.


% We note that a more conventional presentation of
% \rref{T-Conv} would instead use full beta reduction as the base for
% the definition of coherence. However, since full beta reduction
% doesn't satisfy the diamond property, one typically needs parallel
% reduction as an auxilliary definition to derive the confluence of full
% beta reduction. Our formulation of \lang through parallel reduction
% is slightly more economical.

\section{Logical Relation}
\label{sec:logreldep}
\begin{figure}[h]
\drules[I]{$[[Interp I i A S]]$}{Logical Relation}{Void, Bool, Eq, Pi, Set, Red}
\caption{Logical relation for \lang}
\label{fig:logrel}
\end{figure}
In this section, we define the logical relation for \lang{} in the
form of an inductively defined relation (Figure~\ref{fig:logrel}).
Throughout the text, we use the notation $[[PowerSet S]]$ denotes the powerset of the set $[[S]]$.
The logical relation takes the form $[[Interp I i A S]]$. The
metavariables $[[A]]$ and $[[i]]$ stand for terms and natural
numbers respectively, as introduced earlier in
Figure~\ref{fig:syntax}.
The metavariables $[[I]]$ and $[[S]]$ are
sets with the following signatures.
\begin{equation*}
  \begin{split}
    [[I]] &\in [[ { j | j < i  } ->  PowerSet STm ]] \\
    [[S]] &\in [[PowerSet STm]]
  \end{split}
\end{equation*}
The function $[[I]]$ is a family of sets of terms indexed by
natural numbers strictly less than the parameter $[[i]]$, which
represents the current universe level.  In \rref{I-Set}, function
$[[I]]$ is used to define the meaning of
universes that are strictly smaller than the current level $[[i]]$. The
restriction $[[j < i]]$ in \rref{I-Set} is crucial for our system to
be predicative. Removing the ordering constraint would result in a
system where one can encode Girard's paradox~\citep{girard-thesis}.

\begin{figure}[h]
\begin{equation*}
    [[InterpR i A S]] := [[ Interp I i A S  ]], \text{where } [[I i]] := [[{A | exists S , InterpR i A S}]]
\end{equation*}
\caption{Logical relation for all universe levels}
\label{fig:logrelrec}
\end{figure}
To tie the knot and obtain an interpretation of all universe levels,
we define in Figure~\ref{fig:logrelrec} the final version of our interpretation judgment recursively
using the well-foundedness of the strict less than relation on natural
numbers (recall that
the parameter $[[I]]$ of $[[Interp I i A S]]$ takes only natural
numbers strictly less than $[[i]]$ as its input).
The judgment $[[InterpR i A S]]$ now reads that the type $[[A]]$ is a
level-$[[i]]$ type \emph{semantically} inhabited by terms from the set
$[[S]]$.

With the definition from Figure~\ref{fig:logrelrec}, we can
show that the same introduction rules for $[[Interp I i A S]]$ are
admissible for $[[InterpR i A S]]$, by
instantiating $[[I]]$ with $[[I i]] := [[{A | exists S , InterpR i A
  S}]]$, the same function $[[I]]$ used in the definition of $[[InterpR i A
S]]$. We give as example the following rules.
\begin{center}
\drule[]{IR-Void} \qquad \drule[]{IR-Set}
\end{center}

In most informal presentations, instead of defining the logical
relation in two steps as we have shown above, the rules for $[[InterpR
i A S]]$ are given directly, with the implicit understanding that the
relation is an inductive definition nested inside a recursive
function over the universe level $[[i]]$. We choose
the more explicit definition not only because it is directly definable
in existing proof assistants where inductive definitions must appear
at the top level, but also because it makes clear the induction
principle we are allowed to use when reasoning about $[[InterpR i A
S]]$.

% The paragraph below might be useful but I don't know how to phrase
% it well

% The most general format of the induction principle over
% $[[InterpR i A S]]$ is first by strong induction over the universe level $[[i]]$
% followed by structural induction over $[[Interp I i A S]]$. As
% examples, ... (\rref{I-Set} and \rref{I-Red}).

For the majority of the properties we are about to prove in this section, we
do not need any information about the parameterized function $[[I]]$.
Each property about $[[InterpR i A S]]$ follows as a corollary of
a property about $[[Interp I i A S]]$ with no or few assumptions imposed on
$[[I]]$. As a result, we usually state our lemmas in terms of
$[[Interp I i A S]]$ without duplicating them in terms of $[[InterpR i
A S]]$.

To derive consistency, it suffices to restrict $[[S]]$ to the set of
terms to reduce to closed terms. \Rref{I-Void, I-Bool} are
unsurprising; when considering only closed terms, the empty type
should not be inhabited and therefore corresponds to the empty set,
whereas the boolean type is semantically inhabited by terms that
evaluate to the boolean values $[[true]]$ or $[[false]]$. \Rref{I-Eq}
says that an equality type $[[a ~ b : A]]$ corresonds to the
set of terms that evaluate to $[[refl]]$ when $[[a <=> b]]$ holds and
otherwise corresponds to the empty set. Side conditions like $[[a <=>
b]]$ are typically required for indexed types, of which equality types
are an instance.

\Rref{I-Pi} is the most interesting. The precondition consists of a
mysterious function $[[F]]$ that takes an element from the set $[[S]]$, the interpretation
of the type $[[A]]$, and returns a subset of terms. $[[F]]$ is further
subject to the constraint that $[[forall a, (# a in S implies Interp I
i B { a } F a #)]]$. Ignoring the content below the horizontal bar of
the derivation, the statements from the precondition are equivalent to
the conjunction of the following statements:
\begin{itemize}
\item $[[Interp I i A S]]$
\item $\forall [[a]], \text{ if }[[a in S]]\text{, then } \exists
  [[S0]]\text{, } [[Interp I i B { a } S0 ]] $
\end{itemize}
In general, let $R$ be a binary relation over the sets $[[A]]$ and
$[[B]]$, it easy to verify the following equivalence, which is used to
justify the skolemization process~\citep{skolemization}.
\[\forall a \in A, \exists b \in B \text{ such that } (a,b) \in R
  \iff \exists F \in A \rightarrow B \text, \forall a \in A, (a, F(a))
  \in R\]
The left-hand side is equivalent to the right-hand side, but has no
mentioning of any functions.
In the context of \rref{I-Pi}, through
the equivalence, we can more easily tell what's happening: the
function type $[[Pi A B]]$ has a semantic interpretation if its input
type $[[A]]$ can be semantically
interpreted as some set $[[S]]$, and for all terms $[[a in S]]$, the
type $[[B {a}]]$, obtained by substituing $[[a]]$ into the output type
$[[B]]$, has a semantic interpretation.

If we look at $[[Interp I i Pi A B { b | forall a, (# a in S implies b
  a in F a #) }]]$, the conclusion of \rref{I-Pi}, we see why the
presentation with an explicit $[[F in S -> PowerSet STm]]$ is
useful. We want to state the fact that $[[B {a}]]$ has a semantic
interpretation of some set $[[S0]]$, but we also want to refer to the
set $[[S0]]$ when we talk about the set that $[[Pi A B]]$ corresponds
to. With the function $[[F]]$, we can use $[[F a]]$ to retrive the
witness in the precondition for $[[a in S]]$.
With the alternative representation that is free of the function $[[F]]$, we
might want to reformulate our logical relation in the following way.
\begin{center}
  \drule[]{I-PiAlt}
\end{center}
Unfortunately, \rref{I-PiAlt} not only violates the syntactic strict
positivity constraint required in proof assistants, but
is genuinely non-monotone when written as an endofunction over the
domain of relations.
Intuitively, the failure of monotonicity stems from the fact
that the witness picked in the precondition is not necessarily the
same witness being referred to in the post condition. While it might
be possible to restrict the domain with additional constraints such as
functionality and inversion properties, we opt for our current
skolemized formulation of \rref{I-Pi} so we immediately obtain a
well-defined inductive relation and a usable induction principle. The
slight disadvantage of \rref{I-Pi} is that we need to construct the
function $[[F]]$ each time we apply it. Therefore, in
Lemma~\ref{lemma:piintroalt}, we show the admissibility of
\rref{I-PiAlt} a posteriori and use that as a more convenient
introduction rule for the rest of our proofs.


In the rest of the section, we establish some important facts about
the logical relation that will be useful for proving fundamental theorem
in Section~\ref{sec:logrelproof}.

The relation $[[Interp I i A S]]$ satisfies the following inversion
principles.
\begin{lemma}[Inversion of the logical relation]
  \label{lemma:interpinv}\leavevmode
  \begin{enumerate}
  \item If $[[Interp I i Void S]]$, then $[[S = emptyset]]$.\footnote{\dotv{semtyping.v}{InterpExt\_Void\_inv}}
  \item If $[[Interp I i Bool S]]$, then $[[S = { a | a =>+ true \/ a =>+ false   }]]$.\footnote{\dotv{semtyping.v}{InterpExt\_Bool\_inv}}
  \item If $[[Interp I i a ~ b : A S]]$, then $[[S = { p | p =>+ refl , a <=> b  }]]$.\footnote{\dotv{semtyping.v}{InterpExt\_Eq\_inv}}
  \item If $[[Interp I i Pi A B S0]]$, then there exists $[[S]],[[F]]$ such that:\footnote{\dotv{semtyping.v}{InterpExt\_Fun\_inv}}
    \begin{itemize}
    \item $[[Interp I i A S ]]$
    \item $[[F in S -> PowerSet STm]]$
    \item $[[forall a, (# a in S implies Interp I i B { a } F a #)]]$
    \item $[[S0 = { b | forall a, (# a in S implies b a in F a #) }]]$
    \end{itemize}
  \item If $[[Interp I i Set j S]]$, then $[[j < i]]$ and $[[S = I j]]$.\footnote{\dotv{semtyping.v}{InterpExt\_Univ\_inv}}
  \end{enumerate}
\end{lemma}
\begin{proof}
  We only show the most involved function case; the rest follows a
  similar but simpler pattern. We start by
  inducting over the derivation of $[[Interp I i Pi A B S]]$. There
  are only two possible cases we need to consider.
  \begin{description}
  \item[\Rref{I-Pi}:] Immediate.
  \item[\Rref{I-Red}:] We are given that $[[Interp I i Pi A B S0]]$.
    We know that there exists some $[[A0]]$ and
    $[[B0]]$ such that $[[Pi A B => Pi A0 B0]]$ and $[[Interp I i Pi
    A0 B0 S0]]$. From the
    induction hypothesis, there exists $[[S]]$ and $[[F]]$ such that :
    \begin{itemize}
    \item $[[Interp I i A0 S ]]$
    \item $[[F in S -> PowerSet STm]]$
    \item $[[forall a, (# a in S implies Interp I i B0 { a } F a #)]]$
    \item $[[S0 = { b | forall a, (# a in S implies b a in F a #) }]]$
    \end{itemize}
    By inverting $[[Pi A B => Pi A0 B0]]$, we derive $[[A => A0]]$ and
    $[[B => B0]]$. By Lemma~\ref{lemma:parsubst}, we have $[[B {a} => B0 {a} ]]$ for all
    $[[a]]$. As a result, by \rref{I-Red}, the same $[[S]]$ and
    $[[F]]$ satisfies the following properties:
    \begin{itemize}
    \item $[[Interp I i A S ]]$
    \item $[[F in S -> PowerSet STm]]$
    \item $[[forall a, (# a in S implies Interp I i B { a } F a #)]]$
    \end{itemize}
    These properties are exactly what's required in the conclusion.
  \end{description}
\end{proof}

\Rref{I-Red} bakes into the logical relation the backward preservation
property. The following property shows that preservation holds in the
usual forward direction too.
\begin{lemma}[Preservation of the logical relation\footnote{\dotv{semtyping.v}{InterpExt\_preservation}}]
  \label{lemma:interppreservation}
  If $[[Interp I i A S]]$ and $[[A => B]]$, then $[[Interp I i B S]]$.
\end{lemma}
\begin{proof}
  We carry out the proof by induction over the derivation of $[[Interp
  I i A S]]$.
  \begin{description}
  \item[\Rref{I-Void}:] There exists some $[[B]]$ such that $[[Void =>
    B]]$. By inverting the derivation of $[[Void => B]]$, $[[B]]$ must
    be $[[Void]]$ and the result trivially follows.
  \item[\Rref{I-Bool, I-Set}:] Similar to the case for \rref{I-Void}.
  \item[\Rref{I-Eq}:] We know that $[[Interp I i a ~ b : A { p | p =>+
      refl , a <=> b  }]]$ and, by inverting the derivation of
    parallel reduction, $[[a => a0]]$, $[[b => b0]]$, $[[A => A0]]$
    for some $[[a0]]$, $[[b0]]$, and $[[A0]]$. Our goal is to show
    that $[[Interp I i a0 ~ b0 : A {p | p =>+ refl, a <=> b}]]$. By
    \rref{I-Eq}, we already know that $[[Interp I i a0 ~ b0 : A {p | p
      =>+ refl, a0 <=> b0}]]$ and therefore it suffices to show that
    the sets $[[{p | p =>+ refl, a <=> b}]]$ and $[[{p | p =>+ refl,
      a0 <=> b0}]]$ are equal. Equivalently, it suffices to show that
    $[[a <=> b]]$ if and only if $[[a0 <=> b0]]$. By definition, from
    $[[a => a0]]$ and $[[b => b0]]$, we derive $[[a <=> a0]]$ and $[[b
    <=> b0]]$. The result then immediately follows from the fact that
    coherence is an equivalence relation.
  \item[\Rref{I-Pi}:] There exists $[[S]]$ and $[[F]]$
    such that:
    \begin{itemize}
    \item $[[Interp I i Pi A B { b | forall a, (# a in S implies b a in F
        a #) }]]$
    \item $[[Interp I i A S ]]$
    \item $[[F in S -> PowerSet STm]]$
    \item $[[forall a, (# a in S implies Interp I i B { a } F a #)]]$
    \end{itemize}
    There exists some $[[A0]]$ and $[[B0]]$ such that $[[A => A0]]$ and
    $[[B => B0]]$. Our goal is to show that $[[Interp I i Pi A0 B0 { b | forall a, (# a in S implies b a in F
      a #) }]]$. By \rref{I-Pi}, it suffices to show:
    \begin{itemize}
    \item $[[Interp I i A0 S ]]$
    \item $[[F in S -> PowerSet STm]]$
    \item $[[forall a, (# a in S implies Interp I i B0 { a } F a #)]]$
    \end{itemize}
    Since $[[A => A0]]$ and $[[B {a} => B0 {a}]]$ forall $[[a]]$, the
    latter of which follows from Lemma~\ref{lemma:parsubst}, the above
    conditions follow immediately from the induction hypothesis.
  \item[\Rref{I-Red}:] There exists $[[B0]]$ and $[[S]]$ such that $[[A => B0]]$ and
    $[[Interp I i B0 S]]$. Given an arbitrary $[[B]]$ such that $[[A
    => B]]$, our goal is to show that $[[Interp I i B S]]$. By the diamond
    property of parallel
    reduction (Lemma~\ref{lemma:pardiamond}), there exists some term
    $[[C]]$ such that $[[B0 => C]]$ and $[[B => C]]$. By the induction
    hypothesis, we derive $[[Interp I i C S]]$ from $[[Interp I i
    B0 S]]$. By \rref{I-Red} and
    $[[B => C]]$, we conclude that $[[Interp I i B S]]$.
  \end{description}
\end{proof}
From Lemma~\ref{lemma:interppreservation} and \rref{I-Red}, we can easily
derive the following corollary that two coherent types have the same
interpretation.
\begin{corollary}[Irrelevance of logical relation\footnote{\dotv{semtyping.v}{InterpUnivN\_Coherent}}]
  \label{lemma:logrelcoherence}
  If $[[Interp I i A S]]$ and $[[A <=> B]]$, then $[[Interp I i B S]]$.
\end{corollary}
Next, we show that $[[Interp I i A S]]$ is in fact a partial function.
\begin{lemma}[Logical relation is functional\footnote{\dotv{semtyping.v}{InterpExt\_deterministic}}]
  \label{lemma:logreldeter}
  If $[[Interp I i A S0]]$ and $[[Interp I i A S1]]$, then $[[S0 = S1]]$.
\end{lemma}
\begin{proof}
  We start by inducting over the derivation of the first premise $[[Interp I i A
  S0]]$.
  \begin{description}
  \item[\Rref{I-Void}:] We know that $[[Interp I i Void
    emptyset]]$. Given $[[Interp I i Void S1]]$, our goal is to show that
    $[[emptyset = S1]]$. This is immediate by applying the $[[Void]]$ case of
    Lemma~\ref{lemma:interpinv} to $[[Interp I i Void S1]]$.
  \item[\Rref{I-Bool, I-Eq, I-Set}:] Similar to the \rref{I-Void} case
    by applying the matching case of Lemma~\ref{lemma:interpinv}
    to $[[Interp I i A S1]]$.
  \item[\Rref{I-Pi}:] There exists $[[S]]$ and $[[F]]$
    such that:
    \begin{itemize}
    \item $[[Interp I i A S ]]$
    \item $[[F in S -> PowerSet STm]]$
    \item $[[forall a, (# a in S implies Interp I i B { a } F a #)]]$
    \end{itemize}
    Our goal is to show that given $[[Interp I i Pi A B S1]]$, we have
    $[[S1 = { b | forall a, (# a in S implies b a in F
      a #) }]]$.
    By the function case of Lemma~\ref{lemma:interpinv}, there exists
    some $[[S0]]$ and $[[F0]]$ such that:
    \begin{itemize}
    \item $[[Interp I i A S0 ]]$
    \item $[[F0 in S0 -> PowerSet STm]]$
    \item
      $[[forall a, (# a in S0 implies Interp I i B { a } F0 a #)]]$
    \item
      $[[S1 = { b | forall a, (# a in S0 implies b a in F0 a #) }]]$
    \end{itemize}
    It suffices to show that $[[S = S0]]$ and $[[F = F0]]$. The
    equality $[[S = S0]]$ immediately follows from the induction
    hypothesis since $[[Interp I i A S]]$ and $[[Interp I i A
    S0]]$. Therefore, functions $[[F]]$ and $[[F0]]$ have the same
    domain and codomain and thus it suffices to show that forall $[[a in S]]$,
    $[[F a = F0 a]]$. Suppose $[[a in S]]$, we must have $[[Interp I
    i B {a} F a]]$ and $[[Interp I i B {a} F0 a]]$ from the two
    $\forall$-quantified statements above. The equality $[[F a = F0 a]]$ then
    immediately follows from the induction hypothesis.
  \item[\Rref{I-Red}:] There exists some $[[B]]$ such that $[[A =>
    B]]$ and $[[Interp I i B S0]]$. Our goal is to show that given
    $[[Interp I i A S1]]$, we have $[[S0 = S1]]$. By
    Lemma~\ref{lemma:interppreservation}, from $[[Interp I i A S1]]$
    and $[[A => B]]$, we have $[[Interp I i B S1]]$. From the
    induction hypothesis, we can conclude that $[[S0 = S1]]$ since
    $[[Interp I i B S0]]$ and $[[Interp I i B S1]]$.
  \end{description}
\end{proof}

Lemma~\ref{lemma:logreldeter} enables us to show the admissibility of
\rref{I-PiAlt} and its related inversion principle.
\begin{lemma}[Pi Intro Alt\footnote{\dotv{semtyping.v}{InterpExt\_Fun\_nopf}}]
  \label{lemma:piintroalt}
  Suppose the following two statements hold:
  \begin{itemize}
  \item $[[Interp I i A S]]$
  \item $[[forall a, a in S implies (# exists S0 , Interp I i B {a} S0 #)]]$
  \end{itemize}
  Then we have $[[Interp I i Pi A B { b | forall a, (# a in S , forall
    S0, (# Interp I i B {a} S0,  b a in F a #) #) }]]$
\end{lemma}
\begin{proof}
  Let $[[F]]$ be the relation defined as follows:
  \[ (a,S) \in [[F]] \iff [[Interp I i B {a} S]] \]
  By the second bullet from the premise and
  Lemma~\ref{lemma:logreldeter}, $[[F]]$ is a function that is total
  on the set $[[S]]$. The conclusion then trivially follows from
  \rref{I-Pi}.
\end{proof}

\begin{lemma}[Pi Inv Alt\footnote{\dotv{semtyping.v}{InterpExt\_Fun\_inv\_nopf}}]
  \label{lemma:piinvalt}
  Suppose $[[Interp I i Pi A B S]]$, then there exists some $[[S0]]$
  such that the following constraints hold:
  \begin{itemize}
  \item $[[Interp I i A S0]]$
  \item $[[forall a, (# a in S0 implies (# exists S1 , Interp I i B {a}
    S1 #) #)]]$
  \item $[[S = { b | forall a, (# a in S0 , forall
    S1, (# Interp I i B {a} S1,  b a in S1 #) #) }]]$
  \end{itemize}
\end{lemma}
\begin{proof}
  Immedaite from Lemmas~\ref{lemma:interpinv} and \ref{lemma:logreldeter}.
\end{proof}

% The combination of Lemmas~\ref{lemma:piintroalt} and
% \ref{lemma:piinvalt} reveals what we truly want to capture with
% \rref{I-Pi}. A function type is semantically well-defined if its input
% type is well-defined, and its output type is defined for each valid
% inahbitant of its input type.

The next lemma shows that our logical relation satisfies
cumulativity. That is, if a type has an interpretation at a lower
universe level, then we can obtain the same interpretation at a higher
universe level.
\begin{lemma}[Logical relation cumulativity\footnote{\dotv{semtyping.v}{InterpExt\_cumulative}}]
  \label{lemma:logrelcumulativity}
  If $[[Interp I i0 A S]]$ and $[[i0 < i1]]$, then $[[Interp I i1 A S]]$.
\end{lemma}
\begin{proof}
  Trivial by structural induction over the derivation of $[[Interp I
  i0 A S]]$.
\end{proof}
Note that in the statement of Lemma~\ref{lemma:logrelcumulativity}, we
implicitly assume that $[[I]]$ is defined on the set of natural
numbers less than $[[i1]]$.

\begin{corollary}[Logical relation is functional with different levels\footnote{\dotv{semtyping.v}{InterpExt\_deterministic'}}]
  \label{lemma:logreldeterhet}
  If $[[Interp I i0 A S0]]$ and $[[Interp I i1 A S1]]$, then $[[S0 = S1]]$.
\end{corollary}
\begin{proof}
  Immediate from Lemma~\ref{lemma:logreldeter} and
  \ref{lemma:logrelcumulativity}.
\end{proof}

We say that a set of terms $[[S]]$ is closed under expansion if given
$[[a in S]]$, then $[[b in S]]$ for all $[[b => a]]$.
The final property we want to show is that the output set $[[S]]$ from
the logical relation is closed under expansion. Unlike the previous
lemmas, we need to constrain the function $[[I]]$ so its outputs are
all closed under expansion.
\begin{lemma}[Logical Relation Elements back preservation\footnote{\dotv{semtyping.v}{InterpExt\_back\_clos}}]
  \label{lemma:logrelbackclos}
  If $[[Interp I i A S]]$ and $[[I]]$ satisfies the property that
  for all $[[i]]$, $[[I i]]$ is closed under expansion, then the set
  $[[S]]$ is closed under expansion.
\end{lemma}
\begin{proof}
  Trivial by structural induction over the derivation of $[[Interp I i
  A S]]$. The function case requires the following simple fact about
  parallel reduction:
  If $[[b0 => b1]]$ then $[[b0 a => b1 a]]$ for all $[[a]]$. This fact
  is not immediate from the definition of parallel reduction but
  follows from Lemma~\ref{lemma:parrefl} and \rref{P-App}.
\end{proof}

\begin{corollary}[Logical Relation Elements back preservation (rec)\footnote{\dotv{semtyping.v}{InterpUnivN\_back\_clos}}]
  \label{lemma:logrelNbackclos}
  If $[[InterpR i A S]]$, then $[[S]]$ is closed under expansion.
\end{corollary}
\begin{proof}
  Immediate from Lemma~\ref{lemma:logrelbackclos}, the definition of
  $[[InterpR i A S]]$, and \rref{I-Red}.
\end{proof}

\section{Semantic Typing and Consistency}
\label{sec:logrelproof}
\begin{figure}[h]
\[
\begin{array}{lcl}

      [[rho |= G]] &:= & \forall i\ j\ S, \text{ if }[[i < |G|]]\text{ and
                     } [[InterpR j (G i < up Suc i > ) { rho } S ]] \text{, then } [[rho i in S]] \\
      [[G |= a : A]] &:= & \forall [[rho]], \text{ if }[[rho |=
                       G]]\text{ then there exists some } [[j]] \text{
                       and } [[S]] \text{ such that } [[InterpR j A
                       {rho} S]] \text{ and } [[a {rho} in S]] \\
      [[|= G]] &:= & \forall [[i < |G|]], \exists [[j]], [[drop Suc i G |= G i : Set j]]
\end{array}
\]
  \caption{Semantic Typing for \lang}
  \label{fig:semtyping}
\end{figure}

The logical relation we define in Figure~\ref{fig:logrel} does not
include cases for variables. Likewise, for the base types such as
boolean and equality, the output set $[[S]]$ contains only terms that
evaluate to closed terms. To generalize our logical relation to open
terms, we define the semantic typing judgment by closing the open
terms with a substitution whose codomain consists of terms that
respect the interpretation of the types from the context. The full
definitions of well-formed substitution ($[[rho |= G]]$), semantic
typing ($[[ G |= a : A]]$), and semantic context well-formedness
($[[|= G]]$) are presented in Figure~\ref{fig:semtyping}. In the
definition of $[[|= G]]$, we use the notation $[[drop i G]]$ to denote
the typing context obtained by dropping the last $[[i]]$ elements of
$[[G]]$. When $[[G]]$ has less than $[[i]]$ elements, $[[drop i G]]$
returns the empty list.

The following lemma makes the statement $[[G |= A : Set i]]$ easier to
work with.
\begin{lemma}[Set Inv\footnote{\dotv{soundness.v}{SemWt\_Univ}}]
  \label{lemma:setinv}
  The following two statements are equivalent:
  \begin{itemize}
  \item $[[G |= A : Set i]]$
  \item $\forall$ $[[rho]]$, if $[[rho |= G]]$, then there exists
    $[[S]]$ such that $[[InterpR i (A {rho}) S]]$
  \end{itemize}
\end{lemma}
\begin{proof}
  The forward direction is immediate by
  Lemma~\ref{lemma:interpinv}. We now consider the backward direction
  and show that $[[G |= A : Set i]]$ given the second bullet.

  Suppose $[[rho |= G]]$, then we know that there exists some $[[S]]$
  such that $[[InterpR i (A {rho}) S]]$. By the definition of semantic
  typing, it suffices to show that there exists some $[[j]]$ and
  $[[S0]]$ such that  $[[InterpR j Set i S0]]$ and $[[A {rho} in
  S0]]$.
  Pick $[[Suc i]]$ for $[[j]]$ and $[[ { A | exists S , InterpR i A S }
  ]]$ for $[[S0]]$ and it's trivial to verify the conditions hold.
\end{proof}

The semantic context well-formedness judgment ($[[|= G]]$), unlike its syntactic
counterpart $[[|- G]]$, is defined through a for all quantified statement rather
than inductively over the context. It is easy to recover the same
structural rules:
\begin{lemma}[Semantic context well-formedness cons]
  \label{lemma:semwffcons}
  If $[[|= G]]$ and $[[G |= A : Set i]]$, then $[[|= G ++ A]]$.
\end{lemma}
\begin{proof}
  By the definition of semantic context well-formedness, the goal is
  to show that given $[[i < | G ++ A |]] = [[Suc |G|]]$, $[[drop Suc i
  (G ++ A) |= (G ++ A) i : Set j]]$. The statement can be easily
  proven by case analysis on whether $[[i]]$ is zero.
\end{proof}

Likewise, the semantic well-formendness judgment for substitutions
satisfies similar structural rules.
\begin{lemma}[Well-formed $[[rho]]$ cons\footnote{\dotv{soundness.v}{$\gamma$\_ok\_cons}}]
  If $[[InterpR i A S]]$, $[[a in S]]$, and $[[rho |= G]]$, then
  $[[rho .: a |= G ++ A]]$.
\end{lemma}
\begin{proof}
  Start by unfolding the definition of $[[rho .: a |= G ++ A]]$ and
  performing a case analysis similar to the proof of
  Lemma~\ref{lemma:semwffcons}.  The case where the number is $[[0]]$
  requires Lemma~\ref{lemma:logreldeterhet} to finish the proof.
\end{proof}

Next, we show some non-trivial cases of the fundamental theorem as
top-level lemmas and leave the remaining cases as exercises for the
reader.

First, we formulate the definition of valid renamings and prove that
semantic typing satisfies renaming so we can weaken the context when
reasoning about the variable case of the fundamental lemma
(Lemma~\ref{lemma:stvar}). Intuitively, given a valuation $[[rho |= G
++ D]]$, it is easy to show that we can extract some valuation
$[[rho0]]$ such that $[[rho0 |= G]]$, where $[[rho0]]$ is obtained by
``truncating'' $[[rho]]$. As a result, if we know that $[[G |= a :
A]]$, then we can conclude that $[[G ++ D |= a0 : A0 ]]$, where
$[[a0]]$ and $[[A0]]$ are obtained by shifting $[[a]]$ and $[[A]]$
after weakening the context; this implication holds because $[[rho |=
G ++ D]]$ induces a context $[[rho0]]$ such that $[[rho0 |= G]]$ so we
can make use of the premise $[[G |= a : A]]$ to derive what we need
for the conclusion. We recommend the readers to skip the proofs of
Lemmas~\ref{lemma:validtruncate} through \ref{lemma:semrenaming}
during the first read as long as they have an intuitive understanding
of what the renaming property is meant to capture.

We say that $[[xi]]$ is
valid from the context $[[G]]$ to the context $[[D]]$ if the
following condition holds.
\[ \forall i \text{, if } i < | [[G]] |\text{, then }[[ ren xi i < |D| ]] \text{ and }
  [[D ren xi
  i < up Suc ren xi i > = G i < up Suc i > < xi >]] \]

\begin{lemma}[Truncate is valid]
  \label{lemma:validtruncate}
  If $[[i < |G|]]$, then $[[up i]]$ is a valid renaming from $[[drop i
  G]]$ to $[[G]]$.
\end{lemma}
\begin{proof}
  By the definition of a valid renaming, we must show that given $[[j
  < |drop i G|]] = [[|G|]] - [[i]]$, then the following conditions hold:
  \begin{itemize}
  \item $[[ren up i j]] = i + j  < [[| G | ]]$
  \item $[[G ren up i j < up Suc ren up i j > = drop i G j < up Suc j > < up i >]]$
  \end{itemize}
  The first bullet point is immediate from the fact that $[[j]] <
  [[|G|]] - [[i]]$. The second bullet follows from unfolding the
  definitions, and the fact that $[[drop i G j]] = [[G]](i + j)$ when
  $[[i]] + [[j]] < [[|G|]]$.
\end{proof}

\begin{lemma}[Renaming for $[[rho |= G]]$]
  \label{lemma:renamingval}
  If $[[rho |= D]]$ and $[[xi]]$ is a valid renaming from $[[G]]$ to
  $[[D]]$, then we have $[[rho0 |= G]]$ where $[[rho0 i = rho ren xi i]]$.
\end{lemma}
\begin{proof}
  Unfolding the definition of $[[rho0 |= G]]$, the goal is to show
  that for all $i,j,$ and $S$, if $[[i < |G|]]$ and $[[InterpR j (G i
  < up Suc i > ) { rho0 } S ]] \text{, then } [[rho0 i]] = [[rho ren xi i in S]]$.

  By the definition of $[[rho0]]$ and the validity of $[[xi]]$, we
have $[[G i < up Suc i > { rho0 }]] = [[G i < up Suc i > < xi > { rho
} ]] = [[D ren xi i < up Suc ren xi i > { rho }]]$. From $[[rho |=
D]]$ and $[[ren xi i < | D |]]$, we have $[[InterpR j D ren xi i < up Suc ren xi i > { rho }
S]]$ and $[[rho ren xi i in S]]$. Done.
\end{proof}

\begin{lemma}[Renaming for $[[G |= a : A]]$]
  \label{lemma:semrenaming}
  If $[[G |= a : A]]$ and $[[xi]]$ is a valid renaming from $[[G]]$ to
  $[[D]]$, then $[[D |= a < xi > : A < xi > ]]$.
\end{lemma}
\begin{proof}
  Immediate from the definition of semantic typing and Lemma~\ref{lemma:renamingval}.
\end{proof}

\begin{lemma}[ST-Var]
  \label{lemma:stvar}
  If $[[|= G]]$ and $[[i < |G|]]$, then $[[G |= var i : G i < up Suc i  >]]$.
\end{lemma}
\begin{proof}
  Suppose $[[rho |= G]]$. By the definition of semantic typing, we
need to show that there exists some $[[j]]$ and $[[S]]$ such that
  \begin{itemize}
  \item $[[InterpR j G i < up Suc i > { rho } S]]$
  \item $[[rho i in S]]$
  \end{itemize}
  From the definition of $[[|= G]]$, we know that there exists some
  $[[j]]$ such that $[[drop Suc i G |= G i : Set j]]$. By
  Lemma~\ref{lemma:validtruncate}, we know that $[[up Suc i]]$ is a
  valid renaming from $[[drop Suc i G]]$ to $[[G]]$. By
  Lemma~\ref{lemma:semrenaming}, we deduce $[[G |= G i < up Suc
  i > : Set j]]$. By the identity from Lemma~\ref{lemma:setinv}, we
  know that $[[InterpR j G i < up Suc i > { rho } S]]$. It now
  suffices to show $[[rho i in S]]$, but that is immediate from the
  definition of $[[rho |= G]]$.
\end{proof}

\begin{lemma}[ST-Set]
  \label{lemma:stset}
  If $[[i < j]]$, then $[[G |= Set i : Set j]]$.
\end{lemma}
\begin{proof}
  Immedaite by Lemma~\ref{lemma:setinv} and \rref{I-Set}.
\end{proof}

\begin{lemma}[ST-Pi]
  \label{lemma:stpi}
  If $[[G |= A : Set i]]$ and $[[G ++ A |= B : Set i]]$, then $[[G |= Pi
  A B : Set i]]$.
\end{lemma}
\begin{proof}
  Applying Lemma~\ref{lemma:setinv} to the
  conclusion, it now suffices to show that given $[[rho |= G]]$, there
  exists some $[[S]]$ such that $[[InterpR i Pi A{rho} B{up rho} S]]$.
  From Lemma~\ref{lemma:setinv} and $[[G |= A : Set i]]$, we know that
  there exists some set $[[S0]]$ such that $[[InterpR i A {rho} S0]]$.
From $[[G ++ A |= B : Set i]]$, we know that there must
exists $[[S]]$ such that $[[InterpR i B {rho .: a} S]]$ for every $[[a
in S0]]$. The conclusion immediately follows from Lemma~\ref{lemma:piintroalt}.
\end{proof}

\begin{lemma}[ST-Abs]
  \label{lemma:stabs}
  If $[[G |= Pi A B : Set i]]$ and $[[G ++ A |= b : B]]$, then $[[G |=
  \ A b : Pi A B]]$.
\end{lemma}
\begin{proof}
  By unfolding the definition of $[[G |= \ A b : Pi A B]]$, we need to
  show that given some $[[rho |= G]]$, there exists some $[[i]]$ and
  $[[S]]$ such that $[[InterpR i Pi A {rho} B {up rho} S]]$ and $[[\
  A{rho} b{up rho} in S]]$.

  By Lemma~\ref{lemma:setinv} and the premise $[[G |= Pi A B : Set
  i]]$, there exists some set $[[S]]$ such that
  $[[InterpR i Pi A {rho} B {up rho} S]]$. It now suffices to show that
  $[[\A{rho} b{up rho} in S
  ]]$. By Lemma~\ref{lemma:piinvalt}, there exists some $[[S0]]$ such
  that all following conditions hold:
  \begin{itemize}
  \item $[[InterpR i A{rho} S0]]$
  \item $[[forall a, (# a in S0 implies (# exists S1 , InterpR i B
    {rho .: a}
    S1 #) #)]]$
  \item $[[S = { b | forall a, (# a in S0 , forall
      S1, (# InterpR i B {rho .: a} S1,  b a in S1 #) #) }]]$
  \end{itemize}
  To show that $[[\A{rho} b{up rho} in S]]$, we need to prove
  that given $[[a in S0]]$,
  $[[Interp I i B {rho .: a} S1]]$, we have  $[[( \A{rho} b{up rho} )
  a in S1]]$.
  By Lemma~\ref{lemma:logrelbackclos}, the set $[[S1]]$ is closed
  under expansion. By Lemma~\ref{lemma:parabscbn}, since $[[( \A{rho} b{up rho} )
  a => b {up rho} {a}]] = [[b {rho .: a}]]$, it suffices to show that
  $[[b {rho .: a} in S1]]$, which is immediate from $[[G ++ A |= b :
  B]]$ and the fact that the logical relation is deterministic and
  cumulative (Lemma~\ref{lemma:logreldeterhet}).
\end{proof}

\begin{lemma}[ST-App]
  \label{lemma:stapp}
  If $[[G |= b : Pi A B]]$ and $[[G |= a : A]]$, then $[[G |= b a : B {a}]]$.
\end{lemma}
\begin{proof}
Suppose $[[rho |= G]]$. The goal is to show that there exists some
$[[i]]$ and $[[S1]]$
such that  $[[b {rho} a {rho} in S1 ]]$ and $[[InterpR i B {a} {rho}
S1]]$, or equivalently, $[[InterpR i B {rho .: a {rho}} S1]]$ since
$[[B {a}{rho}]] = [[B {rho .: a {rho}}]]$. By the premise $[[G |= b :
Pi A B]]$, Lemma~\ref{lemma:setinv}, and Lemma~\ref{lemma:piinvalt},
there exists some $[[i]]$ and $[[S0]]$ such that:
  \begin{itemize}
  \item $[[InterpR i A{rho} S0]]$
  \item $[[forall a0, (# a0 in S0 implies (# exists S1 , InterpR i B
    {rho .: a0}
    S1 #) #)]]$
  \item $[[forall a0, (# a0 in S0 , forall
      S1, (# InterpR i B {rho .: a0} S1,  b {rho} a0 in S1 #) #)]]$
  \end{itemize}
  Instantiating the variable $[[a0]]$ from the last two bullets with
  the term $[[a {rho}]]$, the conclusion immediately follows.
\end{proof}

\begin{theorem}[The Fundamental Theorem\footnote{\dotv{soundness.v}{soundness}}]
  \label{theorem:soundness}\leavevmode
  \begin{itemize}
  \item If $[[G |- a : A]]$, then $[[G |= a : A]]$.
  \item If $[[|- G]]$, then $[[|= G]]$.
  \end{itemize}
\end{theorem}
\begin{proof}
  Proof by mutual induction over the derivation of $[[G |- a :
  A]]$ and $[[|- G]]$.   The cases related to context well-formedness immediately follows
  from Lemma~\ref{lemma:semwffcons}.
Lemmas~\ref{lemma:stvar},~\ref{lemma:stset},~\ref{lemma:stpi},~\ref{lemma:stabs},~\ref{lemma:stapp}
  can be used to discharge their syntactic counterpart
  (e.g. Lemma~\ref{lemma:stabs} for case \rref{T-Abs}). The remaining
  cases not covered by the lemmas are similar to the ones already
  shown or simpler and therefore omitted from the text.

\end{proof}

\begin{corollary}[Logical Consistency]
  \label{corollary:consistency}
  The judgment $[[empty |- a : Void ]]$ is not derivable.
\end{corollary}
\begin{proof}
  Immediate from Theorem~\ref{theorem:soundness} and the $[[Void]]$ case of Lemma~\ref{lemma:interpinv}.
\end{proof}

\section{Toward Decidability of Type Conversion and $\eta$ laws}
\label{sec:extension}
\begin{figure}[h]
  \[
    \begin{array}{lcl}
      % \beta\text{-}\mathit{neutral\ terms}\\
      [[e]] & ::= & [[i]]\ |\ [[e f]]\ |\ [[J e f f f]]\ |\ [[if e f
                    f]] \\ \\
      % \beta\text{-}\mathit{normal\ terms} \\
      [[f]] & ::= & [[e]]\ |\ [[Set i]]\ |\ [[Void]]\ |\ [[Pi f f]]\
                    |\ [[f ~ f : f]]\\
            & |   & [[\\ f]]\ |\ [[refl]]\ |\ [[Bool]]\ |\ [[true]]\ |\ [[false]]
    \end{array}
  \]
  \caption{$\beta$-neutral and normal forms}
  \label{fig:nenf}
\end{figure}
\begin{figure}[h]
  \drules[I]{$[[Interp I i A S]]$}{Logical Relation}{Ne, VoidNew, BoolNew, EqNew}
  \caption{Extended logical relation}
  \label{fig:logrelopen}
\end{figure}

In this section, we sketch out how the logical relation from
Section~\ref{sec:logreldep} can be extended show the existence of
$\beta\eta$ normal forms for (open and closed) well-typed terms. We
first extend parallel reduction to include $\eta$ reduction for
functions.
\begin{center}
  \drule[width=2.5in]{P-AbsEta}
\end{center}
\Rref{P-AbsEta} effectively adds $\eta$ laws for functions to our
equational theory since coherence, the untyped relation used for type
conversion, is built on top of parallel reduction. We can recover the
same confluence result about parallel reduction using the standard
techniques from \citet{barendregt:lambda-calculi-with-types,
takahashi-parallel-reduction}, though specifically for the de Bruijn
representation, we need the following anti-renaming lemma about
parallel reduction.
\begin{lemma}[Par anti-renaming]
  \label{lemma:parantirenaming} If $[[a < xi > => b0]]$, then there
exists some $[[b]]$ such that $[[b < xi > = b0]]$ and $[[a => b]]$.
\end{lemma}



The syntactic forms $[[e]]$ and $[[f]]$ (Figure~\ref{fig:nenf}) capture the neutral terms
and normal forms with respect to $\beta$-reduction, but can still take
$\eta$ reduction steps. We sometimes use the judgment forms $[[ne a]]$
and $[[nf a]]$ to indicate that there exists $[[e]]$ or $[[f]]$ such
that $[[a = e]]$ or $[[a = f]]$.

We can show that parallel reduction preserves $\beta$-normal and
neutral forms.
\begin{lemma}[Par preserves $\beta$-neutral and normal forms]
  \label{lemma:parnenf}
  If $[[a => b]]$, then
  \begin{itemize}
  \item $[[ne a]]$ implies $[[ne b]]$
  \item $[[nf a]]$ implies $[[nf b]]$
  \end{itemize}
\end{lemma}
This lemma is mainly to show that \rref{P-AbsEta} does not introduce
any new $\beta$ redex because $\eta$ reduction is the only real step
we can take.

The predicates $[[wne a]]$ and $[[wn
a]]$ describe terms that can evaluate into $\beta$-neutral or
$\beta$-normal form through parallel reduction and are defined as
follows.
\[ [[wne a]] \iff \exists [[e]], [[a =>+ e]] \]
\[ [[wn a]] \iff \exists [[f]], [[a =>+ f]] \]

The updated logical relation and its auxiliary definitions are shown
in Figure~\ref{fig:logrelopen}.

% The idea of a term blocked from $\beta$ reduction is
% captured by $[[e]]$, the set of neutral terms. We augment the
% interpretation of booleans and the empty types with terms that
% evaluate to neutral terms. Furthermore, types that are neutral terms
% can also be assigned a meaning since they may be inhabited by other
% neutral terms.

In the definition of the logical relation, we omit the rules for
the function and universe cases since they remain identical to the
original version in Figure~\ref{fig:logrel}.
The changes to \rref{I-Bool} and \rref{I-Void} follow the exact same pattern.
An open term of type $[[Bool]]$ does
not necessarily reduce to $[[true]]$ or $[[false]]$, but may reduce to
a variable, or more generally, a neutral term. Likewise, the
$[[Void]]$ type, while remains uninhabited under an empty context, may
be inherited by the set of neutral terms when there is a variable in
the context that allows us to inhabit $[[Void]]$.

The rule for equality type $[[a ~ b : A]]$ is augmented with the preconditions that
$[[a]]$, $[[b]]$, and $[[A]]$ are all in their normal forms since
otherwise our model would include equality types that are themselves
not normalizing. Furthermore, the side condition $[[a <=> b]]$ is only
available when the equality proof reduces to $[[refl]]$. If the proof
term reduces to a neutral term, then there is nothing we can learn
about the relationship between $[[a]]$ and $[[b]]$.

Finally, in a
non-empty context, a type itself may evaluate to a neutral term and in
turn can only inhabited by neutral terms, thus the addition of \rref{I-Ne}.

Interestingly, all the properties we have shown in
Section~\ref{sec:logreldep} and \ref{sec:logrelproof} before the
fundamental lemma can be proven in the exact same order, where the new
cases due to \rref{I-Ne} and the augmentation of neutral terms
to \rref{I-Void, I-Eq, I-Bool} can be immediately discharged by
Lemma~\ref{lemma:parnenf}.

Before we can prove the fundamental theorem and derive the
normalization property as its corollary, we need to additionally
formulate and prove the adequacy property.

Let us first start with some auxiliary lemmas and definitions.
\begin{lemma}[Ext Wn]
  \label{lemma:extwn}
  If $[[wn a var i]]$, then $[[wn a]]$.
\end{lemma}
\begin{proof}
  By induction over the length of the reduction sequence in $[[wn a
  var i]]$. The proof relies on Lemma~\ref{lemma:parantirenaming} and
  \ref{lemma:parnenf}.
\end{proof}

\begin{lemma}[wne wn]
  \label{lemma:wnewn}
  If $[[wne a]]$ and $[[wn b]]$, then $[[wne a b]]$.
\end{lemma}
\begin{proof}
  Immediate by lexicographical induction over the length of the reduction sequences in
  $[[wne a]]$ and $[[wn b]]$.
\end{proof}

\begin{definition}[CR]
  Let $[[S]]$ be a set of lambda terms. We say that
  \begin{itemize}
  \item $[[S]] \in CR_1 \iff $  $[[forall a, (#  wne a implies a in S #)]]$
  \item $[[S]] \in CR_2 \iff$ $[[forall a, (# a in S implies wn a #)]]$
  \item $[[S]] \in CR \iff $ $[[S]] \in CR_1$ and $[[S]] \in CR_2$
  \end{itemize}
\end{definition}

\begin{lemma}[$CR_1$ for type]
  \label{lemma:cr1ty}
  If $[[wne A]]$, then we have $[[Interp I i A {a | wne a }]]$.
\end{lemma}
\begin{proof}
  Immediately from \rref{I-Ne} and \rref{I-Par}.
\end{proof}

\begin{lemma}[$CR$ for interpreted sets]
  \label{lemma:crel}
  If $[[I]](j) \in CR$ for all $[[j < i]]$ and $[[Interp I i A S]]$, then $[[S]] \in CR$.
\end{lemma}
\begin{proof}
  By induction over the derivation of $[[Interp I i A S]]$. The base
  cases are all immediate.

  In the function case ($[[Pi A B]]$), we use the induction
  hypothesis to show that variables, which are special cases of
  neutral terms, semantically inhabit the input type $[[A]]$. We apply the
  function to an arbitrary variable and we can then use
  Lemma~\ref{lemma:extwn} to conclude the $CR_2$ property.

  To show
  the $CR_1$ property, we need to prove that given a neutral term $[[b]]$
  such that $[[wne b]]$,
  and a term $[[a]]$ that semantically inhabits $[[A]]$, $[[b a]]$ gives
  us a term that semantically inhabits $[[B {a}]]$. From the induction
  hypothesis, $[[A]]$ also satisfies $CR_2$ and therefore $[[wn a]]$
  holds. By Lemma~\ref{lemma:wnewn}, we have $[[wne b a]]$. By $CR_2$
  from the induction hypothesis, since every term that evaluates to
  some neutral form semantically inhabits $[[B {a}]]$. Done.
\end{proof}


\begin{lemma}[$CR_2$ for type]
  \label{lemma:cr2ty}
  If $[[I]](j) \in CR$ for all $[[j < i]]$ and $[[Interp I i A S]]$, then $[[wn A]]$ holds.
\end{lemma}
\begin{proof}
  By induction over the derivation of $[[Interp I i A S]]$. The
  function case uses Lemma~\ref{lemma:crel} and Lemma~\ref{lemma:extwn}.
\end{proof}

\begin{lemma}[$CR_2$ for types (Rec)]
  \label{lemma:cr2tyrec}
  If $[[InterpR i A S]]$, then $[[wn A]]$.
\end{lemma}
\begin{proof}
  By strong induction over $[[i]]$ and Lemma~\ref{lemma:cr2ty}.
\end{proof}

\begin{lemma}[$CR$ for terms (Rec)]
  \label{lemma:crelrec}
  If $[[InterpR i A S]]$, then $[[S]] \in CR$.
\end{lemma}
\begin{proof}
  After unfolding the definition of $[[InterpR i A S]]$, trivial by
  Lemmas~\ref{lemma:cr1ty}, \ref{lemma:crel} and \ref{lemma:cr2tyrec}.
\end{proof}

The formulation of the valuation and semantic well-typedness from
Figure~\ref{fig:semtyping} and the fundamental lemma remains
unchanged.
The proof of the fundamental lemma is still carried out by induction
over the typing derivation, where the additional neutral term related
cases are handled by Lemmas~\ref{lemma:cr2tyrec} and
\ref{lemma:crelrec}.

The normalization property then follows as a corollary of the
fundamental theorem.
\begin{corollary}[Existence of $\beta$-normal form]
  \label{corollary:exbetanf}
  If $[[G |- a : A]]$, then $[[wn a]]$ and $[[wn A]]$.
\end{corollary}
\begin{proof}
  By the fundamental lemma, we know that $[[G |= a : A]]$. That is,
  for all $[[rho |= G]]$, there exists some $[[i]]$ and $[[S]]$ such
  that $[[InterpR i A {rho} S]]$ and $[[a {rho} in S]]$.
  We pick the valuation $[[rho]] = [[idtm]]$ (defined in Figure~\ref{fig:auxdef}), which injects
  natural numbers as term variables. The side condition $[[idtm |=
  G]]$ is satisfied since Lemma~\ref{lemma:crelrec} says neutral terms,
  including variables, semantically inhabit any $[[S0]]$ where
  $[[S0]]$ is the interpretation of some type. With our choice of
  $[[rho]]$, we have $[[A {rho}]] = [[A {idtm}]] = [[A]]$ and $[[a {rho}]] = [[a{idtm}]] = [[a]]$. Then we
  know that $[[InterpR i A S]]$ and $[[a in S]]$ for some $[[i]]$ and
  $[[S]]$. By Lemmas~\ref{lemma:crelrec} and \ref{lemma:cr2tyrec}, we
  conclude that $[[wn a]]$ and $[[wn A]]$ respectively.
\end{proof}
From Corollary~\ref{corollary:exbetanf}, we can show that there exists
$\beta\eta$-normal forms for well-typed terms, since $\eta$ reduction
preserves $\beta$-normal form (implied by Lemma~\ref{lemma:parnenf})
and also strictly decreases the size of the term.

Due to the non-deterministic nature of parallel reduction, we need to
take a few more steps to convert the existence of $\beta\eta$-normal
form into a decision procedure for type conversion. More specifically,
we can show that a deterministic evaluation strategy such as
leftmost-outermost reduction can always find the $\beta\eta$-normal
form if there exists one. However, we omit such proofs since they can
can be formulated on untyped lambda terms and thus orthogonal to the
specifics of dependently typed systems. Instead, we redirect readers
to \citet{factorization-essentially, takahashi-parallel-reduction} for
the details.

Finally, we want to point out that
Lemmas~\ref{lemma:cr1ty},~\ref{lemma:cr2tyrec}, and
\ref{lemma:crelrec}, often referred to as adequacy of the logical
relation, are in fact required in the normalization proof for simply
typed languages~\citep{abel2019poplmark}. Similar to the simply typed
scenario, adequacy needs to be proven before the fundamental theorem
so we can handle rules such as \rref{T-If} where the scrutinee is a
neutral term. In \citet{abel2019poplmark}, a variant of
Lemma~\ref{lemma:extwn} is used in the exact same way to show that
lambda terms are themselves normalizing as we have done in
Lemma~\ref{lemma:crel}.

Dependent types make the proof slightly more complicated
as we also need to know that every type has a normal form. Whereas the
$CR_1$ property for types (Lemma~\ref{lemma:cr1ty}) is directly
derivable, the $CR_2$ property for types (Lemma~\ref{lemma:cr2ty})
requires the $CR_1$ property about the interpreted sets
(Lemma~\ref{lemma:crel}).

Overall, despite the dependently typed setting,
the extension of our logical relation to prove normalization of open
\emph{and} closed terms closely mirrors the progression from
normalization of closed terms~\citep{harpertait} to normalization of
open terms~\citep{harperkripke} in the simply typed lambda calculus.
It is in fact reassuring that once we have laid the foundational
technique for handling dependent types in our logical relation, the
further extensions more or less boil down to properties that can be
derived through syntactic means, which tend to not get in the way of
GÃ¶del's second incompleteness theorem.

\section{Mechanization}
\label{sec:logrelmech}
\begin{figure}[h]
  \begin{tabular}{ c |  c  | c  }
    & Consistency & Normalization \\
    \hline
    Library (Autosubst 2)  & 491 & - \\
    Syntactic typing (specification) &  69 & - \\
    Renaming (common)  & 46 & -  \\
    Syntactic soundness & 660 &  - \\
    Untyped reduction & 350 & 834 \\
    Logical relation & 342 & 515 \\
    Semantic typing and soundness & 169 & 197 \\
  \end{tabular}
  \caption{Statistics of the Coq Development}
  \label{fig:linecount}
\end{figure}

Figure~\ref{fig:linecount} shows the statics of our
development, including the base consistency proof from
Section~\ref{sec:logreldep} and \ref{sec:logrelproof} and the
extension to normalization for open and closed terms from
Section~\ref{sec:extension}.

Since the normalization and the consistency development share the same
syntactic and typing specification, they differ in only the categories
that are related to the logical relation. We use - as a marker that
the line count is the same.

Autosubst 2 takes our syntax specification in higher-order abstract
syntax and generates Coq syntax specification, renaming and
substitution functions, and lemmas and tactics that allow reasoning
about those functions. The auto-generated files and the library header
files are counted toward the \emph{Library (Autosubst 2)} category.

Orthogonal to the development of our consistency and normalization
proof, we prove the syntactic soundness of our system through subject
reduction and progress. The syntactic soundness proof shares the
definition of renaming with our semantic soundness proof, which is
factored out as a separate file under the Renaming (common) category.

\subsection{Artifacts Specific to Coq}
In this section, we discuss the Coq encoding of the definitions and proofs presented
in Section~\ref{sec:logrelproof}  and the artifacts that are
specific to Coq and may not appear in other proof assistants.

The powerset $[[PowerSet STm]]$ is encoded as the type \texttt{tm ->
Prop}, a predicate over \lang{} terms.
The inductive
definition of the logical relation in Figure~\ref{fig:logrel} requires
the impredicativity of Coq's \texttt{Prop} sort since in \rref{I-Pi},
the function $[[F]]$ can be later instantiated into the logical
relation itself (e.g. in the proof of Lemma~\ref{lemma:piintroalt}).

In Coq, there is a distinction between computable functions and
relations that can later be proven to be functional. The former can be
viewed as a strict subset of the latter in axiom-free Coq. To be more
precise, given a relation \texttt{R : A -> B -> Prop} subject to the
totality and functionality constraints ($\forall$ \texttt{a} $\in$
\texttt{A}, there exists a unique \texttt{b} $\in$ \texttt{B} such
that \texttt{R a b} is inhabited), we do not immediately obtain a function
\texttt{F : A -> B} such that $\forall$ \texttt{a} $\in$ \texttt{A},
\texttt{R a (F a)} is inhabited. However, the functional side
conditions of a relation is clunky to express and tend to block
automation. A simple workaround is to assume the axiom of unique choice, which
is known to be consistent with Coq and allows us to induce a function \texttt{F
: A -> B} once we have shown the relation \texttt{R : A -> B -> Prop}
is functional. This approach would make our Coq development match
the text version of our proof from Section~\ref{sec:logrelproof} more
closely.

However, we choose instead an axiom-free workaround and define
\rref{I-Pi} as follows in our Coq mechanization.
\begin{center}
  \drule[]{I-PiCoq}
\end{center}
It should be easy to verify that the preconditions of
\rref{I-Pi}, \rref{I-PiAlt}, and \rref{I-PiCoq} are all
equivalent. After establishing Lemma~\ref{lemma:logreldeter}, it is
possible to further show that the conclusions of the rules are
equivalent, too.

% This formulation allows us to derive Lemma~\ref{lemma:piintroalt}
% before we even show that our logical relation is
% functional/deterministic, but does not affect the proof structure
% otherwise.
We choose to keep this discrepancy between the Coq development and the
logical relation presented in Section~\ref{sec:logreldep} since the
skolemization process is more intuitively expressed in terms of
function symbols rather than relation symbols. Otherwise, we do not
see a clear advantage of \rref{I-PiCoq} over \rref{I-Pi} in set
theory, where there is no distinction between computable functions and
functions in general.

\subsection{Automation}
\label{sec:automation}
Our Coq mechanization heavily uses automation, though instead of
defining custom tactics, we rely mostly on off-the-shelf tools such as
Autosubst 2~\citep{autosubst2} and CoqHammer~\citep{czajka2018hammer}.

We use the Autosubst 2 framework to specify our syntax in HOAS and
produce Coq syntax files in de Bruijn representation. Additionallly,
Autosubst 2 provides a powerful tactic \texttt{asimpl} which
can be used to prove the equivalence of two terms constructed using
the primitive operators provided by the framework. This greatly
simplifies the reasoning about substitution in our development as
almost all substitution related properties are immediately discharged
by \texttt{asimpl} without having to manually prove or even directly invoke any
substitution related lemmas.

For other automation tasks that are not specific to binding, we use
the powerful \texttt{sauto} tactic provided by CoqHammer to write
short and declarative proofs. For example, here is a one-line proof of
the triangle property about parallel reduction, from which the diamond
property (Lemma~\ref{lemma:pardiamond}) follows as a corollary.
\begin{minted}{coq}
Lemma par_triangle a : forall b, Par a b ->  Par b (tstar a).
Proof.
  apply tstar_ind; hauto lq:on inv:Par use:Par_refl,par_cong ctrs:Par.
Qed.
\end{minted}
In prose, the triangle property can be proven by induction over the
graph of the \texttt{tstar} function, which stands for the Takahashi
translation~\citep{takahashi-parallel-reduction}. Options \texttt{inv:Par} and
\texttt{ctrs:Par} say that the proof involves inverting and
constructing of the derivations of parallel
reduction. The option \texttt{use:Par\_refl,par\_cong} allows the
automation tactic to use
the reflexivity and congruence properties of parallel
reduction as lemmas.

The automation here not only gives us a proof that is shorter and more
resiliant to changes in definition, but also gives useful
documentation for readers who wish to understand how the underlying
proof works since the automation tactic is guaranteed to not use
lemmas or invert derivations that are not specified in the
\texttt{use} or \texttt{inv} flag.


\section{Related Work and Discussion}
\label{sec:relatedwork}
\citet{Martin-Lof-1973}, \citet{geuvers1994short}, and
\citet{barendregt:lambda-calculi-with-types} are some of the earlier
works that establish metatheoretic results strong enough to derive
consistency for dependently typed systems. Some of these techniques
are still in use in more recent works. For example, the technique for
proving strong normalization by \citet{geuvers1994short} is adapted by
\citet{moon2021graded} to show the same property to a dependently
typed system extended with modalities.

\citet{decagda} mechanizes in Agda the decidability of type
conversion rule for a dependently typed language with one predicative
universe level and typed judgmental equality with function
$\eta$-law. Unlike our logical relation for \lang{}, \citet{decagda}
uses a Kripke-style logical relation parameterized over an
type-directed equivalence relation satisfying certain
properties. Their logical relation is defined using the
induction-recursion scheme, which is available in Agda but not in Coq.
\citet{martin-lof-a-la-coq} manages to encode the logical relation
from \citet{decagda} in the predicative fragment of Coq using a
special way of encoding induction recursion. Their work further
extends the decidability of type conversion result from~\citet{decagda} to the decidability
type checking of a bidrectional type system.

\citet{anand2014towards} mechanizes the metatheory of
Nuprl~\citep{constable1986implementing} in Coq. The metatheory is an
extensional type theory with features such as dependent functions,
inductive types, and a full universe hierarchy. \citet{nbeincoq}
mechanizes the normalization-by-evaluation algorithm in Coq for a
dependently typed language with one predicative universe, similar to
\citet{decagda} and \citet{martin-lof-a-la-coq}. Both
\citet{anand2014towards} and \citet{nbeincoq} leverage the
impredicative \texttt{Prop} sort of Coq to define the interpretation
of dependent function types and thus are closely related to our
mechanization. However, instead of explaining the purely inductive
logical relation as a convoluted workaround to the lack of
induction-recursion in Coq, we give a self-contained explanation of
our logical relation.

Finally, it is worth pointing out that all systems we have discussed
so far builds a relational model for their logical relation. Recall
that our logical relation takes the form $[[InterpR i A S]]$ where
$[[S]]$ is a set of terms. In a relational model, each type is
interpreted as a partial equivalence relation over terms rather than a
set. A relational model is necessary for an extensional type theory
such as Nuprl, though \citet{nbeincoq,decagda,martin-lof-a-la-coq} all
use a relational model either to justify the function $\eta$-law or to
derive $\Pi$-injectivity. In Section~\ref{sec:extension}, our $\eta$
law for function is baked into the untyped reduction
relation and therefore a relational model is not needed.

The dependently typed systems we have discussed so far also vary
greatly in expressiveness. For example, the Calculus of
Constructions~\citep{CoC} and MLTT without universe levels are unable
to encode large elimination. \citet{decagda} and \citet{nbeincoq} lack
identity types. \citet{nbeincoq} lacks $\eta$-law for functions. Among
the mechanized systems we have discussed so far, only
\citet{anand2014towards} has a full universe hierarchy.
Our object language \lang{}, while small, has a decent coverage of
features commonly seen in dependently typed languages, including
dependent pattern matching, dependent function types, a full universe
hierarchy, an intensional identity type. We hope features such as
type-directed reduction (necessary for unit $\eta$-law) and
impredicative sorts can be implemented in a similarly streamlined
fashion and we will leave those extensions as part of our future work.

% To end this section, we

The final question we want to address is: why is our proof,
even with the extension from Section~\ref{sec:extension}, so much
shorter than the proofs from \citet{decagda, nbeincoq,
  martin-lof-a-la-coq}?
First, unlike developments that mechanize the correctness of a clever
type conversion algorithm, we only show the existence of
normal form for open and closed terms and state our properties in
terms of the untyped small-step reduction relation. This removes a lot
of scaffolding in the specification of our type system and our logical
relation.

This contrasts our development with
\citet{martin-lof-a-la-coq}, where the irrelevance property turns out to be the most
difficult property to prove due to the complexity of the equality
judgment used to define the logical relation. In our system, the
irrelevance property (Corollary~\ref{lemma:logrelcoherence}) is a
direct consequence of Lemma~\ref{lemma:interppreservation}, which is
straightforward after we prove the classical results about parallel
reduction in Section~\ref{sec:spec}. In other words, we keep the
the logical relation itself minimal at the cost of extra lemmas that can be proven
through syntactic means independently from the logical relation.
For example, as commented near the end of Section~\ref{sec:extension},
our normalization property (Corollary~\ref{corollary:exbetanf})
% can induce a decision procedure for type conversion by reducing two
% terms to $\beta\eta$-normal form and check for their syntactic
% equivalence. This decision procedure would be inefficient compared to
% NbE or the algorithm from \citet{martin-lof-a-la-coq} that reduces terms
% to weak head normal and checks for the equivalence of subterms
% recursively
does not immediately induce an efficient decision procedure, but it is
possible to recover an efficient algorithm by reasoning about untyped
lambda terms.

% the concision of
% our proof can be largely attributed to the fact that we bake into the
% logical relation only the minimum amount of information that is the
% most conducive to the proof of the metatheoretic result.

Another key to our proof is the very early establishment of the confluence
property of the paralell reduction relation
(Lemma~\ref{lemma:pardiamond}). This property is used in
Lemma~\ref{lemma:interppreservation} to show that the interpretation
of a type is preserved under evaluation. That is, if $[[InterpR i A
S]]$ and $[[A => B]]$, then we also have $[[InterpR i B S]]$.
In a system with typed directed reduction, the confluence result is
harder to establish since confluence requires subject reduction, which
circularly depends on $\Pi$-injectivity, a consequence of
confluence~\citep{siles2012pure}. There are different workarounds to
this problem. \citet{siles2012pure} proposes a syntactic approach by
defining a type system where the confluence result is
directly provable and later show that the system of interest is
equivalent to the system with the confluence property.
\citet{decagda} uses a relational model and the relational counterpart
of Lemma~\ref{lemma:extwn} to derive $\Pi$-injectivity. The relational
model is parameterized by a typed indexed equivalence relation and
is reused to prove derive different properties in their
development. Another perhaps simpler approach is to simply
extend the judgmental equality with rules about
$\Pi$-injectivity~\citep{weirich:systemd}. This allows subject
reduction to be proven independently from confluence and
$\Pi$-injectivity can later be shown to be admissible. We find the
approach from \citep{weirich:systemd} the most lightweight as it
allows us to derive confluence early on even in systems with typed
conversion.

In cases where the judgmental equality does not leverage type information heavily
(e.g. $\eta$-law for the unit type), it might be possible to show that
$\Gamma \vdash a \equiv b : A$ is equivalent to the conjunction of
$[[G |- a : A]]$, $[[G |- b : A ]]$, and $[[a <=> b]]$. If such a
property holds (we believe this is likely true for both
\citet{decagda} and \citet{martin-lof-a-la-coq}), we can reuse our existing logical relation in
terms of untyped parallel reduction to show the decidability of type
conversion. Otherwise, to fully model the system, we need to bake
typing information into our logical relation and we need to redefine
our logical relation in Kripke-style so we can relax the scoping
constraint in order to prove adequacy, though a relational model would
still be unnecessary as long as the $\eta$ laws are baked into the
typed directed relation.

Since confluence plays such as key role in our proof, we are uncertain
how to generalize our technique to systems where confluence does not
hold, and we will investigate those scenarios in our future work.

% We are able to avoid the complexivity of a Kripke-style logical relation
% by defining our logical relation in terms of untyped parallel
% reduction, which does not impose any scoping constraint on the
% terms.


% Why is it that the justification of $\eta$ law
% requires a Kripke-style relational model in all three developments
% but not ours? Are we ``cheating'' by defining \lang{}'s equational
% theory using an untyped conversion rule? Instead of answering the
% questions one by one, we clarify the design of our type system and our
% proof technique so the answers to those questions are self-evident.

% The key to the shortness of

\section{Conclusion}
\label{sec:conclusion}


% Type soundness can be proven through a syntactic
% approach~\citep{syntacticsoundness} as a corollary of two properties:
% progress and preservation. % The syntactic type soundness proof
% % varies in complexity depending on the underlying type
% % system. For example, a type system that tracks information flow would
% % require additional structural rules related to security levels. In
% % this paper, we focus on one specific type of complexity: the
% In Figure~\ref{fig:stlcsoundness}, we summarize the structure of the
% syntactic type soundness proof for the simply typed lambda
% calculus. Each lemma can be proven by structural induction over the
% typing derivation, while using the previous established results as
% lemmas for specific cases that do not immediately follow from the
% induction hypothesis. If we make our language more complex by adding
% full dependent type support, the overall structure remains almost
% identical.


% NbE in Coq

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{refs}


%%
%% If your work has an appendix, this is the place to put it.

\end{document}
\endinput
%%
%% End of file `sample-acmsmall.tex'.
